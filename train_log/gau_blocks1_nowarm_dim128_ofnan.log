Device cuda
Loading csv... Device cuda
Loading csv... done, took 5.7s
Parsing... done, took 5.0s
Entropy of DMV([Column(Record Type, distribution_size=2), Column(Registration Class, distribution_size=69), Column(State, distribution_size=77), Column(County, distribution_size=63), Column(Body Type, distribution_size=57), Column(Fuel Type, distribution_size=8), Column(Reg Valid Date, distribution_size=2828), Column(Color, distribution_size=218), Column(Scofflaw Indicator, distribution_size=2), Column(Suspension Indicator, distribution_size=2), Column(Revocation Indicator, distribution_size=2)]): 19.3435 bits
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7315785 entries, 0 to 7315784
Data columns (total 11 columns):
 #   Column                Dtype         
---  ------                -----         
 0   Record Type           object        
 1   Registration Class    object        
 2   State                 object        
 3   County                object        
 4   Body Type             object        
 5   Fuel Type             object        
 6   Reg Valid Date        datetime64[ns]
 7   Color                 object        
 8   Scofflaw Indicator    object        
 9   Suspension Indicator  object        
 10  Revocation Indicator  object        
dtypes: datetime64[ns](1), object(10)
memory usage: 614.0+ MB
None
ordering [ 0  1  2  3  4  5  6  7  8  9 10]
Number of model parameters: 544177 (~= 2.1MB)
FLASHTransformer(
  (layers): Sequential(
    (0): FLASH(
      (attn_fn): ReLUSquared()
      (rotary_pos_emb): RotaryEmbedding()
      (rel_pos_bias): T5RelativePositionBias(
        (relative_attention_bias): Embedding(32, 1)
      )
      (norm): ScaleNorm()
      (dropout): Dropout(p=0.0, inplace=False)
      (to_hidden): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
      )
      (to_qk): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): SiLU()
      )
      (qk_offset_scale): OffsetScale()
      (to_out): Linear(in_features=256, out_features=128, bias=True)
    )
  )
  (to_logits): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (embeddings): ModuleList(
    (0): Embedding(2, 128)
    (1): Embedding(69, 128)
    (2): Embedding(77, 128)
    (3): Embedding(63, 128)
    (4): Embedding(57, 128)
    (5): Embedding(8, 128)
    (6): Embedding(2828, 128)
    (7): Embedding(218, 128)
    (8): Embedding(2, 128)
    (9): Embedding(2, 128)
    (10): Embedding(2, 128)
  )
  (pos_embeddings): Embedding(11, 128)
)
Discretizing table... done, took 3.7s
Epoch 0 Iter 0, train entropy gap 31.7564 bits (loss 51.100, data 19.343) 
Epoch 0 Iter 200, train entropy gap 2.9626 bits (loss 22.306, data 19.343) 
Epoch 0 Iter 400, train entropy gap 2.0793 bits (loss 21.423, data 19.343) 
Epoch 0 Iter 600, train entropy gap 2.1560 bits (loss 21.499, data 19.343) 
Epoch 0 Iter 800, train entropy gap 2.2655 bits (loss 21.609, data 19.343) 
Epoch 0 Iter 1000, train entropy gap 2.0490 bits (loss 21.392, data 19.343) 
Epoch 0 Iter 1200, train entropy gap 1.9116 bits (loss 21.255, data 19.343) 
Epoch 0 Iter 1400, train entropy gap 2.0081 bits (loss 21.352, data 19.343) 
Epoch 0 Iter 1600, train entropy gap 1.7433 bits (loss 21.087, data 19.343) 
Epoch 0 Iter 1800, train entropy gap 1.5415 bits (loss 20.885, data 19.343) 
Epoch 0 Iter 2000, train entropy gap 1.7964 bits (loss 21.140, data 19.343) 
Epoch 0 Iter 2200, train entropy gap 1.3079 bits (loss 20.651, data 19.343) 
Epoch 0 Iter 2400, train entropy gap 0.7999 bits (loss 20.143, data 19.343) 
Epoch 0 Iter 2600, train entropy gap 0.9526 bits (loss 20.296, data 19.343) 
Epoch 0 Iter 2800, train entropy gap 0.9370 bits (loss 20.280, data 19.343) 
Epoch 0 Iter 3000, train entropy gap 0.8895 bits (loss 20.233, data 19.343) 
Epoch 0 Iter 3200, train entropy gap 0.9560 bits (loss 20.299, data 19.343) 
Epoch 0 Iter 3400, train entropy gap 1.1972 bits (loss 20.541, data 19.343) 
Epoch 0 Iter 3600, train entropy gap 0.8921 bits (loss 20.236, data 19.343) 
Epoch 0 Iter 3800, train entropy gap 1.0364 bits (loss 20.380, data 19.343) 
Epoch 0 Iter 4000, train entropy gap 1.1030 bits (loss 20.446, data 19.343) 
Epoch 0 Iter 4200, train entropy gap 1.1115 bits (loss 20.455, data 19.343) 
Epoch 0 Iter 4400, train entropy gap 0.9812 bits (loss 20.325, data 19.343) 
Epoch 0 Iter 4600, train entropy gap 1.1418 bits (loss 20.485, data 19.343) 
Epoch 0 Iter 4800, train entropy gap 0.9600 bits (loss 20.303, data 19.343) 
Epoch 0 Iter 5000, train entropy gap 1.0738 bits (loss 20.417, data 19.343) 
Epoch 0 Iter 5200, train entropy gap 1.0720 bits (loss 20.415, data 19.343) 
Epoch 0 Iter 5400, train entropy gap 0.8876 bits (loss 20.231, data 19.343) 
Epoch 0 Iter 5600, train entropy gap 0.9908 bits (loss 20.334, data 19.343) 
Epoch 0 Iter 5800, train entropy gap 0.9157 bits (loss 20.259, data 19.343) 
Epoch 0 Iter 6000, train entropy gap 0.9524 bits (loss 20.296, data 19.343) 
Epoch 0 Iter 6200, train entropy gap 1.0865 bits (loss 20.430, data 19.343) 
Epoch 0 Iter 6400, train entropy gap 0.8959 bits (loss 20.239, data 19.343) 
Epoch 0 Iter 6600, train entropy gap 0.9631 bits (loss 20.307, data 19.343) 
Epoch 0 Iter 6800, train entropy gap 0.8993 bits (loss 20.243, data 19.343) 
Epoch 0 Iter 7000, train entropy gap 0.7941 bits (loss 20.138, data 19.343) 
epoch 0 train loss 14.3995 nats / 20.7741 bits
time since start: 130.4 secs
Epoch 1 Iter 0, train entropy gap 0.7586 bits (loss 20.102, data 19.343) 
Epoch 1 Iter 200, train entropy gap 1.1318 bits (loss 20.475, data 19.343) 
Epoch 1 Iter 400, train entropy gap 1.0487 bits (loss 20.392, data 19.343) 
Epoch 1 Iter 600, train entropy gap 1.0862 bits (loss 20.430, data 19.343) 
Epoch 1 Iter 800, train entropy gap 0.7742 bits (loss 20.118, data 19.343) 
Epoch 1 Iter 1000, train entropy gap 0.7889 bits (loss 20.132, data 19.343) 
Epoch 1 Iter 1200, train entropy gap 0.8524 bits (loss 20.196, data 19.343) 
Epoch 1 Iter 1400, train entropy gap 0.9281 bits (loss 20.272, data 19.343) 
Epoch 1 Iter 1600, train entropy gap 0.7947 bits (loss 20.138, data 19.343) 
Epoch 1 Iter 1800, train entropy gap 0.9516 bits (loss 20.295, data 19.343) 
Epoch 1 Iter 2000, train entropy gap 0.9246 bits (loss 20.268, data 19.343) 
Epoch 1 Iter 2200, train entropy gap 0.9688 bits (loss 20.312, data 19.343) 
Epoch 1 Iter 2400, train entropy gap 0.8157 bits (loss 20.159, data 19.343) 
Epoch 1 Iter 2600, train entropy gap 0.8950 bits (loss 20.238, data 19.343) 
Epoch 1 Iter 2800, train entropy gap 0.9148 bits (loss 20.258, data 19.343) 
Epoch 1 Iter 3000, train entropy gap 0.8069 bits (loss 20.150, data 19.343) 
Epoch 1 Iter 3200, train entropy gap 0.8459 bits (loss 20.189, data 19.343) 
Epoch 1 Iter 3400, train entropy gap 0.9549 bits (loss 20.298, data 19.343) 
Epoch 1 Iter 3600, train entropy gap 0.7624 bits (loss 20.106, data 19.343) 
Epoch 1 Iter 3800, train entropy gap 0.9973 bits (loss 20.341, data 19.343) 
Epoch 1 Iter 4000, train entropy gap 0.7749 bits (loss 20.118, data 19.343) 
Epoch 1 Iter 4200, train entropy gap 0.9312 bits (loss 20.275, data 19.343) 
Epoch 1 Iter 4400, train entropy gap 0.8361 bits (loss 20.180, data 19.343) 
Epoch 1 Iter 4600, train entropy gap 0.9081 bits (loss 20.252, data 19.343) 
Epoch 1 Iter 4800, train entropy gap 0.8437 bits (loss 20.187, data 19.343) 
Epoch 1 Iter 5000, train entropy gap 0.8237 bits (loss 20.167, data 19.343) 
Epoch 1 Iter 5200, train entropy gap 0.5910 bits (loss 19.934, data 19.343) 
Epoch 1 Iter 5400, train entropy gap 0.7813 bits (loss 20.125, data 19.343) 
Epoch 1 Iter 5600, train entropy gap 0.8812 bits (loss 20.225, data 19.343) 
Epoch 1 Iter 5800, train entropy gap 0.8885 bits (loss 20.232, data 19.343) 
Epoch 1 Iter 6000, train entropy gap 0.9748 bits (loss 20.318, data 19.343) 
Epoch 1 Iter 6200, train entropy gap 0.9781 bits (loss 20.322, data 19.343) 
Epoch 1 Iter 6400, train entropy gap 0.9031 bits (loss 20.247, data 19.343) 
Epoch 1 Iter 6600, train entropy gap 0.7933 bits (loss 20.137, data 19.343) 
Epoch 1 Iter 6800, train entropy gap 0.8641 bits (loss 20.208, data 19.343) 
Epoch 1 Iter 7000, train entropy gap 0.8625 bits (loss 20.206, data 19.343) 
epoch 1 train loss 14.0290 nats / 20.2396 bits
time since start: 260.2 secs
Epoch 2 Iter 0, train entropy gap 0.8094 bits (loss 20.153, data 19.343) 
Epoch 2 Iter 200, train entropy gap 0.8481 bits (loss 20.192, data 19.343) 
Epoch 2 Iter 400, train entropy gap 0.7861 bits (loss 20.130, data 19.343) 
Epoch 2 Iter 600, train entropy gap 0.9299 bits (loss 20.273, data 19.343) 
Epoch 2 Iter 800, train entropy gap 0.8243 bits (loss 20.168, data 19.343) 
Epoch 2 Iter 1000, train entropy gap 0.6438 bits (loss 19.987, data 19.343) 
Epoch 2 Iter 1200, train entropy gap 0.7984 bits (loss 20.142, data 19.343) 
Epoch 2 Iter 1400, train entropy gap 0.8043 bits (loss 20.148, data 19.343) 
Epoch 2 Iter 1600, train entropy gap 0.8138 bits (loss 20.157, data 19.343) 
Epoch 2 Iter 1800, train entropy gap 0.9363 bits (loss 20.280, data 19.343) 
Epoch 2 Iter 2000, train entropy gap 0.7308 bits (loss 20.074, data 19.343) 
Epoch 2 Iter 2200, train entropy gap 0.6932 bits (loss 20.037, data 19.343) 
Epoch 2 Iter 2400, train entropy gap 0.9914 bits (loss 20.335, data 19.343) 
Epoch 2 Iter 2600, train entropy gap 0.7483 bits (loss 20.092, data 19.343) 
Epoch 2 Iter 2800, train entropy gap 0.6691 bits (loss 20.013, data 19.343) 
Epoch 2 Iter 3000, train entropy gap 0.8936 bits (loss 20.237, data 19.343) 
Epoch 2 Iter 3200, train entropy gap 0.8170 bits (loss 20.160, data 19.343) 
Epoch 2 Iter 3400, train entropy gap 0.9642 bits (loss 20.308, data 19.343) 
Epoch 2 Iter 3600, train entropy gap 0.8315 bits (loss 20.175, data 19.343) 
Epoch 2 Iter 3800, train entropy gap 0.9469 bits (loss 20.290, data 19.343) 
Epoch 2 Iter 4000, train entropy gap 0.9086 bits (loss 20.252, data 19.343) 
Epoch 2 Iter 4200, train entropy gap 0.7773 bits (loss 20.121, data 19.343) 
Epoch 2 Iter 4400, train entropy gap 0.7483 bits (loss 20.092, data 19.343) 
Epoch 2 Iter 4600, train entropy gap 0.8646 bits (loss 20.208, data 19.343) 
Epoch 2 Iter 4800, train entropy gap 1.1477 bits (loss 20.491, data 19.343) 
Epoch 2 Iter 5000, train entropy gap 0.9834 bits (loss 20.327, data 19.343) 
Epoch 2 Iter 5200, train entropy gap 0.7815 bits (loss 20.125, data 19.343) 
Epoch 2 Iter 5400, train entropy gap 0.8502 bits (loss 20.194, data 19.343) 
Epoch 2 Iter 5600, train entropy gap 0.9667 bits (loss 20.310, data 19.343) 
Epoch 2 Iter 5800, train entropy gap 0.6770 bits (loss 20.021, data 19.343) 
Epoch 2 Iter 6000, train entropy gap 0.7330 bits (loss 20.076, data 19.343) 
Epoch 2 Iter 6200, train entropy gap 0.8510 bits (loss 20.194, data 19.343) 
Epoch 2 Iter 6400, train entropy gap 1.0501 bits (loss 20.394, data 19.343) 
Epoch 2 Iter 6600, train entropy gap 0.8011 bits (loss 20.145, data 19.343) 
Epoch 2 Iter 6800, train entropy gap 0.9240 bits (loss 20.267, data 19.343) 
Epoch 2 Iter 7000, train entropy gap 1.0023 bits (loss 20.346, data 19.343) 
epoch 2 train loss 14.0105 nats / 20.2129 bits
time since start: 389.6 secs
Epoch 3 Iter 0, train entropy gap 0.8425 bits (loss 20.186, data 19.343) 
Epoch 3 Iter 200, train entropy gap 0.8735 bits (loss 20.217, data 19.343) 
Epoch 3 Iter 400, train entropy gap 0.7312 bits (loss 20.075, data 19.343) 
Epoch 3 Iter 600, train entropy gap 0.9499 bits (loss 20.293, data 19.343) 
Epoch 3 Iter 800, train entropy gap 1.0119 bits (loss 20.355, data 19.343) 
Epoch 3 Iter 1000, train entropy gap 0.7976 bits (loss 20.141, data 19.343) 
Epoch 3 Iter 1200, train entropy gap 0.8057 bits (loss 20.149, data 19.343) 
Epoch 3 Iter 1400, train entropy gap 0.9171 bits (loss 20.261, data 19.343) 
Epoch 3 Iter 1600, train entropy gap 0.8419 bits (loss 20.185, data 19.343) 
Epoch 3 Iter 1800, train entropy gap 0.9131 bits (loss 20.257, data 19.343) 
Epoch 3 Iter 2000, train entropy gap 0.7627 bits (loss 20.106, data 19.343) 
Epoch 3 Iter 2200, train entropy gap 0.7121 bits (loss 20.056, data 19.343) 
Epoch 3 Iter 2400, train entropy gap 0.8009 bits (loss 20.144, data 19.343) 
Epoch 3 Iter 2600, train entropy gap 0.9238 bits (loss 20.267, data 19.343) 
Epoch 3 Iter 2800, train entropy gap 0.8863 bits (loss 20.230, data 19.343) 
Epoch 3 Iter 3000, train entropy gap 1.0195 bits (loss 20.363, data 19.343) 
Epoch 3 Iter 3200, train entropy gap 0.9046 bits (loss 20.248, data 19.343) 
Epoch 3 Iter 3400, train entropy gap 0.9620 bits (loss 20.305, data 19.343) 
Epoch 3 Iter 3600, train entropy gap 0.9056 bits (loss 20.249, data 19.343) 
Epoch 3 Iter 3800, train entropy gap 0.7905 bits (loss 20.134, data 19.343) 
Epoch 3 Iter 4000, train entropy gap 0.7531 bits (loss 20.097, data 19.343) 
Epoch 3 Iter 4200, train entropy gap 0.7736 bits (loss 20.117, data 19.343) 
Epoch 3 Iter 4400, train entropy gap 0.9370 bits (loss 20.280, data 19.343) 
Epoch 3 Iter 4600, train entropy gap 0.9033 bits (loss 20.247, data 19.343) 
Epoch 3 Iter 4800, train entropy gap 0.8859 bits (loss 20.229, data 19.343) 
Epoch 3 Iter 5000, train entropy gap 0.8463 bits (loss 20.190, data 19.343) 
Epoch 3 Iter 5200, train entropy gap 0.7468 bits (loss 20.090, data 19.343) 
Epoch 3 Iter 5400, train entropy gap 0.7821 bits (loss 20.126, data 19.343) 
Epoch 3 Iter 5600, train entropy gap 0.8115 bits (loss 20.155, data 19.343) 
Epoch 3 Iter 5800, train entropy gap 0.8539 bits (loss 20.197, data 19.343) 
Epoch 3 Iter 6000, train entropy gap 0.8017 bits (loss 20.145, data 19.343) 
Epoch 3 Iter 6200, train entropy gap 1.1673 bits (loss 20.511, data 19.343) 
Epoch 3 Iter 6400, train entropy gap 0.7919 bits (loss 20.135, data 19.343) 
Epoch 3 Iter 6600, train entropy gap 0.6279 bits (loss 19.971, data 19.343) 
Epoch 3 Iter 6800, train entropy gap 0.8975 bits (loss 20.241, data 19.343) 
Epoch 3 Iter 7000, train entropy gap 0.9252 bits (loss 20.269, data 19.343) 
epoch 3 train loss 14.0027 nats / 20.2016 bits
time since start: 519.2 secs
Epoch 4 Iter 0, train entropy gap 0.9166 bits (loss 20.260, data 19.343) 
Epoch 4 Iter 200, train entropy gap 0.8208 bits (loss 20.164, data 19.343) 
Epoch 4 Iter 400, train entropy gap 0.7244 bits (loss 20.068, data 19.343) 
Epoch 4 Iter 600, train entropy gap 0.7160 bits (loss 20.059, data 19.343) 
Epoch 4 Iter 800, train entropy gap 0.8629 bits (loss 20.206, data 19.343) 
Epoch 4 Iter 1000, train entropy gap 0.8333 bits (loss 20.177, data 19.343) 
Epoch 4 Iter 1200, train entropy gap 0.8552 bits (loss 20.199, data 19.343) 
Epoch 4 Iter 1400, train entropy gap 0.6305 bits (loss 19.974, data 19.343) 
Epoch 4 Iter 1600, train entropy gap 0.9930 bits (loss 20.336, data 19.343) 
Epoch 4 Iter 1800, train entropy gap 1.0042 bits (loss 20.348, data 19.343) 
Epoch 4 Iter 2000, train entropy gap 0.7941 bits (loss 20.138, data 19.343) 
Epoch 4 Iter 2200, train entropy gap 0.7535 bits (loss 20.097, data 19.343) 
Epoch 4 Iter 2400, train entropy gap 0.9626 bits (loss 20.306, data 19.343) 
Epoch 4 Iter 2600, train entropy gap 0.7098 bits (loss 20.053, data 19.343) 
Epoch 4 Iter 2800, train entropy gap 0.9072 bits (loss 20.251, data 19.343) 
Epoch 4 Iter 3000, train entropy gap 0.8535 bits (loss 20.197, data 19.343) 
Epoch 4 Iter 3200, train entropy gap 0.8956 bits (loss 20.239, data 19.343) 
Epoch 4 Iter 3400, train entropy gap 0.9179 bits (loss 20.261, data 19.343) 
Epoch 4 Iter 3600, train entropy gap 1.2247 bits (loss 20.568, data 19.343) 
Epoch 4 Iter 3800, train entropy gap 0.8186 bits (loss 20.162, data 19.343) 
Epoch 4 Iter 4000, train entropy gap 0.8498 bits (loss 20.193, data 19.343) 
Epoch 4 Iter 4200, train entropy gap 0.8951 bits (loss 20.239, data 19.343) 
Epoch 4 Iter 4400, train entropy gap 1.0430 bits (loss 20.386, data 19.343) 
Epoch 4 Iter 4600, train entropy gap 0.8128 bits (loss 20.156, data 19.343) 
Epoch 4 Iter 4800, train entropy gap 0.9781 bits (loss 20.322, data 19.343) 
Epoch 4 Iter 5000, train entropy gap 0.8005 bits (loss 20.144, data 19.343) 
Epoch 4 Iter 5200, train entropy gap 0.9167 bits (loss 20.260, data 19.343) 
Epoch 4 Iter 5400, train entropy gap 0.7527 bits (loss 20.096, data 19.343) 
Epoch 4 Iter 5600, train entropy gap 0.7284 bits (loss 20.072, data 19.343) 
Epoch 4 Iter 5800, train entropy gap 0.7296 bits (loss 20.073, data 19.343) 
Epoch 4 Iter 6000, train entropy gap 0.8123 bits (loss 20.156, data 19.343) 
Epoch 4 Iter 6200, train entropy gap 1.0223 bits (loss 20.366, data 19.343) 
Epoch 4 Iter 6400, train entropy gap 0.7336 bits (loss 20.077, data 19.343) 
Epoch 4 Iter 6600, train entropy gap 0.9017 bits (loss 20.245, data 19.343) 
Epoch 4 Iter 6800, train entropy gap 0.9864 bits (loss 20.330, data 19.343) 
Epoch 4 Iter 7000, train entropy gap 0.7847 bits (loss 20.128, data 19.343) 
epoch 4 train loss 13.9973 nats / 20.1938 bits
time since start: 649.0 secs
Epoch 5 Iter 0, train entropy gap 0.8645 bits (loss 20.208, data 19.343) 
Epoch 5 Iter 200, train entropy gap 1.1651 bits (loss 20.509, data 19.343) 
Epoch 5 Iter 400, train entropy gap 0.6681 bits (loss 20.012, data 19.343) 
Epoch 5 Iter 600, train entropy gap 0.8908 bits (loss 20.234, data 19.343) 
Epoch 5 Iter 800, train entropy gap 0.7885 bits (loss 20.132, data 19.343) 
Epoch 5 Iter 1000, train entropy gap 1.0919 bits (loss 20.435, data 19.343) 
Epoch 5 Iter 1200, train entropy gap 0.8048 bits (loss 20.148, data 19.343) 
Epoch 5 Iter 1400, train entropy gap 0.6984 bits (loss 20.042, data 19.343) 
Epoch 5 Iter 1600, train entropy gap 0.9192 bits (loss 20.263, data 19.343) 
Epoch 5 Iter 1800, train entropy gap 0.7048 bits (loss 20.048, data 19.343) 
Epoch 5 Iter 2000, train entropy gap 0.8452 bits (loss 20.189, data 19.343) 
Epoch 5 Iter 2200, train entropy gap 0.9225 bits (loss 20.266, data 19.343) 
Epoch 5 Iter 2400, train entropy gap 0.8656 bits (loss 20.209, data 19.343) 
Epoch 5 Iter 2600, train entropy gap 0.9628 bits (loss 20.306, data 19.343) 
Epoch 5 Iter 2800, train entropy gap 0.7363 bits (loss 20.080, data 19.343) 
Epoch 5 Iter 3000, train entropy gap 0.7367 bits (loss 20.080, data 19.343) 
Epoch 5 Iter 3200, train entropy gap 0.8985 bits (loss 20.242, data 19.343) 
Epoch 5 Iter 3400, train entropy gap 1.0001 bits (loss 20.344, data 19.343) 
Epoch 5 Iter 3600, train entropy gap 0.9722 bits (loss 20.316, data 19.343) 
Epoch 5 Iter 3800, train entropy gap 0.7352 bits (loss 20.079, data 19.343) 
Epoch 5 Iter 4000, train entropy gap 0.8660 bits (loss 20.210, data 19.343) 
Epoch 5 Iter 4200, train entropy gap 0.7486 bits (loss 20.092, data 19.343) 
Epoch 5 Iter 4400, train entropy gap 0.6253 bits (loss 19.969, data 19.343) 
Epoch 5 Iter 4600, train entropy gap 0.7505 bits (loss 20.094, data 19.343) 
Epoch 5 Iter 4800, train entropy gap 0.6980 bits (loss 20.041, data 19.343) 
Epoch 5 Iter 5000, train entropy gap 0.9799 bits (loss 20.323, data 19.343) 
Epoch 5 Iter 5200, train entropy gap 0.8150 bits (loss 20.158, data 19.343) 
Epoch 5 Iter 5400, train entropy gap 0.9146 bits (loss 20.258, data 19.343) 
Epoch 5 Iter 5600, train entropy gap 0.8206 bits (loss 20.164, data 19.343) 
Epoch 5 Iter 5800, train entropy gap 0.9400 bits (loss 20.283, data 19.343) 
Epoch 5 Iter 6000, train entropy gap 0.5968 bits (loss 19.940, data 19.343) 
Epoch 5 Iter 6200, train entropy gap 0.8654 bits (loss 20.209, data 19.343) 
Epoch 5 Iter 6400, train entropy gap 0.9997 bits (loss 20.343, data 19.343) 
Epoch 5 Iter 6600, train entropy gap 0.7829 bits (loss 20.126, data 19.343) 
Epoch 5 Iter 6800, train entropy gap 0.8661 bits (loss 20.210, data 19.343) 
Epoch 5 Iter 7000, train entropy gap 0.8034 bits (loss 20.147, data 19.343) 
epoch 5 train loss 13.9934 nats / 20.1881 bits
time since start: 778.6 secs
Epoch 6 Iter 0, train entropy gap 0.7626 bits (loss 20.106, data 19.343) 
Epoch 6 Iter 200, train entropy gap 0.8870 bits (loss 20.230, data 19.343) 
Epoch 6 Iter 400, train entropy gap 0.8366 bits (loss 20.180, data 19.343) 
Epoch 6 Iter 600, train entropy gap 0.9026 bits (loss 20.246, data 19.343) 
Epoch 6 Iter 800, train entropy gap 0.9238 bits (loss 20.267, data 19.343) 
Epoch 6 Iter 1000, train entropy gap 0.8461 bits (loss 20.190, data 19.343) 
Epoch 6 Iter 1200, train entropy gap 0.9671 bits (loss 20.311, data 19.343) 
Epoch 6 Iter 1400, train entropy gap 0.8554 bits (loss 20.199, data 19.343) 
Epoch 6 Iter 1600, train entropy gap 0.6167 bits (loss 19.960, data 19.343) 
Epoch 6 Iter 1800, train entropy gap 0.9311 bits (loss 20.275, data 19.343) 
Epoch 6 Iter 2000, train entropy gap 0.8380 bits (loss 20.181, data 19.343) 
Epoch 6 Iter 2200, train entropy gap 0.9412 bits (loss 20.285, data 19.343) 
Epoch 6 Iter 2400, train entropy gap 0.8513 bits (loss 20.195, data 19.343) 
Epoch 6 Iter 2600, train entropy gap 0.8482 bits (loss 20.192, data 19.343) 
Epoch 6 Iter 2800, train entropy gap 0.9205 bits (loss 20.264, data 19.343) 
Epoch 6 Iter 3000, train entropy gap 0.9302 bits (loss 20.274, data 19.343) 
Epoch 6 Iter 3200, train entropy gap 0.8993 bits (loss 20.243, data 19.343) 
Epoch 6 Iter 3400, train entropy gap 0.9957 bits (loss 20.339, data 19.343) 
Epoch 6 Iter 3600, train entropy gap 0.8673 bits (loss 20.211, data 19.343) 
Epoch 6 Iter 3800, train entropy gap 0.8627 bits (loss 20.206, data 19.343) 
Epoch 6 Iter 4000, train entropy gap 0.5830 bits (loss 19.926, data 19.343) 
Epoch 6 Iter 4200, train entropy gap 0.6810 bits (loss 20.024, data 19.343) 
Epoch 6 Iter 4400, train entropy gap 0.8409 bits (loss 20.184, data 19.343) 
Epoch 6 Iter 4600, train entropy gap 0.7912 bits (loss 20.135, data 19.343) 
Epoch 6 Iter 4800, train entropy gap 0.8875 bits (loss 20.231, data 19.343) 
Epoch 6 Iter 5000, train entropy gap 0.8556 bits (loss 20.199, data 19.343) 
Epoch 6 Iter 5200, train entropy gap 0.5882 bits (loss 19.932, data 19.343) 
Epoch 6 Iter 5400, train entropy gap 0.6567 bits (loss 20.000, data 19.343) 
Epoch 6 Iter 5600, train entropy gap 1.0115 bits (loss 20.355, data 19.343) 
Epoch 6 Iter 5800, train entropy gap 0.6679 bits (loss 20.011, data 19.343) 
Epoch 6 Iter 6000, train entropy gap 0.7751 bits (loss 20.119, data 19.343) 
Epoch 6 Iter 6200, train entropy gap 0.6865 bits (loss 20.030, data 19.343) 
Epoch 6 Iter 6400, train entropy gap 0.8765 bits (loss 20.220, data 19.343) 
Epoch 6 Iter 6600, train entropy gap 0.7243 bits (loss 20.068, data 19.343) 
Epoch 6 Iter 6800, train entropy gap 0.7781 bits (loss 20.122, data 19.343) 
Epoch 6 Iter 7000, train entropy gap 0.9226 bits (loss 20.266, data 19.343) 
epoch 6 train loss 13.9904 nats / 20.1839 bits
time since start: 908.3 secs
Epoch 7 Iter 0, train entropy gap 0.9050 bits (loss 20.248, data 19.343) 
Epoch 7 Iter 200, train entropy gap 0.5259 bits (loss 19.869, data 19.343) 
Epoch 7 Iter 400, train entropy gap 0.8887 bits (loss 20.232, data 19.343) 
Epoch 7 Iter 600, train entropy gap 0.7094 bits (loss 20.053, data 19.343) 
Epoch 7 Iter 800, train entropy gap 0.6586 bits (loss 20.002, data 19.343) 
Epoch 7 Iter 1000, train entropy gap 0.7332 bits (loss 20.077, data 19.343) 
Epoch 7 Iter 1200, train entropy gap 0.8368 bits (loss 20.180, data 19.343) 
Epoch 7 Iter 1400, train entropy gap 0.6284 bits (loss 19.972, data 19.343) 
Epoch 7 Iter 1600, train entropy gap 0.8467 bits (loss 20.190, data 19.343) 
Epoch 7 Iter 1800, train entropy gap 0.7936 bits (loss 20.137, data 19.343) 
Epoch 7 Iter 2000, train entropy gap 0.8627 bits (loss 20.206, data 19.343) 
Epoch 7 Iter 2200, train entropy gap 0.8364 bits (loss 20.180, data 19.343) 
Epoch 7 Iter 2400, train entropy gap 0.9287 bits (loss 20.272, data 19.343) 
Epoch 7 Iter 2600, train entropy gap 0.9162 bits (loss 20.260, data 19.343) 
Epoch 7 Iter 2800, train entropy gap 1.0131 bits (loss 20.357, data 19.343) 
Epoch 7 Iter 3000, train entropy gap 0.9160 bits (loss 20.259, data 19.343) 
Epoch 7 Iter 3200, train entropy gap 0.8515 bits (loss 20.195, data 19.343) 
Epoch 7 Iter 3400, train entropy gap 0.7105 bits (loss 20.054, data 19.343) 
Epoch 7 Iter 3600, train entropy gap 0.8646 bits (loss 20.208, data 19.343) 
Epoch 7 Iter 3800, train entropy gap 1.0542 bits (loss 20.398, data 19.343) 
Epoch 7 Iter 4000, train entropy gap 0.7566 bits (loss 20.100, data 19.343) 
Epoch 7 Iter 4200, train entropy gap 0.8555 bits (loss 20.199, data 19.343) 
Epoch 7 Iter 4400, train entropy gap 0.7998 bits (loss 20.143, data 19.343) 
Epoch 7 Iter 4600, train entropy gap 0.7887 bits (loss 20.132, data 19.343) 
Epoch 7 Iter 4800, train entropy gap 0.8487 bits (loss 20.192, data 19.343) 
Epoch 7 Iter 5000, train entropy gap 0.8898 bits (loss 20.233, data 19.343) 
Epoch 7 Iter 5200, train entropy gap 1.0273 bits (loss 20.371, data 19.343) 
Epoch 7 Iter 5400, train entropy gap 0.7571 bits (loss 20.101, data 19.343) 
Epoch 7 Iter 5600, train entropy gap 0.8218 bits (loss 20.165, data 19.343) 
Epoch 7 Iter 5800, train entropy gap 0.8980 bits (loss 20.241, data 19.343) 
Epoch 7 Iter 6000, train entropy gap 0.6985 bits (loss 20.042, data 19.343) 
Epoch 7 Iter 6200, train entropy gap 1.0511 bits (loss 20.395, data 19.343) 
Epoch 7 Iter 6400, train entropy gap 0.9879 bits (loss 20.331, data 19.343) 
Epoch 7 Iter 6600, train entropy gap 0.8273 bits (loss 20.171, data 19.343) 
Epoch 7 Iter 6800, train entropy gap 0.8565 bits (loss 20.200, data 19.343) 
Epoch 7 Iter 7000, train entropy gap 0.5576 bits (loss 19.901, data 19.343) 
epoch 7 train loss 13.9880 nats / 20.1804 bits
time since start: 1038.1 secs
Epoch 8 Iter 0, train entropy gap 0.8555 bits (loss 20.199, data 19.343) 
Epoch 8 Iter 200, train entropy gap 0.9563 bits (loss 20.300, data 19.343) 
Epoch 8 Iter 400, train entropy gap 0.6877 bits (loss 20.031, data 19.343) 
Epoch 8 Iter 600, train entropy gap 0.8519 bits (loss 20.195, data 19.343) 
Epoch 8 Iter 800, train entropy gap 0.9516 bits (loss 20.295, data 19.343) 
Epoch 8 Iter 1000, train entropy gap 0.5883 bits (loss 19.932, data 19.343) 
Epoch 8 Iter 1200, train entropy gap 0.8410 bits (loss 20.184, data 19.343) 
Epoch 8 Iter 1400, train entropy gap 0.8363 bits (loss 20.180, data 19.343) 
Epoch 8 Iter 1600, train entropy gap 0.6592 bits (loss 20.003, data 19.343) 
Epoch 8 Iter 1800, train entropy gap 0.9734 bits (loss 20.317, data 19.343) 
Epoch 8 Iter 2000, train entropy gap 1.0202 bits (loss 20.364, data 19.343) 
Epoch 8 Iter 2200, train entropy gap 0.5741 bits (loss 19.918, data 19.343) 
Epoch 8 Iter 2400, train entropy gap 0.8593 bits (loss 20.203, data 19.343) 
Epoch 8 Iter 2600, train entropy gap 0.7396 bits (loss 20.083, data 19.343) 
Epoch 8 Iter 2800, train entropy gap 0.7640 bits (loss 20.107, data 19.343) 
Epoch 8 Iter 3000, train entropy gap 0.8045 bits (loss 20.148, data 19.343) 
Epoch 8 Iter 3200, train entropy gap 0.8693 bits (loss 20.213, data 19.343) 
Epoch 8 Iter 3400, train entropy gap 1.0626 bits (loss 20.406, data 19.343) 
Epoch 8 Iter 3600, train entropy gap 0.8121 bits (loss 20.156, data 19.343) 
Epoch 8 Iter 3800, train entropy gap 0.6595 bits (loss 20.003, data 19.343) 
Epoch 8 Iter 4000, train entropy gap 0.8728 bits (loss 20.216, data 19.343) 
Epoch 8 Iter 4200, train entropy gap 0.7875 bits (loss 20.131, data 19.343) 
Epoch 8 Iter 4400, train entropy gap 0.9063 bits (loss 20.250, data 19.343) 
Epoch 8 Iter 4600, train entropy gap 0.7973 bits (loss 20.141, data 19.343) 
Epoch 8 Iter 4800, train entropy gap 0.7411 bits (loss 20.085, data 19.343) 
Epoch 8 Iter 5000, train entropy gap 0.9307 bits (loss 20.274, data 19.343) 
Epoch 8 Iter 5200, train entropy gap 0.9511 bits (loss 20.295, data 19.343) 
Epoch 8 Iter 5400, train entropy gap 0.5357 bits (loss 19.879, data 19.343) 
Epoch 8 Iter 5600, train entropy gap 0.8099 bits (loss 20.153, data 19.343) 
Epoch 8 Iter 5800, train entropy gap 0.7452 bits (loss 20.089, data 19.343) 
Epoch 8 Iter 6000, train entropy gap 0.8912 bits (loss 20.235, data 19.343) 
Epoch 8 Iter 6200, train entropy gap 0.6328 bits (loss 19.976, data 19.343) 
Epoch 8 Iter 6400, train entropy gap 0.9014 bits (loss 20.245, data 19.343) 
Epoch 8 Iter 6600, train entropy gap 1.0664 bits (loss 20.410, data 19.343) 
Epoch 8 Iter 6800, train entropy gap 0.9163 bits (loss 20.260, data 19.343) 
Epoch 8 Iter 7000, train entropy gap 0.7181 bits (loss 20.062, data 19.343) 
epoch 8 train loss 13.9863 nats / 20.1779 bits
time since start: 1167.7 secs
Epoch 9 Iter 0, train entropy gap 0.6422 bits (loss 19.986, data 19.343) 
Epoch 9 Iter 200, train entropy gap 0.9533 bits (loss 20.297, data 19.343) 
Epoch 9 Iter 400, train entropy gap 0.8675 bits (loss 20.211, data 19.343) 
Epoch 9 Iter 600, train entropy gap 0.9114 bits (loss 20.255, data 19.343) 
Epoch 9 Iter 800, train entropy gap 0.8577 bits (loss 20.201, data 19.343) 
Epoch 9 Iter 1000, train entropy gap 0.9340 bits (loss 20.277, data 19.343) 
Epoch 9 Iter 1200, train entropy gap 0.6248 bits (loss 19.968, data 19.343) 
Epoch 9 Iter 1400, train entropy gap 0.6678 bits (loss 20.011, data 19.343) 
Epoch 9 Iter 1600, train entropy gap 0.9165 bits (loss 20.260, data 19.343) 
Epoch 9 Iter 1800, train entropy gap 0.8424 bits (loss 20.186, data 19.343) 
Epoch 9 Iter 2000, train entropy gap 0.7004 bits (loss 20.044, data 19.343) 
Epoch 9 Iter 2200, train entropy gap 0.7330 bits (loss 20.077, data 19.343) 
Epoch 9 Iter 2400, train entropy gap 0.7372 bits (loss 20.081, data 19.343) 
Epoch 9 Iter 2600, train entropy gap 0.9421 bits (loss 20.286, data 19.343) 
Epoch 9 Iter 2800, train entropy gap 0.8548 bits (loss 20.198, data 19.343) 
Epoch 9 Iter 3000, train entropy gap 0.6936 bits (loss 20.037, data 19.343) 
Epoch 9 Iter 3200, train entropy gap 0.8773 bits (loss 20.221, data 19.343) 
Epoch 9 Iter 3400, train entropy gap 0.6051 bits (loss 19.949, data 19.343) 
Epoch 9 Iter 3600, train entropy gap 0.7128 bits (loss 20.056, data 19.343) 
Epoch 9 Iter 3800, train entropy gap 0.8182 bits (loss 20.162, data 19.343) 
Epoch 9 Iter 4000, train entropy gap 0.7868 bits (loss 20.130, data 19.343) 
Epoch 9 Iter 4200, train entropy gap 0.7672 bits (loss 20.111, data 19.343) 
Epoch 9 Iter 4400, train entropy gap 0.8364 bits (loss 20.180, data 19.343) 
Epoch 9 Iter 4600, train entropy gap 0.7104 bits (loss 20.054, data 19.343) 
Epoch 9 Iter 4800, train entropy gap 0.8414 bits (loss 20.185, data 19.343) 
Epoch 9 Iter 5000, train entropy gap 0.8353 bits (loss 20.179, data 19.343) 
Epoch 9 Iter 5200, train entropy gap 0.6598 bits (loss 20.003, data 19.343) 
Epoch 9 Iter 5400, train entropy gap 1.0366 bits (loss 20.380, data 19.343) 
Epoch 9 Iter 5600, train entropy gap 0.7602 bits (loss 20.104, data 19.343) 
Epoch 9 Iter 5800, train entropy gap 0.9736 bits (loss 20.317, data 19.343) 
Epoch 9 Iter 6000, train entropy gap 0.9261 bits (loss 20.270, data 19.343) 
Epoch 9 Iter 6200, train entropy gap 1.0319 bits (loss 20.375, data 19.343) 
Epoch 9 Iter 6400, train entropy gap 0.7058 bits (loss 20.049, data 19.343) 
Epoch 9 Iter 6600, train entropy gap 0.5637 bits (loss 19.907, data 19.343) 
Epoch 9 Iter 6800, train entropy gap 0.6042 bits (loss 19.948, data 19.343) 
Epoch 9 Iter 7000, train entropy gap 0.5743 bits (loss 19.918, data 19.343) 
epoch 9 train loss 13.9845 nats / 20.1754 bits
time since start: 1297.1 secs
Epoch 10 Iter 0, train entropy gap 0.7489 bits (loss 20.092, data 19.343) 
Epoch 10 Iter 200, train entropy gap 0.6960 bits (loss 20.039, data 19.343) 
Epoch 10 Iter 400, train entropy gap 0.9821 bits (loss 20.326, data 19.343) 
Epoch 10 Iter 600, train entropy gap 0.7562 bits (loss 20.100, data 19.343) 
Epoch 10 Iter 800, train entropy gap 0.6875 bits (loss 20.031, data 19.343) 
Epoch 10 Iter 1000, train entropy gap 0.6403 bits (loss 19.984, data 19.343) 
Epoch 10 Iter 1200, train entropy gap 0.7065 bits (loss 20.050, data 19.343) 
Epoch 10 Iter 1400, train entropy gap 0.9525 bits (loss 20.296, data 19.343) 
Epoch 10 Iter 1600, train entropy gap 0.6741 bits (loss 20.018, data 19.343) 
Epoch 10 Iter 1800, train entropy gap 0.7603 bits (loss 20.104, data 19.343) 
Epoch 10 Iter 2000, train entropy gap 1.0488 bits (loss 20.392, data 19.343) 
Epoch 10 Iter 2200, train entropy gap 1.0135 bits (loss 20.357, data 19.343) 
Epoch 10 Iter 2400, train entropy gap 0.7547 bits (loss 20.098, data 19.343) 
Epoch 10 Iter 2600, train entropy gap 0.9292 bits (loss 20.273, data 19.343) 
Epoch 10 Iter 2800, train entropy gap 0.6454 bits (loss 19.989, data 19.343) 
Epoch 10 Iter 3000, train entropy gap 0.8325 bits (loss 20.176, data 19.343) 
Epoch 10 Iter 3200, train entropy gap 0.8287 bits (loss 20.172, data 19.343) 
Epoch 10 Iter 3400, train entropy gap 0.6612 bits (loss 20.005, data 19.343) 
Epoch 10 Iter 3600, train entropy gap 0.9801 bits (loss 20.324, data 19.343) 
Epoch 10 Iter 3800, train entropy gap 0.6547 bits (loss 19.998, data 19.343) 
Epoch 10 Iter 4000, train entropy gap 0.8143 bits (loss 20.158, data 19.343) 
Epoch 10 Iter 4200, train entropy gap 1.0046 bits (loss 20.348, data 19.343) 
Epoch 10 Iter 4400, train entropy gap 0.8017 bits (loss 20.145, data 19.343) 
Epoch 10 Iter 4600, train entropy gap 0.7905 bits (loss 20.134, data 19.343) 
Epoch 10 Iter 4800, train entropy gap 0.6392 bits (loss 19.983, data 19.343) 
Epoch 10 Iter 5000, train entropy gap 0.8839 bits (loss 20.227, data 19.343) 
Epoch 10 Iter 5200, train entropy gap 0.9795 bits (loss 20.323, data 19.343) 
Epoch 10 Iter 5400, train entropy gap 0.8444 bits (loss 20.188, data 19.343) 
Epoch 10 Iter 5600, train entropy gap 0.7407 bits (loss 20.084, data 19.343) 
Epoch 10 Iter 5800, train entropy gap 0.8167 bits (loss 20.160, data 19.343) 
Epoch 10 Iter 6000, train entropy gap 0.6471 bits (loss 19.991, data 19.343) 
Epoch 10 Iter 6200, train entropy gap 1.1255 bits (loss 20.469, data 19.343) 
Epoch 10 Iter 6400, train entropy gap 0.9329 bits (loss 20.276, data 19.343) 
Epoch 10 Iter 6600, train entropy gap 0.7097 bits (loss 20.053, data 19.343) 
Epoch 10 Iter 6800, train entropy gap 0.7295 bits (loss 20.073, data 19.343) 
Epoch 10 Iter 7000, train entropy gap 0.8626 bits (loss 20.206, data 19.343) 
epoch 10 train loss 13.9826 nats / 20.1727 bits
time since start: 1427.4 secs
Epoch 11 Iter 0, train entropy gap 0.7613 bits (loss 20.105, data 19.343) 
Epoch 11 Iter 200, train entropy gap 0.7978 bits (loss 20.141, data 19.343) 
Epoch 11 Iter 400, train entropy gap 0.7969 bits (loss 20.140, data 19.343) 
Epoch 11 Iter 600, train entropy gap 0.8441 bits (loss 20.188, data 19.343) 
Epoch 11 Iter 800, train entropy gap 0.7329 bits (loss 20.076, data 19.343) 
Epoch 11 Iter 1000, train entropy gap 0.6237 bits (loss 19.967, data 19.343) 
Epoch 11 Iter 1200, train entropy gap 0.7870 bits (loss 20.130, data 19.343) 
Epoch 11 Iter 1400, train entropy gap 0.7023 bits (loss 20.046, data 19.343) 
Epoch 11 Iter 1600, train entropy gap 0.9413 bits (loss 20.285, data 19.343) 
Epoch 11 Iter 1800, train entropy gap 0.8752 bits (loss 20.219, data 19.343) 
Epoch 11 Iter 2000, train entropy gap 1.1047 bits (loss 20.448, data 19.343) 
Epoch 11 Iter 2200, train entropy gap 0.6925 bits (loss 20.036, data 19.343) 
Epoch 11 Iter 2400, train entropy gap 0.8313 bits (loss 20.175, data 19.343) 
Epoch 11 Iter 2600, train entropy gap 0.8188 bits (loss 20.162, data 19.343) 
Epoch 11 Iter 2800, train entropy gap 0.8131 bits (loss 20.157, data 19.343) 
Epoch 11 Iter 3000, train entropy gap 0.6802 bits (loss 20.024, data 19.343) 
Epoch 11 Iter 3200, train entropy gap 0.6535 bits (loss 19.997, data 19.343) 
Epoch 11 Iter 3400, train entropy gap 0.9560 bits (loss 20.299, data 19.343) 
Epoch 11 Iter 3600, train entropy gap 0.8132 bits (loss 20.157, data 19.343) 
Epoch 11 Iter 3800, train entropy gap 0.6487 bits (loss 19.992, data 19.343) 
Epoch 11 Iter 4000, train entropy gap 0.9456 bits (loss 20.289, data 19.343) 
Epoch 11 Iter 4200, train entropy gap 0.7465 bits (loss 20.090, data 19.343) 
Epoch 11 Iter 4400, train entropy gap 0.8902 bits (loss 20.234, data 19.343) 
Epoch 11 Iter 4600, train entropy gap 0.8973 bits (loss 20.241, data 19.343) 
Epoch 11 Iter 4800, train entropy gap 0.9616 bits (loss 20.305, data 19.343) 
Epoch 11 Iter 5000, train entropy gap 0.9165 bits (loss 20.260, data 19.343) 
Epoch 11 Iter 5200, train entropy gap 0.9837 bits (loss 20.327, data 19.343) 
Epoch 11 Iter 5400, train entropy gap 0.9212 bits (loss 20.265, data 19.343) 
Epoch 11 Iter 5600, train entropy gap 0.7710 bits (loss 20.114, data 19.343) 
Epoch 11 Iter 5800, train entropy gap 0.9012 bits (loss 20.245, data 19.343) 
Epoch 11 Iter 6000, train entropy gap 0.8983 bits (loss 20.242, data 19.343) 
Epoch 11 Iter 6200, train entropy gap 0.9797 bits (loss 20.323, data 19.343) 
Epoch 11 Iter 6400, train entropy gap 0.9044 bits (loss 20.248, data 19.343) 
Epoch 11 Iter 6600, train entropy gap 0.9665 bits (loss 20.310, data 19.343) 
Epoch 11 Iter 6800, train entropy gap 0.9029 bits (loss 20.246, data 19.343) 
Epoch 11 Iter 7000, train entropy gap 0.8821 bits (loss 20.226, data 19.343) 
epoch 11 train loss 13.9813 nats / 20.1708 bits
time since start: 1557.5 secs
Epoch 12 Iter 0, train entropy gap 0.7243 bits (loss 20.068, data 19.343) 
Epoch 12 Iter 200, train entropy gap 0.8650 bits (loss 20.208, data 19.343) 
Epoch 12 Iter 400, train entropy gap 0.7781 bits (loss 20.122, data 19.343) 
Epoch 12 Iter 600, train entropy gap 0.6025 bits (loss 19.946, data 19.343) 
Epoch 12 Iter 800, train entropy gap 1.0081 bits (loss 20.352, data 19.343) 
Epoch 12 Iter 1000, train entropy gap 0.8437 bits (loss 20.187, data 19.343) 
Epoch 12 Iter 1200, train entropy gap 0.8757 bits (loss 20.219, data 19.343) 
Epoch 12 Iter 1400, train entropy gap 0.7316 bits (loss 20.075, data 19.343) 
Epoch 12 Iter 1600, train entropy gap 0.8286 bits (loss 20.172, data 19.343) 
Epoch 12 Iter 1800, train entropy gap 0.9155 bits (loss 20.259, data 19.343) 
Epoch 12 Iter 2000, train entropy gap 0.8271 bits (loss 20.171, data 19.343) 
Epoch 12 Iter 2200, train entropy gap 0.9450 bits (loss 20.288, data 19.343) 
Epoch 12 Iter 2400, train entropy gap 0.8109 bits (loss 20.154, data 19.343) 
Epoch 12 Iter 2600, train entropy gap 0.9004 bits (loss 20.244, data 19.343) 
Epoch 12 Iter 2800, train entropy gap 0.8579 bits (loss 20.201, data 19.343) 
Epoch 12 Iter 3000, train entropy gap 0.7550 bits (loss 20.098, data 19.343) 
Epoch 12 Iter 3200, train entropy gap 0.7206 bits (loss 20.064, data 19.343) 
Epoch 12 Iter 3400, train entropy gap 0.6817 bits (loss 20.025, data 19.343) 
Epoch 12 Iter 3600, train entropy gap 0.8415 bits (loss 20.185, data 19.343) 
Epoch 12 Iter 3800, train entropy gap 0.8345 bits (loss 20.178, data 19.343) 
Epoch 12 Iter 4000, train entropy gap 0.9106 bits (loss 20.254, data 19.343) 
Epoch 12 Iter 4200, train entropy gap 0.7675 bits (loss 20.111, data 19.343) 
Epoch 12 Iter 4400, train entropy gap 0.7938 bits (loss 20.137, data 19.343) 
Epoch 12 Iter 4600, train entropy gap 0.7323 bits (loss 20.076, data 19.343) 
Epoch 12 Iter 4800, train entropy gap 0.7774 bits (loss 20.121, data 19.343) 
Epoch 12 Iter 5000, train entropy gap 0.8480 bits (loss 20.191, data 19.343) 
Epoch 12 Iter 5200, train entropy gap 0.7344 bits (loss 20.078, data 19.343) 
Epoch 12 Iter 5400, train entropy gap 0.9797 bits (loss 20.323, data 19.343) 
Epoch 12 Iter 5600, train entropy gap 0.8449 bits (loss 20.188, data 19.343) 
Epoch 12 Iter 5800, train entropy gap 0.6479 bits (loss 19.991, data 19.343) 
Epoch 12 Iter 6000, train entropy gap 0.9212 bits (loss 20.265, data 19.343) 
Epoch 12 Iter 6200, train entropy gap 0.8653 bits (loss 20.209, data 19.343) 
Epoch 12 Iter 6400, train entropy gap 0.6718 bits (loss 20.015, data 19.343) 
Epoch 12 Iter 6600, train entropy gap 0.8339 bits (loss 20.177, data 19.343) 
Epoch 12 Iter 6800, train entropy gap 0.9308 bits (loss 20.274, data 19.343) 
Epoch 12 Iter 7000, train entropy gap 0.9032 bits (loss 20.247, data 19.343) 
epoch 12 train loss 13.9804 nats / 20.1695 bits
time since start: 1687.2 secs
Epoch 13 Iter 0, train entropy gap 0.8056 bits (loss 20.149, data 19.343) 
Epoch 13 Iter 200, train entropy gap 0.7965 bits (loss 20.140, data 19.343) 
Epoch 13 Iter 400, train entropy gap 1.0294 bits (loss 20.373, data 19.343) 
Epoch 13 Iter 600, train entropy gap 0.7413 bits (loss 20.085, data 19.343) 
Epoch 13 Iter 800, train entropy gap 0.7385 bits (loss 20.082, data 19.343) 
Epoch 13 Iter 1000, train entropy gap 0.8445 bits (loss 20.188, data 19.343) 
Epoch 13 Iter 1200, train entropy gap 0.6866 bits (loss 20.030, data 19.343) 
Epoch 13 Iter 1400, train entropy gap 0.9826 bits (loss 20.326, data 19.343) 
Epoch 13 Iter 1600, train entropy gap 0.8275 bits (loss 20.171, data 19.343) 
Epoch 13 Iter 1800, train entropy gap 0.7075 bits (loss 20.051, data 19.343) 
Epoch 13 Iter 2000, train entropy gap 0.9001 bits (loss 20.244, data 19.343) 
Epoch 13 Iter 2200, train entropy gap 0.8899 bits (loss 20.233, data 19.343) 
Epoch 13 Iter 2400, train entropy gap 0.6476 bits (loss 19.991, data 19.343) 
Epoch 13 Iter 2600, train entropy gap 0.8365 bits (loss 20.180, data 19.343) 
Epoch 13 Iter 2800, train entropy gap 0.6829 bits (loss 20.026, data 19.343) 
Epoch 13 Iter 3000, train entropy gap 0.8128 bits (loss 20.156, data 19.343) 
Epoch 13 Iter 3200, train entropy gap 1.0644 bits (loss 20.408, data 19.343) 
Epoch 13 Iter 3400, train entropy gap 0.8023 bits (loss 20.146, data 19.343) 
Epoch 13 Iter 3600, train entropy gap 0.8450 bits (loss 20.189, data 19.343) 
Epoch 13 Iter 3800, train entropy gap 0.8078 bits (loss 20.151, data 19.343) 
Epoch 13 Iter 4000, train entropy gap 0.8054 bits (loss 20.149, data 19.343) 
Epoch 13 Iter 4200, train entropy gap 0.8142 bits (loss 20.158, data 19.343) 
Epoch 13 Iter 4400, train entropy gap 0.8707 bits (loss 20.214, data 19.343) 
Epoch 13 Iter 4600, train entropy gap 0.6986 bits (loss 20.042, data 19.343) 
Epoch 13 Iter 4800, train entropy gap 0.7899 bits (loss 20.133, data 19.343) 
Epoch 13 Iter 5000, train entropy gap 0.8284 bits (loss 20.172, data 19.343) 
Epoch 13 Iter 5200, train entropy gap 0.8042 bits (loss 20.148, data 19.343) 
Epoch 13 Iter 5400, train entropy gap 0.9321 bits (loss 20.276, data 19.343) 
Epoch 13 Iter 5600, train entropy gap 0.8000 bits (loss 20.143, data 19.343) 
Epoch 13 Iter 5800, train entropy gap 0.6669 bits (loss 20.010, data 19.343) 
Epoch 13 Iter 6000, train entropy gap 0.9668 bits (loss 20.310, data 19.343) 
Epoch 13 Iter 6200, train entropy gap 0.7600 bits (loss 20.103, data 19.343) 
Epoch 13 Iter 6400, train entropy gap 0.7967 bits (loss 20.140, data 19.343) 
Epoch 13 Iter 6600, train entropy gap 0.8643 bits (loss 20.208, data 19.343) 
Epoch 13 Iter 6800, train entropy gap 0.7283 bits (loss 20.072, data 19.343) 
Epoch 13 Iter 7000, train entropy gap 0.8977 bits (loss 20.241, data 19.343) 
epoch 13 train loss 13.9799 nats / 20.1687 bits
time since start: 1816.8 secs
Epoch 14 Iter 0, train entropy gap 0.9866 bits (loss 20.330, data 19.343) 
Epoch 14 Iter 200, train entropy gap 0.8101 bits (loss 20.154, data 19.343) 
Epoch 14 Iter 400, train entropy gap 0.7225 bits (loss 20.066, data 19.343) 
Epoch 14 Iter 600, train entropy gap 0.7388 bits (loss 20.082, data 19.343) 
Epoch 14 Iter 800, train entropy gap 0.8494 bits (loss 20.193, data 19.343) 
Epoch 14 Iter 1000, train entropy gap 0.8578 bits (loss 20.201, data 19.343) 
Epoch 14 Iter 1200, train entropy gap 0.8897 bits (loss 20.233, data 19.343) 
Epoch 14 Iter 1400, train entropy gap 0.6850 bits (loss 20.028, data 19.343) 
Epoch 14 Iter 1600, train entropy gap 0.9602 bits (loss 20.304, data 19.343) 
Epoch 14 Iter 1800, train entropy gap 0.8334 bits (loss 20.177, data 19.343) 
Epoch 14 Iter 2000, train entropy gap 0.9113 bits (loss 20.255, data 19.343) 
Epoch 14 Iter 2200, train entropy gap 1.1283 bits (loss 20.472, data 19.343) 
Epoch 14 Iter 2400, train entropy gap 0.7271 bits (loss 20.071, data 19.343) 
Epoch 14 Iter 2600, train entropy gap 0.8045 bits (loss 20.148, data 19.343) 
Epoch 14 Iter 2800, train entropy gap 0.8277 bits (loss 20.171, data 19.343) 
Epoch 14 Iter 3000, train entropy gap 0.7646 bits (loss 20.108, data 19.343) 
Epoch 14 Iter 3200, train entropy gap 0.8010 bits (loss 20.144, data 19.343) 
Epoch 14 Iter 3400, train entropy gap 0.7052 bits (loss 20.049, data 19.343) 
Epoch 14 Iter 3600, train entropy gap 0.7487 bits (loss 20.092, data 19.343) 
Epoch 14 Iter 3800, train entropy gap 0.9485 bits (loss 20.292, data 19.343) 
Epoch 14 Iter 4000, train entropy gap 0.6162 bits (loss 19.960, data 19.343) 
Epoch 14 Iter 4200, train entropy gap 0.9125 bits (loss 20.256, data 19.343) 
Epoch 14 Iter 4400, train entropy gap 0.8880 bits (loss 20.231, data 19.343) 
Epoch 14 Iter 4600, train entropy gap 0.9591 bits (loss 20.303, data 19.343) 
Epoch 14 Iter 4800, train entropy gap 0.9683 bits (loss 20.312, data 19.343) 
Epoch 14 Iter 5000, train entropy gap 0.8763 bits (loss 20.220, data 19.343) 
Epoch 14 Iter 5200, train entropy gap 0.7761 bits (loss 20.120, data 19.343) 
Epoch 14 Iter 5400, train entropy gap 0.9319 bits (loss 20.275, data 19.343) 
Epoch 14 Iter 5600, train entropy gap 1.0134 bits (loss 20.357, data 19.343) 
Epoch 14 Iter 5800, train entropy gap 0.8749 bits (loss 20.218, data 19.343) 
Epoch 14 Iter 6000, train entropy gap 0.6310 bits (loss 19.974, data 19.343) 
Epoch 14 Iter 6200, train entropy gap 0.7870 bits (loss 20.130, data 19.343) 
Epoch 14 Iter 6400, train entropy gap 0.8340 bits (loss 20.177, data 19.343) 
Epoch 14 Iter 6600, train entropy gap 0.5547 bits (loss 19.898, data 19.343) 
Epoch 14 Iter 6800, train entropy gap 0.7102 bits (loss 20.054, data 19.343) 
Epoch 14 Iter 7000, train entropy gap 0.9198 bits (loss 20.263, data 19.343) 
epoch 14 train loss 13.9790 nats / 20.1674 bits
time since start: 1947.0 secs
Epoch 15 Iter 0, train entropy gap 0.6002 bits (loss 19.944, data 19.343) 
Epoch 15 Iter 200, train entropy gap 0.8366 bits (loss 20.180, data 19.343) 
Epoch 15 Iter 400, train entropy gap 0.7785 bits (loss 20.122, data 19.343) 
Epoch 15 Iter 600, train entropy gap 0.7380 bits (loss 20.082, data 19.343) 
Epoch 15 Iter 800, train entropy gap 0.8780 bits (loss 20.221, data 19.343) 
Epoch 15 Iter 1000, train entropy gap 0.7792 bits (loss 20.123, data 19.343) 
Epoch 15 Iter 1200, train entropy gap 0.6440 bits (loss 19.988, data 19.343) 
Epoch 15 Iter 1400, train entropy gap 0.7571 bits (loss 20.101, data 19.343) 
Epoch 15 Iter 1600, train entropy gap 0.9401 bits (loss 20.284, data 19.343) 
Epoch 15 Iter 1800, train entropy gap 0.6369 bits (loss 19.980, data 19.343) 
Epoch 15 Iter 2000, train entropy gap 0.7488 bits (loss 20.092, data 19.343) 
Epoch 15 Iter 2200, train entropy gap 0.7616 bits (loss 20.105, data 19.343) 
Epoch 15 Iter 2400, train entropy gap 0.7656 bits (loss 20.109, data 19.343) 
Epoch 15 Iter 2600, train entropy gap 0.7246 bits (loss 20.068, data 19.343) 
Epoch 15 Iter 2800, train entropy gap 0.8383 bits (loss 20.182, data 19.343) 
Epoch 15 Iter 3000, train entropy gap 0.9469 bits (loss 20.290, data 19.343) 
Epoch 15 Iter 3200, train entropy gap 0.7367 bits (loss 20.080, data 19.343) 
Epoch 15 Iter 3400, train entropy gap 0.6961 bits (loss 20.040, data 19.343) 
Epoch 15 Iter 3600, train entropy gap 0.8112 bits (loss 20.155, data 19.343) 
Epoch 15 Iter 3800, train entropy gap 0.8815 bits (loss 20.225, data 19.343) 
Epoch 15 Iter 4000, train entropy gap 0.7803 bits (loss 20.124, data 19.343) 
Epoch 15 Iter 4200, train entropy gap 0.7586 bits (loss 20.102, data 19.343) 
Epoch 15 Iter 4400, train entropy gap 0.9581 bits (loss 20.302, data 19.343) 
Epoch 15 Iter 4600, train entropy gap 0.9316 bits (loss 20.275, data 19.343) 
Epoch 15 Iter 4800, train entropy gap 0.6516 bits (loss 19.995, data 19.343) 
Epoch 15 Iter 5000, train entropy gap 0.7793 bits (loss 20.123, data 19.343) 
Epoch 15 Iter 5200, train entropy gap 0.9810 bits (loss 20.324, data 19.343) 
Epoch 15 Iter 5400, train entropy gap 0.6938 bits (loss 20.037, data 19.343) 
Epoch 15 Iter 5600, train entropy gap 0.8308 bits (loss 20.174, data 19.343) 
Epoch 15 Iter 5800, train entropy gap 0.7597 bits (loss 20.103, data 19.343) 
Epoch 15 Iter 6000, train entropy gap 0.7256 bits (loss 20.069, data 19.343) 
Epoch 15 Iter 6200, train entropy gap 0.9472 bits (loss 20.291, data 19.343) 
Epoch 15 Iter 6400, train entropy gap 0.8490 bits (loss 20.193, data 19.343) 
Epoch 15 Iter 6600, train entropy gap 0.7261 bits (loss 20.070, data 19.343) 
Epoch 15 Iter 6800, train entropy gap 0.8728 bits (loss 20.216, data 19.343) 
Epoch 15 Iter 7000, train entropy gap 0.9009 bits (loss 20.244, data 19.343) 
epoch 15 train loss 13.9768 nats / 20.1642 bits
time since start: 2076.9 secs
Epoch 16 Iter 0, train entropy gap 1.2183 bits (loss 20.562, data 19.343) 
Epoch 16 Iter 200, train entropy gap 0.7093 bits (loss 20.053, data 19.343) 
Epoch 16 Iter 400, train entropy gap 0.8361 bits (loss 20.180, data 19.343) 
Epoch 16 Iter 600, train entropy gap 0.8695 bits (loss 20.213, data 19.343) 
Epoch 16 Iter 800, train entropy gap 0.9134 bits (loss 20.257, data 19.343) 
Epoch 16 Iter 1000, train entropy gap 0.7023 bits (loss 20.046, data 19.343) 
Epoch 16 Iter 1200, train entropy gap 0.9244 bits (loss 20.268, data 19.343) 
Epoch 16 Iter 1400, train entropy gap 0.7848 bits (loss 20.128, data 19.343) 
Epoch 16 Iter 1600, train entropy gap 0.9418 bits (loss 20.285, data 19.343) 
Epoch 16 Iter 1800, train entropy gap 0.9300 bits (loss 20.273, data 19.343) 
Epoch 16 Iter 2000, train entropy gap 0.7005 bits (loss 20.044, data 19.343) 
Epoch 16 Iter 2200, train entropy gap 0.7738 bits (loss 20.117, data 19.343) 
Epoch 16 Iter 2400, train entropy gap 0.9301 bits (loss 20.274, data 19.343) 
Epoch 16 Iter 2600, train entropy gap 0.8135 bits (loss 20.157, data 19.343) 
Epoch 16 Iter 2800, train entropy gap 0.7599 bits (loss 20.103, data 19.343) 
Epoch 16 Iter 3000, train entropy gap 0.7756 bits (loss 20.119, data 19.343) 
Epoch 16 Iter 3200, train entropy gap 0.8255 bits (loss 20.169, data 19.343) 
Epoch 16 Iter 3400, train entropy gap 0.8508 bits (loss 20.194, data 19.343) 
Epoch 16 Iter 3600, train entropy gap 0.8257 bits (loss 20.169, data 19.343) 
Epoch 16 Iter 3800, train entropy gap 0.8583 bits (loss 20.202, data 19.343) 
Epoch 16 Iter 4000, train entropy gap 0.7354 bits (loss 20.079, data 19.343) 
Epoch 16 Iter 4200, train entropy gap 0.5939 bits (loss 19.937, data 19.343) 
Epoch 16 Iter 4400, train entropy gap 0.8079 bits (loss 20.151, data 19.343) 
Epoch 16 Iter 4600, train entropy gap 0.6678 bits (loss 20.011, data 19.343) 
Epoch 16 Iter 4800, train entropy gap 0.7497 bits (loss 20.093, data 19.343) 
Epoch 16 Iter 5000, train entropy gap 0.8775 bits (loss 20.221, data 19.343) 
Epoch 16 Iter 5200, train entropy gap 0.9277 bits (loss 20.271, data 19.343) 
Epoch 16 Iter 5400, train entropy gap 0.8822 bits (loss 20.226, data 19.343) 
Epoch 16 Iter 5600, train entropy gap 0.7291 bits (loss 20.073, data 19.343) 
Epoch 16 Iter 5800, train entropy gap 0.7940 bits (loss 20.137, data 19.343) 
Epoch 16 Iter 6000, train entropy gap 0.7649 bits (loss 20.108, data 19.343) 
Epoch 16 Iter 6200, train entropy gap 0.5160 bits (loss 19.859, data 19.343) 
Epoch 16 Iter 6400, train entropy gap 0.8264 bits (loss 20.170, data 19.343) 
Epoch 16 Iter 6600, train entropy gap 0.8370 bits (loss 20.180, data 19.343) 
Epoch 16 Iter 6800, train entropy gap 0.9826 bits (loss 20.326, data 19.343) 
Epoch 16 Iter 7000, train entropy gap 1.0572 bits (loss 20.401, data 19.343) 
epoch 16 train loss 13.9753 nats / 20.1621 bits
time since start: 2206.6 secs
Epoch 17 Iter 0, train entropy gap 0.7555 bits (loss 20.099, data 19.343) 
Epoch 17 Iter 200, train entropy gap 0.8788 bits (loss 20.222, data 19.343) 
Epoch 17 Iter 400, train entropy gap 0.6614 bits (loss 20.005, data 19.343) 
Epoch 17 Iter 600, train entropy gap 0.7947 bits (loss 20.138, data 19.343) 
Epoch 17 Iter 800, train entropy gap 0.8507 bits (loss 20.194, data 19.343) 
Epoch 17 Iter 1000, train entropy gap 0.8768 bits (loss 20.220, data 19.343) 
Epoch 17 Iter 1200, train entropy gap 0.7221 bits (loss 20.066, data 19.343) 
Epoch 17 Iter 1400, train entropy gap 1.1375 bits (loss 20.481, data 19.343) 
Epoch 17 Iter 1600, train entropy gap 0.7490 bits (loss 20.092, data 19.343) 
Epoch 17 Iter 1800, train entropy gap 0.7701 bits (loss 20.114, data 19.343) 
Epoch 17 Iter 2000, train entropy gap 0.9403 bits (loss 20.284, data 19.343) 
Epoch 17 Iter 2200, train entropy gap 0.9292 bits (loss 20.273, data 19.343) 
Epoch 17 Iter 2400, train entropy gap 0.6925 bits (loss 20.036, data 19.343) 
Epoch 17 Iter 2600, train entropy gap 0.8335 bits (loss 20.177, data 19.343) 
Epoch 17 Iter 2800, train entropy gap 0.7399 bits (loss 20.083, data 19.343) 
Epoch 17 Iter 3000, train entropy gap 0.9298 bits (loss 20.273, data 19.343) 
Epoch 17 Iter 3200, train entropy gap 0.8524 bits (loss 20.196, data 19.343) 
Epoch 17 Iter 3400, train entropy gap 0.9669 bits (loss 20.310, data 19.343) 
Epoch 17 Iter 3600, train entropy gap 0.9216 bits (loss 20.265, data 19.343) 
Epoch 17 Iter 3800, train entropy gap 0.7869 bits (loss 20.130, data 19.343) 
Epoch 17 Iter 4000, train entropy gap 0.9435 bits (loss 20.287, data 19.343) 
Epoch 17 Iter 4200, train entropy gap 0.8246 bits (loss 20.168, data 19.343) 
Epoch 17 Iter 4400, train entropy gap 0.8418 bits (loss 20.185, data 19.343) 
Epoch 17 Iter 4600, train entropy gap 1.0131 bits (loss 20.357, data 19.343) 
Epoch 17 Iter 4800, train entropy gap 0.6643 bits (loss 20.008, data 19.343) 
Epoch 17 Iter 5000, train entropy gap 0.8536 bits (loss 20.197, data 19.343) 
Epoch 17 Iter 5200, train entropy gap 0.8875 bits (loss 20.231, data 19.343) 
Epoch 17 Iter 5400, train entropy gap 0.9466 bits (loss 20.290, data 19.343) 
Epoch 17 Iter 5600, train entropy gap 0.7352 bits (loss 20.079, data 19.343) 
Epoch 17 Iter 5800, train entropy gap 0.9671 bits (loss 20.311, data 19.343) 
Epoch 17 Iter 6000, train entropy gap 0.6048 bits (loss 19.948, data 19.343) 
Epoch 17 Iter 6200, train entropy gap 0.6820 bits (loss 20.025, data 19.343) 
Epoch 17 Iter 6400, train entropy gap 0.7724 bits (loss 20.116, data 19.343) 
Epoch 17 Iter 6600, train entropy gap 0.7914 bits (loss 20.135, data 19.343) 
Epoch 17 Iter 6800, train entropy gap 0.8765 bits (loss 20.220, data 19.343) 
Epoch 17 Iter 7000, train entropy gap 0.7182 bits (loss 20.062, data 19.343) 
epoch 17 train loss 13.9743 nats / 20.1607 bits
time since start: 2336.6 secs
Epoch 18 Iter 0, train entropy gap 0.9755 bits (loss 20.319, data 19.343) 
Epoch 18 Iter 200, train entropy gap 0.9126 bits (loss 20.256, data 19.343) 
Epoch 18 Iter 400, train entropy gap 0.8986 bits (loss 20.242, data 19.343) 
Epoch 18 Iter 600, train entropy gap 0.8374 bits (loss 20.181, data 19.343) 
Epoch 18 Iter 800, train entropy gap 0.6448 bits (loss 19.988, data 19.343) 
Epoch 18 Iter 1000, train entropy gap 0.6626 bits (loss 20.006, data 19.343) 
Epoch 18 Iter 1200, train entropy gap 0.9436 bits (loss 20.287, data 19.343) 
Epoch 18 Iter 1400, train entropy gap 0.8918 bits (loss 20.235, data 19.343) 
Epoch 18 Iter 1600, train entropy gap 0.9041 bits (loss 20.248, data 19.343) 
Epoch 18 Iter 1800, train entropy gap 0.8510 bits (loss 20.194, data 19.343) 
Epoch 18 Iter 2000, train entropy gap 0.7893 bits (loss 20.133, data 19.343) 
Epoch 18 Iter 2200, train entropy gap 0.8317 bits (loss 20.175, data 19.343) 
Epoch 18 Iter 2400, train entropy gap 0.9505 bits (loss 20.294, data 19.343) 
Epoch 18 Iter 2600, train entropy gap 0.8476 bits (loss 20.191, data 19.343) 
Epoch 18 Iter 2800, train entropy gap 1.0664 bits (loss 20.410, data 19.343) 
Epoch 18 Iter 3000, train entropy gap 0.9052 bits (loss 20.249, data 19.343) 
Epoch 18 Iter 3200, train entropy gap 0.8369 bits (loss 20.180, data 19.343) 
Epoch 18 Iter 3400, train entropy gap 0.4431 bits (loss 19.787, data 19.343) 
Epoch 18 Iter 3600, train entropy gap 0.8965 bits (loss 20.240, data 19.343) 
Epoch 18 Iter 3800, train entropy gap 0.8017 bits (loss 20.145, data 19.343) 
Epoch 18 Iter 4000, train entropy gap 1.0393 bits (loss 20.383, data 19.343) 
Epoch 18 Iter 4200, train entropy gap 0.8437 bits (loss 20.187, data 19.343) 
Epoch 18 Iter 4400, train entropy gap 0.7276 bits (loss 20.071, data 19.343) 
Epoch 18 Iter 4600, train entropy gap 0.7758 bits (loss 20.119, data 19.343) 
Epoch 18 Iter 4800, train entropy gap 0.7788 bits (loss 20.122, data 19.343) 
Epoch 18 Iter 5000, train entropy gap 0.6600 bits (loss 20.004, data 19.343) 
Epoch 18 Iter 5200, train entropy gap 0.6761 bits (loss 20.020, data 19.343) 
Epoch 18 Iter 5400, train entropy gap 0.7674 bits (loss 20.111, data 19.343) 
Epoch 18 Iter 5600, train entropy gap 0.7131 bits (loss 20.057, data 19.343) 
Epoch 18 Iter 5800, train entropy gap 0.7870 bits (loss 20.130, data 19.343) 
Epoch 18 Iter 6000, train entropy gap 0.7497 bits (loss 20.093, data 19.343) 
Epoch 18 Iter 6200, train entropy gap 0.6919 bits (loss 20.035, data 19.343) 
Epoch 18 Iter 6400, train entropy gap 0.9510 bits (loss 20.294, data 19.343) 
Epoch 18 Iter 6600, train entropy gap 0.8327 bits (loss 20.176, data 19.343) 
Epoch 18 Iter 6800, train entropy gap 0.7309 bits (loss 20.074, data 19.343) 
Epoch 18 Iter 7000, train entropy gap 0.7129 bits (loss 20.056, data 19.343) 
epoch 18 train loss 13.9737 nats / 20.1597 bits
time since start: 2466.1 secs
Epoch 19 Iter 0, train entropy gap 0.6902 bits (loss 20.034, data 19.343) 
Epoch 19 Iter 200, train entropy gap 0.8327 bits (loss 20.176, data 19.343) 
Epoch 19 Iter 400, train entropy gap 0.9273 bits (loss 20.271, data 19.343) 
Epoch 19 Iter 600, train entropy gap 0.8972 bits (loss 20.241, data 19.343) 
Epoch 19 Iter 800, train entropy gap 0.8105 bits (loss 20.154, data 19.343) 
Epoch 19 Iter 1000, train entropy gap 0.8566 bits (loss 20.200, data 19.343) 
Epoch 19 Iter 1200, train entropy gap 0.8665 bits (loss 20.210, data 19.343) 
Epoch 19 Iter 1400, train entropy gap 0.8105 bits (loss 20.154, data 19.343) 
Epoch 19 Iter 1600, train entropy gap 0.7885 bits (loss 20.132, data 19.343) 
Epoch 19 Iter 1800, train entropy gap 0.8864 bits (loss 20.230, data 19.343) 
Epoch 19 Iter 2000, train entropy gap 0.9463 bits (loss 20.290, data 19.343) 
Epoch 19 Iter 2200, train entropy gap 0.8686 bits (loss 20.212, data 19.343) 
Epoch 19 Iter 2400, train entropy gap 0.8399 bits (loss 20.183, data 19.343) 
Epoch 19 Iter 2600, train entropy gap 0.7672 bits (loss 20.111, data 19.343) 
Epoch 19 Iter 2800, train entropy gap 0.9762 bits (loss 20.320, data 19.343) 
Epoch 19 Iter 3000, train entropy gap 1.1192 bits (loss 20.463, data 19.343) 
Epoch 19 Iter 3200, train entropy gap 0.7586 bits (loss 20.102, data 19.343) 
Epoch 19 Iter 3400, train entropy gap 0.9405 bits (loss 20.284, data 19.343) 
Epoch 19 Iter 3600, train entropy gap 0.7851 bits (loss 20.129, data 19.343) 
Epoch 19 Iter 3800, train entropy gap 0.6889 bits (loss 20.032, data 19.343) 
Epoch 19 Iter 4000, train entropy gap 0.7077 bits (loss 20.051, data 19.343) 
Epoch 19 Iter 4200, train entropy gap 1.0089 bits (loss 20.352, data 19.343) 
Epoch 19 Iter 4400, train entropy gap 0.9081 bits (loss 20.252, data 19.343) 
Epoch 19 Iter 4600, train entropy gap 0.7796 bits (loss 20.123, data 19.343) 
Epoch 19 Iter 4800, train entropy gap 0.7527 bits (loss 20.096, data 19.343) 
Epoch 19 Iter 5000, train entropy gap 0.7288 bits (loss 20.072, data 19.343) 
Epoch 19 Iter 5200, train entropy gap 0.7412 bits (loss 20.085, data 19.343) 
Epoch 19 Iter 5400, train entropy gap 0.7872 bits (loss 20.131, data 19.343) 
Epoch 19 Iter 5600, train entropy gap 0.6679 bits (loss 20.011, data 19.343) 
Epoch 19 Iter 5800, train entropy gap 0.7058 bits (loss 20.049, data 19.343) 
Epoch 19 Iter 6000, train entropy gap 0.8069 bits (loss 20.150, data 19.343) 
Epoch 19 Iter 6200, train entropy gap 0.6520 bits (loss 19.995, data 19.343) 
Epoch 19 Iter 6400, train entropy gap 0.7991 bits (loss 20.143, data 19.343) 
Epoch 19 Iter 6600, train entropy gap 0.8573 bits (loss 20.201, data 19.343) 
Epoch 19 Iter 6800, train entropy gap 0.7652 bits (loss 20.109, data 19.343) 
Epoch 19 Iter 7000, train entropy gap 0.8679 bits (loss 20.211, data 19.343) 
epoch 19 train loss 13.9731 nats / 20.1590 bits
time since start: 2595.7 secs
Training done; evaluating likelihood on full data:
Epoch None Iter 0, test loss 17.4866 nats / 25.2279 bits
Epoch None Iter 500, test loss 15.0209 nats / 21.6706 bits
Epoch None Iter 1000, test loss 13.1811 nats / 19.0163 bits
Epoch None Iter 1500, test loss 12.5666 nats / 18.1298 bits
Epoch None Iter 2000, test loss 13.4097 nats / 19.3461 bits
Epoch None Iter 2500, test loss 12.3940 nats / 17.8808 bits
Epoch None Iter 3000, test loss 15.4490 nats / 22.2882 bits
Epoch None Iter 3500, test loss 12.9533 nats / 18.6877 bits
Epoch None Iter 4000, test loss 12.5799 nats / 18.1489 bits
Epoch None Iter 4500, test loss 13.6440 nats / 19.6841 bits
Epoch None Iter 5000, test loss 12.7038 nats / 18.3277 bits
Epoch None Iter 5500, test loss 15.5525 nats / 22.4376 bits
Epoch None Iter 6000, test loss 14.0258 nats / 20.2349 bits
Epoch None Iter 6500, test loss 13.0285 nats / 18.7961 bits
Epoch None Iter 7000, test loss 16.8295 nats / 24.2798 bits
Saved to:
models/dmv-ofnan-2.1MB-model20.151-data19.343-flash-blocks1-embed_dim128-expansion_factor2.0-group_size128-posEmb-20epochs-seed0.pt
