Device cuda
Loading csv... done, took 6.3s
Parsing... done, took 5.1s
Entropy of DMV([Column(Record Type, distribution_size=8), Column(Registration Class, distribution_size=72), Column(State, distribution_size=79), Column(County, distribution_size=64), Column(Body Type, distribution_size=59), Column(Fuel Type, distribution_size=10), Column(Reg Valid Date, distribution_size=2884), Column(Color, distribution_size=222), Column(Scofflaw Indicator, distribution_size=3), Column(Suspension Indicator, distribution_size=3), Column(Revocation Indicator, distribution_size=3)]): 19.3808 bits
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7389597 entries, 0 to 7389596
Data columns (total 11 columns):
 #   Column                Dtype         
---  ------                -----         
 0   Record Type           object        
 1   Registration Class    object        
 2   State                 object        
 3   County                object        
 4   Body Type             object        
 5   Fuel Type             object        
 6   Reg Valid Date        datetime64[ns]
 7   Color                 object        
 8   Scofflaw Indicator    object        
 9   Suspension Indicator  object        
 10  Revocation Indicator  object        
dtypes: datetime64[ns](1), object(10)
memory usage: 620.2+ MB
None
ordering [ 0  1  2  3  4  5  6  7  8  9 10]
Number of model parameters: 4303128 (~= 16.4MB)
FLASHTransformer(
  (layers): Sequential(
    (0): FLASH(
      (attn_fn): ReLUSquared()
      (rotary_pos_emb): RotaryEmbedding()
      (rel_pos_bias): T5RelativePositionBias(
        (relative_attention_bias): Embedding(32, 1)
      )
      (norm): ScaleNorm()
      (dropout): Dropout(p=0.0, inplace=False)
      (to_hidden): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): SiLU()
      )
      (to_qk): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): SiLU()
      )
      (qk_offset_scale): OffsetScale()
      (to_out): Linear(in_features=512, out_features=256, bias=True)
    )
    (1): FLASH(
      (attn_fn): ReLUSquared()
      (rotary_pos_emb): RotaryEmbedding()
      (rel_pos_bias): T5RelativePositionBias(
        (relative_attention_bias): Embedding(32, 1)
      )
      (norm): ScaleNorm()
      (dropout): Dropout(p=0.0, inplace=False)
      (to_hidden): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): SiLU()
      )
      (to_qk): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): SiLU()
      )
      (qk_offset_scale): OffsetScale()
      (to_out): Linear(in_features=512, out_features=256, bias=True)
    )
    (2): FLASH(
      (attn_fn): ReLUSquared()
      (rotary_pos_emb): RotaryEmbedding()
      (rel_pos_bias): T5RelativePositionBias(
        (relative_attention_bias): Embedding(32, 1)
      )
      (norm): ScaleNorm()
      (dropout): Dropout(p=0.0, inplace=False)
      (to_hidden): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): SiLU()
      )
      (to_qk): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): SiLU()
      )
      (qk_offset_scale): OffsetScale()
      (to_out): Linear(in_features=512, out_features=256, bias=True)
    )
    (3): FLASH(
      (attn_fn): ReLUSquared()
      (rotary_pos_emb): RotaryEmbedding()
      (rel_pos_bias): T5RelativePositionBias(
        (relative_attention_bias): Embedding(32, 1)
      )
      (norm): ScaleNorm()
      (dropout): Dropout(p=0.0, inplace=False)
      (to_hidden): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): SiLU()
      )
      (to_qk): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): SiLU()
      )
      (qk_offset_scale): OffsetScale()
      (to_out): Linear(in_features=512, out_features=256, bias=True)
    )
    (4): FLASH(
      (attn_fn): ReLUSquared()
      (rotary_pos_emb): RotaryEmbedding()
      (rel_pos_bias): T5RelativePositionBias(
        (relative_attention_bias): Embedding(32, 1)
      )
      (norm): ScaleNorm()
      (dropout): Dropout(p=0.0, inplace=False)
      (to_hidden): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): SiLU()
      )
      (to_qk): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): SiLU()
      )
      (qk_offset_scale): OffsetScale()
      (to_out): Linear(in_features=512, out_features=256, bias=True)
    )
    (5): FLASH(
      (attn_fn): ReLUSquared()
      (rotary_pos_emb): RotaryEmbedding()
      (rel_pos_bias): T5RelativePositionBias(
        (relative_attention_bias): Embedding(32, 1)
      )
      (norm): ScaleNorm()
      (dropout): Dropout(p=0.0, inplace=False)
      (to_hidden): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): SiLU()
      )
      (to_qk): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): SiLU()
      )
      (qk_offset_scale): OffsetScale()
      (to_out): Linear(in_features=512, out_features=256, bias=True)
    )
    (6): FLASH(
      (attn_fn): ReLUSquared()
      (rotary_pos_emb): RotaryEmbedding()
      (rel_pos_bias): T5RelativePositionBias(
        (relative_attention_bias): Embedding(32, 1)
      )
      (norm): ScaleNorm()
      (dropout): Dropout(p=0.0, inplace=False)
      (to_hidden): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): SiLU()
      )
      (to_qk): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): SiLU()
      )
      (qk_offset_scale): OffsetScale()
      (to_out): Linear(in_features=512, out_features=256, bias=True)
    )
    (7): FLASH(
      (attn_fn): ReLUSquared()
      (rotary_pos_emb): RotaryEmbedding()
      (rel_pos_bias): T5RelativePositionBias(
        (relative_attention_bias): Embedding(32, 1)
      )
      (norm): ScaleNorm()
      (dropout): Dropout(p=0.0, inplace=False)
      (to_hidden): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=True)
        (1): SiLU()
      )
      (to_qk): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): SiLU()
      )
      (qk_offset_scale): OffsetScale()
      (to_out): Linear(in_features=512, out_features=256, bias=True)
    )
  )
  (to_logits): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (embeddings): ModuleList(
    (0): Embedding(8, 256)
    (1): Embedding(72, 256)
    (2): Embedding(79, 256)
    (3): Embedding(64, 256)
    (4): Embedding(59, 256)
    (5): Embedding(10, 256)
    (6): Embedding(2884, 256)
    (7): Embedding(222, 256)
    (8): Embedding(3, 256)
    (9): Embedding(3, 256)
    (10): Embedding(3, 256)
  )
  (pos_embeddings): Embedding(11, 256)
)
Discretizing table... done, took 4.9s
Epoch 0 Iter 0, train entropy gap 35.8477 bits (loss 55.229, data 19.381) 
Epoch 0 Iter 200, train entropy gap 18.0676 bits (loss 37.448, data 19.381) 
Epoch 0 Iter 400, train entropy gap 6.6914 bits (loss 26.072, data 19.381) 
Epoch 0 Iter 600, train entropy gap 3.2657 bits (loss 22.647, data 19.381) 
Epoch 0 Iter 800, train entropy gap 1.9838 bits (loss 21.365, data 19.381) 
Epoch 0 Iter 1000, train entropy gap 1.4319 bits (loss 20.813, data 19.381) 
Epoch 0 Iter 1200, train entropy gap 1.3034 bits (loss 20.684, data 19.381) 
Epoch 0 Iter 1400, train entropy gap 1.1687 bits (loss 20.549, data 19.381) 
Epoch 0 Iter 1600, train entropy gap 1.1272 bits (loss 20.508, data 19.381) 
Epoch 0 Iter 1800, train entropy gap 1.1816 bits (loss 20.562, data 19.381) 
Epoch 0 Iter 2000, train entropy gap 1.1644 bits (loss 20.545, data 19.381) 
Epoch 0 Iter 2200, train entropy gap 0.9541 bits (loss 20.335, data 19.381) 
Epoch 0 Iter 2400, train entropy gap 1.0566 bits (loss 20.437, data 19.381) 
Epoch 0 Iter 2600, train entropy gap 0.8793 bits (loss 20.260, data 19.381) 
Epoch 0 Iter 2800, train entropy gap 0.9580 bits (loss 20.339, data 19.381) 
Epoch 0 Iter 3000, train entropy gap 1.2219 bits (loss 20.603, data 19.381) 
Epoch 0 Iter 3200, train entropy gap 1.0841 bits (loss 20.465, data 19.381) 
Epoch 0 Iter 3400, train entropy gap 0.9643 bits (loss 20.345, data 19.381) 
Epoch 0 Iter 3600, train entropy gap 0.9632 bits (loss 20.344, data 19.381) 
Epoch 0 Iter 3800, train entropy gap 0.8383 bits (loss 20.219, data 19.381) 
Epoch 0 Iter 4000, train entropy gap 1.0107 bits (loss 20.391, data 19.381) 
Epoch 0 Iter 4200, train entropy gap 0.9456 bits (loss 20.326, data 19.381) 
Epoch 0 Iter 4400, train entropy gap 1.1527 bits (loss 20.534, data 19.381) 
Epoch 0 Iter 4600, train entropy gap 1.0630 bits (loss 20.444, data 19.381) 
Epoch 0 Iter 4800, train entropy gap 1.0280 bits (loss 20.409, data 19.381) 
Epoch 0 Iter 5000, train entropy gap 0.9544 bits (loss 20.335, data 19.381) 
Epoch 0 Iter 5200, train entropy gap 1.0997 bits (loss 20.481, data 19.381) 
Epoch 0 Iter 5400, train entropy gap 0.9856 bits (loss 20.366, data 19.381) 
Epoch 0 Iter 5600, train entropy gap 0.8970 bits (loss 20.278, data 19.381) 
Epoch 0 Iter 5800, train entropy gap 0.9188 bits (loss 20.300, data 19.381) 
Epoch 0 Iter 6000, train entropy gap 0.9643 bits (loss 20.345, data 19.381) 
Epoch 0 Iter 6200, train entropy gap 0.8451 bits (loss 20.226, data 19.381) 
Epoch 0 Iter 6400, train entropy gap 0.8299 bits (loss 20.211, data 19.381) 
Epoch 0 Iter 6600, train entropy gap 0.8064 bits (loss 20.187, data 19.381) 
Epoch 0 Iter 6800, train entropy gap 0.9317 bits (loss 20.312, data 19.381) 
Epoch 0 Iter 7000, train entropy gap 0.8376 bits (loss 20.218, data 19.381) 
Epoch 0 Iter 7200, train entropy gap 0.8520 bits (loss 20.233, data 19.381) 
epoch 0 train loss 14.9664 nats / 21.5920 bits
time since start: 1431.4 secs
Epoch 1 Iter 0, train entropy gap 1.0226 bits (loss 20.403, data 19.381) 
Epoch 1 Iter 200, train entropy gap 0.7807 bits (loss 20.162, data 19.381) 
Epoch 1 Iter 400, train entropy gap 0.9285 bits (loss 20.309, data 19.381) 
Epoch 1 Iter 600, train entropy gap 0.7678 bits (loss 20.149, data 19.381) 
Epoch 1 Iter 800, train entropy gap 0.9472 bits (loss 20.328, data 19.381) 
Epoch 1 Iter 1000, train entropy gap 0.6930 bits (loss 20.074, data 19.381) 
Epoch 1 Iter 1200, train entropy gap 0.8515 bits (loss 20.232, data 19.381) 
Epoch 1 Iter 1400, train entropy gap 0.7777 bits (loss 20.159, data 19.381) 
Epoch 1 Iter 1600, train entropy gap 0.8939 bits (loss 20.275, data 19.381) 
Epoch 1 Iter 1800, train entropy gap 0.9424 bits (loss 20.323, data 19.381) 
Epoch 1 Iter 2000, train entropy gap 0.8670 bits (loss 20.248, data 19.381) 
Epoch 1 Iter 2200, train entropy gap 0.9629 bits (loss 20.344, data 19.381) 
Epoch 1 Iter 2400, train entropy gap 1.0397 bits (loss 20.421, data 19.381) 
Epoch 1 Iter 2600, train entropy gap 0.6061 bits (loss 19.987, data 19.381) 
Epoch 1 Iter 2800, train entropy gap 1.1058 bits (loss 20.487, data 19.381) 
Epoch 1 Iter 3000, train entropy gap 0.9343 bits (loss 20.315, data 19.381) 
Epoch 1 Iter 3200, train entropy gap 1.1112 bits (loss 20.492, data 19.381) 
Epoch 1 Iter 3400, train entropy gap 0.8941 bits (loss 20.275, data 19.381) 
Epoch 1 Iter 3600, train entropy gap 0.9504 bits (loss 20.331, data 19.381) 
Epoch 1 Iter 3800, train entropy gap 0.8312 bits (loss 20.212, data 19.381) 
Epoch 1 Iter 4000, train entropy gap 0.9169 bits (loss 20.298, data 19.381) 
Epoch 1 Iter 4200, train entropy gap 1.0788 bits (loss 20.460, data 19.381) 
Epoch 1 Iter 4400, train entropy gap 0.8512 bits (loss 20.232, data 19.381) 
Epoch 1 Iter 4600, train entropy gap 1.0402 bits (loss 20.421, data 19.381) 
Epoch 1 Iter 4800, train entropy gap 0.5441 bits (loss 19.925, data 19.381) 
Epoch 1 Iter 5000, train entropy gap 0.9888 bits (loss 20.370, data 19.381) 
Epoch 1 Iter 5200, train entropy gap 0.8400 bits (loss 20.221, data 19.381) 
Epoch 1 Iter 5400, train entropy gap 0.6797 bits (loss 20.060, data 19.381) 
Epoch 1 Iter 5600, train entropy gap 0.9224 bits (loss 20.303, data 19.381) 
Epoch 1 Iter 5800, train entropy gap 0.7841 bits (loss 20.165, data 19.381) 
Epoch 1 Iter 6000, train entropy gap 1.0338 bits (loss 20.415, data 19.381) 
Epoch 1 Iter 6200, train entropy gap 0.8824 bits (loss 20.263, data 19.381) 
Epoch 1 Iter 6400, train entropy gap 0.8714 bits (loss 20.252, data 19.381) 
Epoch 1 Iter 6600, train entropy gap 0.8444 bits (loss 20.225, data 19.381) 
Epoch 1 Iter 6800, train entropy gap 0.8921 bits (loss 20.273, data 19.381) 
Epoch 1 Iter 7000, train entropy gap 0.8062 bits (loss 20.187, data 19.381) 
Epoch 1 Iter 7200, train entropy gap 0.9232 bits (loss 20.304, data 19.381) 
epoch 1 train loss 14.0322 nats / 20.2442 bits
time since start: 2862.3 secs
Epoch 2 Iter 0, train entropy gap 0.7496 bits (loss 20.130, data 19.381) 
Epoch 2 Iter 200, train entropy gap 0.8855 bits (loss 20.266, data 19.381) 
Epoch 2 Iter 400, train entropy gap 0.9682 bits (loss 20.349, data 19.381) 
Epoch 2 Iter 600, train entropy gap 0.8607 bits (loss 20.242, data 19.381) 
Epoch 2 Iter 800, train entropy gap 0.7505 bits (loss 20.131, data 19.381) 
Epoch 2 Iter 1000, train entropy gap 0.8303 bits (loss 20.211, data 19.381) 
Epoch 2 Iter 1200, train entropy gap 0.7370 bits (loss 20.118, data 19.381) 
Epoch 2 Iter 1400, train entropy gap 1.0181 bits (loss 20.399, data 19.381) 
Epoch 2 Iter 1600, train entropy gap 0.8511 bits (loss 20.232, data 19.381) 
Epoch 2 Iter 1800, train entropy gap 0.5789 bits (loss 19.960, data 19.381) 
Epoch 2 Iter 2000, train entropy gap 0.9440 bits (loss 20.325, data 19.381) 
Epoch 2 Iter 2200, train entropy gap 0.9324 bits (loss 20.313, data 19.381) 
Epoch 2 Iter 2400, train entropy gap 0.6378 bits (loss 20.019, data 19.381) 
Epoch 2 Iter 2600, train entropy gap 0.7326 bits (loss 20.113, data 19.381) 
Epoch 2 Iter 2800, train entropy gap 0.8030 bits (loss 20.184, data 19.381) 
Epoch 2 Iter 3000, train entropy gap 0.8655 bits (loss 20.246, data 19.381) 
Epoch 2 Iter 3200, train entropy gap 0.7893 bits (loss 20.170, data 19.381) 
Epoch 2 Iter 3400, train entropy gap 0.6814 bits (loss 20.062, data 19.381) 
Epoch 2 Iter 3600, train entropy gap 0.9105 bits (loss 20.291, data 19.381) 
Epoch 2 Iter 3800, train entropy gap 0.6848 bits (loss 20.066, data 19.381) 
Epoch 2 Iter 4000, train entropy gap 0.9560 bits (loss 20.337, data 19.381) 
Epoch 2 Iter 4200, train entropy gap 0.8654 bits (loss 20.246, data 19.381) 
Epoch 2 Iter 4400, train entropy gap 0.9834 bits (loss 20.364, data 19.381) 
Epoch 2 Iter 4600, train entropy gap 0.8669 bits (loss 20.248, data 19.381) 
Epoch 2 Iter 4800, train entropy gap 0.9502 bits (loss 20.331, data 19.381) 
Epoch 2 Iter 5000, train entropy gap 0.8007 bits (loss 20.182, data 19.381) 
Epoch 2 Iter 5200, train entropy gap 0.8703 bits (loss 20.251, data 19.381) 
Epoch 2 Iter 5400, train entropy gap 0.6593 bits (loss 20.040, data 19.381) 
Epoch 2 Iter 5600, train entropy gap 0.9471 bits (loss 20.328, data 19.381) 
Epoch 2 Iter 5800, train entropy gap 0.7592 bits (loss 20.140, data 19.381) 
Epoch 2 Iter 6000, train entropy gap 0.9313 bits (loss 20.312, data 19.381) 
Epoch 2 Iter 6200, train entropy gap 0.9632 bits (loss 20.344, data 19.381) 
Epoch 2 Iter 6400, train entropy gap 0.8695 bits (loss 20.250, data 19.381) 
Epoch 2 Iter 6600, train entropy gap 1.0300 bits (loss 20.411, data 19.381) 
Epoch 2 Iter 6800, train entropy gap 0.8307 bits (loss 20.212, data 19.381) 
Epoch 2 Iter 7000, train entropy gap 0.9293 bits (loss 20.310, data 19.381) 
Epoch 2 Iter 7200, train entropy gap 0.8703 bits (loss 20.251, data 19.381) 
epoch 2 train loss 14.0133 nats / 20.2169 bits
time since start: 4292.8 secs
Epoch 3 Iter 0, train entropy gap 1.0576 bits (loss 20.438, data 19.381) 
Epoch 3 Iter 200, train entropy gap 1.1153 bits (loss 20.496, data 19.381) 
Epoch 3 Iter 400, train entropy gap 0.7271 bits (loss 20.108, data 19.381) 
Epoch 3 Iter 600, train entropy gap 0.9157 bits (loss 20.296, data 19.381) 
Epoch 3 Iter 800, train entropy gap 0.7783 bits (loss 20.159, data 19.381) 
Epoch 3 Iter 1000, train entropy gap 0.7604 bits (loss 20.141, data 19.381) 
Epoch 3 Iter 1200, train entropy gap 0.6994 bits (loss 20.080, data 19.381) 
Epoch 3 Iter 1400, train entropy gap 0.7797 bits (loss 20.161, data 19.381) 
Epoch 3 Iter 1600, train entropy gap 0.8322 bits (loss 20.213, data 19.381) 
Epoch 3 Iter 1800, train entropy gap 0.9010 bits (loss 20.282, data 19.381) 
Epoch 3 Iter 2000, train entropy gap 0.8663 bits (loss 20.247, data 19.381) 
Epoch 3 Iter 2200, train entropy gap 0.7629 bits (loss 20.144, data 19.381) 
Epoch 3 Iter 2400, train entropy gap 0.8889 bits (loss 20.270, data 19.381) 
Epoch 3 Iter 2600, train entropy gap 0.8052 bits (loss 20.186, data 19.381) 
Epoch 3 Iter 2800, train entropy gap 0.9111 bits (loss 20.292, data 19.381) 
Epoch 3 Iter 3000, train entropy gap 0.8808 bits (loss 20.262, data 19.381) 
Epoch 3 Iter 3200, train entropy gap 0.8865 bits (loss 20.267, data 19.381) 
Epoch 3 Iter 3400, train entropy gap 0.7087 bits (loss 20.089, data 19.381) 
Epoch 3 Iter 3600, train entropy gap 0.8708 bits (loss 20.252, data 19.381) 
Epoch 3 Iter 3800, train entropy gap 0.7640 bits (loss 20.145, data 19.381) 
Epoch 3 Iter 4000, train entropy gap 0.9179 bits (loss 20.299, data 19.381) 
Epoch 3 Iter 4200, train entropy gap 0.7401 bits (loss 20.121, data 19.381) 
Epoch 3 Iter 4400, train entropy gap 0.5343 bits (loss 19.915, data 19.381) 
Epoch 3 Iter 4600, train entropy gap 0.6396 bits (loss 20.020, data 19.381) 
Epoch 3 Iter 4800, train entropy gap 0.6711 bits (loss 20.052, data 19.381) 
Epoch 3 Iter 5000, train entropy gap 0.7952 bits (loss 20.176, data 19.381) 
Epoch 3 Iter 5200, train entropy gap 0.9594 bits (loss 20.340, data 19.381) 
Epoch 3 Iter 5400, train entropy gap 0.9555 bits (loss 20.336, data 19.381) 
Epoch 3 Iter 5600, train entropy gap 0.8815 bits (loss 20.262, data 19.381) 
Epoch 3 Iter 5800, train entropy gap 0.9226 bits (loss 20.303, data 19.381) 
Epoch 3 Iter 6000, train entropy gap 0.9865 bits (loss 20.367, data 19.381) 
Epoch 3 Iter 6200, train entropy gap 0.9061 bits (loss 20.287, data 19.381) 
Epoch 3 Iter 6400, train entropy gap 1.0551 bits (loss 20.436, data 19.381) 
Epoch 3 Iter 6600, train entropy gap 0.8134 bits (loss 20.194, data 19.381) 
Epoch 3 Iter 6800, train entropy gap 1.1090 bits (loss 20.490, data 19.381) 
Epoch 3 Iter 7000, train entropy gap 0.8933 bits (loss 20.274, data 19.381) 
Epoch 3 Iter 7200, train entropy gap 0.9154 bits (loss 20.296, data 19.381) 
epoch 3 train loss 14.0010 nats / 20.1992 bits
time since start: 5723.7 secs
Epoch 4 Iter 0, train entropy gap 0.8473 bits (loss 20.228, data 19.381) 
Epoch 4 Iter 200, train entropy gap 0.7134 bits (loss 20.094, data 19.381) 
Epoch 4 Iter 400, train entropy gap 0.8173 bits (loss 20.198, data 19.381) 
Epoch 4 Iter 600, train entropy gap 0.9414 bits (loss 20.322, data 19.381) 
Epoch 4 Iter 800, train entropy gap 0.8671 bits (loss 20.248, data 19.381) 
Epoch 4 Iter 1000, train entropy gap 0.9188 bits (loss 20.300, data 19.381) 
Epoch 4 Iter 1200, train entropy gap 1.0178 bits (loss 20.399, data 19.381) 
Epoch 4 Iter 1400, train entropy gap 0.7320 bits (loss 20.113, data 19.381) 
Epoch 4 Iter 1600, train entropy gap 0.8752 bits (loss 20.256, data 19.381) 
Epoch 4 Iter 1800, train entropy gap 0.7698 bits (loss 20.151, data 19.381) 
Epoch 4 Iter 2000, train entropy gap 0.7188 bits (loss 20.100, data 19.381) 
Epoch 4 Iter 2200, train entropy gap 0.8999 bits (loss 20.281, data 19.381) 
Epoch 4 Iter 2400, train entropy gap 0.6856 bits (loss 20.066, data 19.381) 
Epoch 4 Iter 2600, train entropy gap 0.8351 bits (loss 20.216, data 19.381) 
Epoch 4 Iter 2800, train entropy gap 0.7076 bits (loss 20.088, data 19.381) 
Epoch 4 Iter 3000, train entropy gap 0.7367 bits (loss 20.117, data 19.381) 
Epoch 4 Iter 3200, train entropy gap 0.6879 bits (loss 20.069, data 19.381) 
Epoch 4 Iter 3400, train entropy gap 0.7148 bits (loss 20.096, data 19.381) 
Epoch 4 Iter 3600, train entropy gap 0.8044 bits (loss 20.185, data 19.381) 
Epoch 4 Iter 3800, train entropy gap 0.7177 bits (loss 20.099, data 19.381) 
Epoch 4 Iter 4000, train entropy gap 0.8567 bits (loss 20.237, data 19.381) 
Epoch 4 Iter 4200, train entropy gap 0.6950 bits (loss 20.076, data 19.381) 
Epoch 4 Iter 4400, train entropy gap 0.6988 bits (loss 20.080, data 19.381) 
Epoch 4 Iter 4600, train entropy gap 0.7639 bits (loss 20.145, data 19.381) 
Epoch 4 Iter 4800, train entropy gap 0.8909 bits (loss 20.272, data 19.381) 
Epoch 4 Iter 5000, train entropy gap 0.7665 bits (loss 20.147, data 19.381) 
Epoch 4 Iter 5200, train entropy gap 0.8430 bits (loss 20.224, data 19.381) 
Epoch 4 Iter 5400, train entropy gap 0.9458 bits (loss 20.327, data 19.381) 
Epoch 4 Iter 5600, train entropy gap 0.8192 bits (loss 20.200, data 19.381) 
Epoch 4 Iter 5800, train entropy gap 0.7777 bits (loss 20.158, data 19.381) 
Epoch 4 Iter 6000, train entropy gap 0.8530 bits (loss 20.234, data 19.381) 
Epoch 4 Iter 6200, train entropy gap 0.9453 bits (loss 20.326, data 19.381) 
Epoch 4 Iter 6400, train entropy gap 0.8449 bits (loss 20.226, data 19.381) 
Epoch 4 Iter 6600, train entropy gap 0.7049 bits (loss 20.086, data 19.381) 
Epoch 4 Iter 6800, train entropy gap 0.6296 bits (loss 20.010, data 19.381) 
Epoch 4 Iter 7000, train entropy gap 1.0583 bits (loss 20.439, data 19.381) 
Epoch 4 Iter 7200, train entropy gap 0.7940 bits (loss 20.175, data 19.381) 
epoch 4 train loss 13.9917 nats / 20.1857 bits
time since start: 7154.9 secs
Epoch 5 Iter 0, train entropy gap 0.7156 bits (loss 20.096, data 19.381) 
Epoch 5 Iter 200, train entropy gap 0.7865 bits (loss 20.167, data 19.381) 
Epoch 5 Iter 400, train entropy gap 0.6611 bits (loss 20.042, data 19.381) 
Epoch 5 Iter 600, train entropy gap 0.8764 bits (loss 20.257, data 19.381) 
Epoch 5 Iter 800, train entropy gap 0.9604 bits (loss 20.341, data 19.381) 
Epoch 5 Iter 1000, train entropy gap 0.7889 bits (loss 20.170, data 19.381) 
Epoch 5 Iter 1200, train entropy gap 1.0193 bits (loss 20.400, data 19.381) 
Epoch 5 Iter 1400, train entropy gap 0.7787 bits (loss 20.160, data 19.381) 
Epoch 5 Iter 1600, train entropy gap 0.7901 bits (loss 20.171, data 19.381) 
Epoch 5 Iter 1800, train entropy gap 0.8801 bits (loss 20.261, data 19.381) 
Epoch 5 Iter 2000, train entropy gap 0.8663 bits (loss 20.247, data 19.381) 
Epoch 5 Iter 2200, train entropy gap 0.8233 bits (loss 20.204, data 19.381) 
Epoch 5 Iter 2400, train entropy gap 0.8237 bits (loss 20.205, data 19.381) 
Epoch 5 Iter 2600, train entropy gap 0.7670 bits (loss 20.148, data 19.381) 
Epoch 5 Iter 2800, train entropy gap 0.9539 bits (loss 20.335, data 19.381) 
Epoch 5 Iter 3000, train entropy gap 0.7114 bits (loss 20.092, data 19.381) 
Epoch 5 Iter 3200, train entropy gap 0.9288 bits (loss 20.310, data 19.381) 
Epoch 5 Iter 3400, train entropy gap 0.7474 bits (loss 20.128, data 19.381) 
Epoch 5 Iter 3600, train entropy gap 0.7921 bits (loss 20.173, data 19.381) 
Epoch 5 Iter 3800, train entropy gap 0.6424 bits (loss 20.023, data 19.381) 
Epoch 5 Iter 4000, train entropy gap 0.8028 bits (loss 20.184, data 19.381) 
Epoch 5 Iter 4200, train entropy gap 0.8875 bits (loss 20.268, data 19.381) 
Epoch 5 Iter 4400, train entropy gap 0.9195 bits (loss 20.300, data 19.381) 
Epoch 5 Iter 4600, train entropy gap 0.7676 bits (loss 20.148, data 19.381) 
Epoch 5 Iter 4800, train entropy gap 0.9044 bits (loss 20.285, data 19.381) 
Epoch 5 Iter 5000, train entropy gap 0.7380 bits (loss 20.119, data 19.381) 
Epoch 5 Iter 5200, train entropy gap 0.8395 bits (loss 20.220, data 19.381) 
Epoch 5 Iter 5400, train entropy gap 0.8346 bits (loss 20.215, data 19.381) 
Epoch 5 Iter 5600, train entropy gap 0.8627 bits (loss 20.244, data 19.381) 
Epoch 5 Iter 5800, train entropy gap 0.8558 bits (loss 20.237, data 19.381) 
Epoch 5 Iter 6000, train entropy gap 0.8169 bits (loss 20.198, data 19.381) 
Epoch 5 Iter 6200, train entropy gap 0.8688 bits (loss 20.250, data 19.381) 
Epoch 5 Iter 6400, train entropy gap 0.9108 bits (loss 20.292, data 19.381) 
Epoch 5 Iter 6600, train entropy gap 0.6809 bits (loss 20.062, data 19.381) 
Epoch 5 Iter 6800, train entropy gap 0.9508 bits (loss 20.332, data 19.381) 
Epoch 5 Iter 7000, train entropy gap 0.7797 bits (loss 20.161, data 19.381) 
Epoch 5 Iter 7200, train entropy gap 0.7378 bits (loss 20.119, data 19.381) 
epoch 5 train loss 13.9837 nats / 20.1743 bits
time since start: 8586.4 secs
Epoch 6 Iter 0, train entropy gap 0.7795 bits (loss 20.160, data 19.381) 
Epoch 6 Iter 200, train entropy gap 0.7987 bits (loss 20.180, data 19.381) 
Epoch 6 Iter 400, train entropy gap 0.9003 bits (loss 20.281, data 19.381) 
Epoch 6 Iter 600, train entropy gap 0.5199 bits (loss 19.901, data 19.381) 
Epoch 6 Iter 800, train entropy gap 0.8481 bits (loss 20.229, data 19.381) 
Epoch 6 Iter 1000, train entropy gap 0.6865 bits (loss 20.067, data 19.381) 
Epoch 6 Iter 1200, train entropy gap 0.7991 bits (loss 20.180, data 19.381) 
Epoch 6 Iter 1400, train entropy gap 0.8668 bits (loss 20.248, data 19.381) 
Epoch 6 Iter 1600, train entropy gap 0.6624 bits (loss 20.043, data 19.381) 
Epoch 6 Iter 1800, train entropy gap 0.6233 bits (loss 20.004, data 19.381) 
Epoch 6 Iter 2000, train entropy gap 0.9027 bits (loss 20.283, data 19.381) 
Epoch 6 Iter 2200, train entropy gap 0.5918 bits (loss 19.973, data 19.381) 
Epoch 6 Iter 2400, train entropy gap 0.7804 bits (loss 20.161, data 19.381) 
Epoch 6 Iter 2600, train entropy gap 0.8972 bits (loss 20.278, data 19.381) 
Epoch 6 Iter 2800, train entropy gap 0.8077 bits (loss 20.189, data 19.381) 
Epoch 6 Iter 3000, train entropy gap 0.8080 bits (loss 20.189, data 19.381) 
Epoch 6 Iter 3200, train entropy gap 0.8532 bits (loss 20.234, data 19.381) 
Epoch 6 Iter 3400, train entropy gap 0.9184 bits (loss 20.299, data 19.381) 
Epoch 6 Iter 3600, train entropy gap 0.6653 bits (loss 20.046, data 19.381) 
Epoch 6 Iter 3800, train entropy gap 0.6964 bits (loss 20.077, data 19.381) 
Epoch 6 Iter 4000, train entropy gap 0.7910 bits (loss 20.172, data 19.381) 
Epoch 6 Iter 4200, train entropy gap 0.8370 bits (loss 20.218, data 19.381) 
Epoch 6 Iter 4400, train entropy gap 0.5975 bits (loss 19.978, data 19.381) 
Epoch 6 Iter 4600, train entropy gap 0.7527 bits (loss 20.134, data 19.381) 
Epoch 6 Iter 4800, train entropy gap 0.8609 bits (loss 20.242, data 19.381) 
Epoch 6 Iter 5000, train entropy gap 0.7765 bits (loss 20.157, data 19.381) 
Epoch 6 Iter 5200, train entropy gap 0.7906 bits (loss 20.171, data 19.381) 
Epoch 6 Iter 5400, train entropy gap 0.9235 bits (loss 20.304, data 19.381) 
Epoch 6 Iter 5600, train entropy gap 0.8497 bits (loss 20.231, data 19.381) 
Epoch 6 Iter 5800, train entropy gap 1.0276 bits (loss 20.408, data 19.381) 
Epoch 6 Iter 6000, train entropy gap 0.8157 bits (loss 20.196, data 19.381) 
Epoch 6 Iter 6200, train entropy gap 0.8415 bits (loss 20.222, data 19.381) 
Epoch 6 Iter 6400, train entropy gap 0.6689 bits (loss 20.050, data 19.381) 
Epoch 6 Iter 6600, train entropy gap 0.8895 bits (loss 20.270, data 19.381) 
Epoch 6 Iter 6800, train entropy gap 0.7208 bits (loss 20.102, data 19.381) 
Epoch 6 Iter 7000, train entropy gap 0.6684 bits (loss 20.049, data 19.381) 
Epoch 6 Iter 7200, train entropy gap 0.7543 bits (loss 20.135, data 19.381) 
epoch 6 train loss 13.9763 nats / 20.1635 bits
time since start: 10017.4 secs
Epoch 7 Iter 0, train entropy gap 0.8409 bits (loss 20.222, data 19.381) 
Epoch 7 Iter 200, train entropy gap 0.7863 bits (loss 20.167, data 19.381) 
Epoch 7 Iter 400, train entropy gap 0.7332 bits (loss 20.114, data 19.381) 
Epoch 7 Iter 600, train entropy gap 1.0640 bits (loss 20.445, data 19.381) 
Epoch 7 Iter 800, train entropy gap 0.6629 bits (loss 20.044, data 19.381) 
Epoch 7 Iter 1000, train entropy gap 0.7456 bits (loss 20.126, data 19.381) 
Epoch 7 Iter 1200, train entropy gap 0.8870 bits (loss 20.268, data 19.381) 
Epoch 7 Iter 1400, train entropy gap 0.7491 bits (loss 20.130, data 19.381) 
Epoch 7 Iter 1600, train entropy gap 0.7998 bits (loss 20.181, data 19.381) 
Epoch 7 Iter 1800, train entropy gap 0.7770 bits (loss 20.158, data 19.381) 
Epoch 7 Iter 2000, train entropy gap 0.5449 bits (loss 19.926, data 19.381) 
Epoch 7 Iter 2200, train entropy gap 0.8337 bits (loss 20.215, data 19.381) 
Epoch 7 Iter 2400, train entropy gap 0.7323 bits (loss 20.113, data 19.381) 
Epoch 7 Iter 2600, train entropy gap 0.8289 bits (loss 20.210, data 19.381) 
Epoch 7 Iter 2800, train entropy gap 0.5285 bits (loss 19.909, data 19.381) 
Epoch 7 Iter 3000, train entropy gap 0.8700 bits (loss 20.251, data 19.381) 
Epoch 7 Iter 3200, train entropy gap 0.7830 bits (loss 20.164, data 19.381) 
Epoch 7 Iter 3400, train entropy gap 0.7719 bits (loss 20.153, data 19.381) 
Epoch 7 Iter 3600, train entropy gap 0.6786 bits (loss 20.059, data 19.381) 
Epoch 7 Iter 3800, train entropy gap 0.6838 bits (loss 20.065, data 19.381) 
Epoch 7 Iter 4000, train entropy gap 0.7509 bits (loss 20.132, data 19.381) 
Epoch 7 Iter 4200, train entropy gap 0.6437 bits (loss 20.024, data 19.381) 
Epoch 7 Iter 4400, train entropy gap 0.8616 bits (loss 20.242, data 19.381) 
Epoch 7 Iter 4600, train entropy gap 1.0034 bits (loss 20.384, data 19.381) 
Epoch 7 Iter 4800, train entropy gap 0.7741 bits (loss 20.155, data 19.381) 
Epoch 7 Iter 5000, train entropy gap 0.8477 bits (loss 20.229, data 19.381) 
Epoch 7 Iter 5200, train entropy gap 0.7388 bits (loss 20.120, data 19.381) 
Epoch 7 Iter 5400, train entropy gap 0.7183 bits (loss 20.099, data 19.381) 
Epoch 7 Iter 5600, train entropy gap 0.9612 bits (loss 20.342, data 19.381) 
Epoch 7 Iter 5800, train entropy gap 0.6824 bits (loss 20.063, data 19.381) 
Epoch 7 Iter 6000, train entropy gap 0.7213 bits (loss 20.102, data 19.381) 
Epoch 7 Iter 6200, train entropy gap 0.8358 bits (loss 20.217, data 19.381) 
Epoch 7 Iter 6400, train entropy gap 0.6624 bits (loss 20.043, data 19.381) 
Epoch 7 Iter 6600, train entropy gap 0.8151 bits (loss 20.196, data 19.381) 
Epoch 7 Iter 6800, train entropy gap 0.7633 bits (loss 20.144, data 19.381) 
Epoch 7 Iter 7000, train entropy gap 0.8680 bits (loss 20.249, data 19.381) 
Epoch 7 Iter 7200, train entropy gap 0.9879 bits (loss 20.369, data 19.381) 
epoch 7 train loss 13.9691 nats / 20.1532 bits
time since start: 11448.5 secs
Epoch 8 Iter 0, train entropy gap 0.7282 bits (loss 20.109, data 19.381) 
Epoch 8 Iter 200, train entropy gap 0.6925 bits (loss 20.073, data 19.381) 
Epoch 8 Iter 400, train entropy gap 0.7731 bits (loss 20.154, data 19.381) 
Epoch 8 Iter 600, train entropy gap 0.8027 bits (loss 20.184, data 19.381) 
Epoch 8 Iter 800, train entropy gap 0.8743 bits (loss 20.255, data 19.381) 
Epoch 8 Iter 1000, train entropy gap 0.6996 bits (loss 20.080, data 19.381) 
Epoch 8 Iter 1200, train entropy gap 0.7037 bits (loss 20.084, data 19.381) 
Epoch 8 Iter 1400, train entropy gap 0.8529 bits (loss 20.234, data 19.381) 
Epoch 8 Iter 1600, train entropy gap 0.7121 bits (loss 20.093, data 19.381) 
Epoch 8 Iter 1800, train entropy gap 0.6232 bits (loss 20.004, data 19.381) 
Epoch 8 Iter 2000, train entropy gap 0.8956 bits (loss 20.276, data 19.381) 
Epoch 8 Iter 2200, train entropy gap 0.6619 bits (loss 20.043, data 19.381) 
Epoch 8 Iter 2400, train entropy gap 0.7038 bits (loss 20.085, data 19.381) 
Epoch 8 Iter 2600, train entropy gap 0.7772 bits (loss 20.158, data 19.381) 
Epoch 8 Iter 2800, train entropy gap 0.5793 bits (loss 19.960, data 19.381) 
Epoch 8 Iter 3000, train entropy gap 0.7033 bits (loss 20.084, data 19.381) 
Epoch 8 Iter 3200, train entropy gap 0.7614 bits (loss 20.142, data 19.381) 
Epoch 8 Iter 3400, train entropy gap 0.6924 bits (loss 20.073, data 19.381) 
Epoch 8 Iter 3600, train entropy gap 0.6285 bits (loss 20.009, data 19.381) 
Epoch 8 Iter 3800, train entropy gap 0.6935 bits (loss 20.074, data 19.381) 
Epoch 8 Iter 4000, train entropy gap 0.9606 bits (loss 20.341, data 19.381) 
Epoch 8 Iter 4200, train entropy gap 0.7020 bits (loss 20.083, data 19.381) 
Epoch 8 Iter 4400, train entropy gap 0.7231 bits (loss 20.104, data 19.381) 
Epoch 8 Iter 4600, train entropy gap 0.7924 bits (loss 20.173, data 19.381) 
Epoch 8 Iter 4800, train entropy gap 0.7088 bits (loss 20.090, data 19.381) 
Epoch 8 Iter 5000, train entropy gap 0.7056 bits (loss 20.086, data 19.381) 
Epoch 8 Iter 5200, train entropy gap 0.8146 bits (loss 20.195, data 19.381) 
Epoch 8 Iter 5400, train entropy gap 0.8436 bits (loss 20.224, data 19.381) 
Epoch 8 Iter 5600, train entropy gap 0.6611 bits (loss 20.042, data 19.381) 
Epoch 8 Iter 5800, train entropy gap 0.5510 bits (loss 19.932, data 19.381) 
Epoch 8 Iter 6000, train entropy gap 0.8490 bits (loss 20.230, data 19.381) 
Epoch 8 Iter 6200, train entropy gap 0.6824 bits (loss 20.063, data 19.381) 
Epoch 8 Iter 6400, train entropy gap 0.9521 bits (loss 20.333, data 19.381) 
Epoch 8 Iter 6600, train entropy gap 0.8498 bits (loss 20.231, data 19.381) 
Epoch 8 Iter 6800, train entropy gap 0.7711 bits (loss 20.152, data 19.381) 
Epoch 8 Iter 7000, train entropy gap 0.7593 bits (loss 20.140, data 19.381) 
Epoch 8 Iter 7200, train entropy gap 0.7591 bits (loss 20.140, data 19.381) 
epoch 8 train loss 13.9619 nats / 20.1428 bits
time since start: 12879.2 secs
Epoch 9 Iter 0, train entropy gap 0.8788 bits (loss 20.260, data 19.381) 
Epoch 9 Iter 200, train entropy gap 0.7020 bits (loss 20.083, data 19.381) 
Epoch 9 Iter 400, train entropy gap 0.6937 bits (loss 20.075, data 19.381) 
Epoch 9 Iter 600, train entropy gap 0.5259 bits (loss 19.907, data 19.381) 
Epoch 9 Iter 800, train entropy gap 0.5911 bits (loss 19.972, data 19.381) 
Epoch 9 Iter 1000, train entropy gap 0.5357 bits (loss 19.917, data 19.381) 
Epoch 9 Iter 1200, train entropy gap 0.6479 bits (loss 20.029, data 19.381) 
Epoch 9 Iter 1400, train entropy gap 0.7679 bits (loss 20.149, data 19.381) 
Epoch 9 Iter 1600, train entropy gap 0.7952 bits (loss 20.176, data 19.381) 
Epoch 9 Iter 1800, train entropy gap 0.7354 bits (loss 20.116, data 19.381) 
Epoch 9 Iter 2000, train entropy gap 0.6900 bits (loss 20.071, data 19.381) 
Epoch 9 Iter 2200, train entropy gap 0.7958 bits (loss 20.177, data 19.381) 
Epoch 9 Iter 2400, train entropy gap 0.8279 bits (loss 20.209, data 19.381) 
Epoch 9 Iter 2600, train entropy gap 0.5680 bits (loss 19.949, data 19.381) 
Epoch 9 Iter 2800, train entropy gap 0.8533 bits (loss 20.234, data 19.381) 
Epoch 9 Iter 3000, train entropy gap 0.6578 bits (loss 20.039, data 19.381) 
Epoch 9 Iter 3200, train entropy gap 0.5409 bits (loss 19.922, data 19.381) 
Epoch 9 Iter 3400, train entropy gap 0.7986 bits (loss 20.179, data 19.381) 
Epoch 9 Iter 3600, train entropy gap 0.6846 bits (loss 20.065, data 19.381) 
Epoch 9 Iter 3800, train entropy gap 0.6694 bits (loss 20.050, data 19.381) 
Epoch 9 Iter 4000, train entropy gap 0.8010 bits (loss 20.182, data 19.381) 
Epoch 9 Iter 4200, train entropy gap 0.5658 bits (loss 19.947, data 19.381) 
Epoch 9 Iter 4400, train entropy gap 0.8714 bits (loss 20.252, data 19.381) 
Epoch 9 Iter 4600, train entropy gap 0.8811 bits (loss 20.262, data 19.381) 
Epoch 9 Iter 4800, train entropy gap 0.7309 bits (loss 20.112, data 19.381) 
Epoch 9 Iter 5000, train entropy gap 0.9171 bits (loss 20.298, data 19.381) 
Epoch 9 Iter 5200, train entropy gap 0.8493 bits (loss 20.230, data 19.381) 
Epoch 9 Iter 5400, train entropy gap 0.8335 bits (loss 20.214, data 19.381) 
Epoch 9 Iter 5600, train entropy gap 0.6834 bits (loss 20.064, data 19.381) 
Epoch 9 Iter 5800, train entropy gap 0.7554 bits (loss 20.136, data 19.381) 
Epoch 9 Iter 6000, train entropy gap 0.8552 bits (loss 20.236, data 19.381) 
Epoch 9 Iter 6200, train entropy gap 0.7836 bits (loss 20.164, data 19.381) 
Epoch 9 Iter 6400, train entropy gap 0.5288 bits (loss 19.910, data 19.381) 
Epoch 9 Iter 6600, train entropy gap 0.7853 bits (loss 20.166, data 19.381) 
Epoch 9 Iter 6800, train entropy gap 0.6657 bits (loss 20.046, data 19.381) 
Epoch 9 Iter 7000, train entropy gap 0.6882 bits (loss 20.069, data 19.381) 
Epoch 9 Iter 7200, train entropy gap 0.9493 bits (loss 20.330, data 19.381) 
epoch 9 train loss 13.9546 nats / 20.1323 bits
time since start: 14310.2 secs
Epoch 10 Iter 0, train entropy gap 0.5924 bits (loss 19.973, data 19.381) 
Epoch 10 Iter 200, train entropy gap 0.7906 bits (loss 20.171, data 19.381) 
Epoch 10 Iter 400, train entropy gap 0.6854 bits (loss 20.066, data 19.381) 
Epoch 10 Iter 600, train entropy gap 0.8305 bits (loss 20.211, data 19.381) 
Epoch 10 Iter 800, train entropy gap 0.7327 bits (loss 20.114, data 19.381) 
Epoch 10 Iter 1000, train entropy gap 0.7357 bits (loss 20.117, data 19.381) 
Epoch 10 Iter 1200, train entropy gap 0.9669 bits (loss 20.348, data 19.381) 
Epoch 10 Iter 1400, train entropy gap 0.5459 bits (loss 19.927, data 19.381) 
Epoch 10 Iter 1600, train entropy gap 0.8580 bits (loss 20.239, data 19.381) 
Epoch 10 Iter 1800, train entropy gap 0.7076 bits (loss 20.088, data 19.381) 
Epoch 10 Iter 2000, train entropy gap 0.7901 bits (loss 20.171, data 19.381) 
Epoch 10 Iter 2200, train entropy gap 0.7324 bits (loss 20.113, data 19.381) 
Epoch 10 Iter 2400, train entropy gap 0.8725 bits (loss 20.253, data 19.381) 
Epoch 10 Iter 2600, train entropy gap 0.5812 bits (loss 19.962, data 19.381) 
Epoch 10 Iter 2800, train entropy gap 0.5735 bits (loss 19.954, data 19.381) 
Epoch 10 Iter 3000, train entropy gap 0.6521 bits (loss 20.033, data 19.381) 
Epoch 10 Iter 3200, train entropy gap 0.7341 bits (loss 20.115, data 19.381) 
Epoch 10 Iter 3400, train entropy gap 0.8244 bits (loss 20.205, data 19.381) 
Epoch 10 Iter 3600, train entropy gap 0.5048 bits (loss 19.886, data 19.381) 
Epoch 10 Iter 3800, train entropy gap 0.5408 bits (loss 19.922, data 19.381) 
Epoch 10 Iter 4000, train entropy gap 0.6796 bits (loss 20.060, data 19.381) 
Epoch 10 Iter 4200, train entropy gap 0.6759 bits (loss 20.057, data 19.381) 
Epoch 10 Iter 4400, train entropy gap 0.5890 bits (loss 19.970, data 19.381) 
Epoch 10 Iter 4600, train entropy gap 0.6224 bits (loss 20.003, data 19.381) 
Epoch 10 Iter 4800, train entropy gap 0.7397 bits (loss 20.120, data 19.381) 
Epoch 10 Iter 5000, train entropy gap 0.7628 bits (loss 20.144, data 19.381) 
Epoch 10 Iter 5200, train entropy gap 0.8474 bits (loss 20.228, data 19.381) 
Epoch 10 Iter 5400, train entropy gap 0.8083 bits (loss 20.189, data 19.381) 
Epoch 10 Iter 5600, train entropy gap 0.6304 bits (loss 20.011, data 19.381) 
Epoch 10 Iter 5800, train entropy gap 0.8576 bits (loss 20.238, data 19.381) 
Epoch 10 Iter 6000, train entropy gap 0.7992 bits (loss 20.180, data 19.381) 
Epoch 10 Iter 6200, train entropy gap 0.8464 bits (loss 20.227, data 19.381) 
Epoch 10 Iter 6400, train entropy gap 0.7617 bits (loss 20.143, data 19.381) 
Epoch 10 Iter 6600, train entropy gap 0.8882 bits (loss 20.269, data 19.381) 
Epoch 10 Iter 6800, train entropy gap 0.9019 bits (loss 20.283, data 19.381) 
Epoch 10 Iter 7000, train entropy gap 0.7111 bits (loss 20.092, data 19.381) 
Epoch 10 Iter 7200, train entropy gap 0.7259 bits (loss 20.107, data 19.381) 
epoch 10 train loss 13.9478 nats / 20.1224 bits
time since start: 15741.2 secs
Epoch 11 Iter 0, train entropy gap 0.7665 bits (loss 20.147, data 19.381) 
Epoch 11 Iter 200, train entropy gap 0.8065 bits (loss 20.187, data 19.381) 
Epoch 11 Iter 400, train entropy gap 0.7564 bits (loss 20.137, data 19.381) 
Epoch 11 Iter 600, train entropy gap 0.6989 bits (loss 20.080, data 19.381) 
Epoch 11 Iter 800, train entropy gap 0.6581 bits (loss 20.039, data 19.381) 
Epoch 11 Iter 1000, train entropy gap 0.7852 bits (loss 20.166, data 19.381) 
Epoch 11 Iter 1200, train entropy gap 0.7195 bits (loss 20.100, data 19.381) 
Epoch 11 Iter 1400, train entropy gap 0.8503 bits (loss 20.231, data 19.381) 
Epoch 11 Iter 1600, train entropy gap 0.5976 bits (loss 19.978, data 19.381) 
Epoch 11 Iter 1800, train entropy gap 0.8437 bits (loss 20.225, data 19.381) 
Epoch 11 Iter 2000, train entropy gap 0.5726 bits (loss 19.953, data 19.381) 
Epoch 11 Iter 2200, train entropy gap 0.5839 bits (loss 19.965, data 19.381) 
Epoch 11 Iter 2400, train entropy gap 0.6831 bits (loss 20.064, data 19.381) 
Epoch 11 Iter 2600, train entropy gap 0.6322 bits (loss 20.013, data 19.381) 
Epoch 11 Iter 2800, train entropy gap 0.8778 bits (loss 20.259, data 19.381) 
Epoch 11 Iter 3000, train entropy gap 0.8848 bits (loss 20.266, data 19.381) 
Epoch 11 Iter 3200, train entropy gap 0.7449 bits (loss 20.126, data 19.381) 
Epoch 11 Iter 3400, train entropy gap 0.8829 bits (loss 20.264, data 19.381) 
Epoch 11 Iter 3600, train entropy gap 0.8411 bits (loss 20.222, data 19.381) 
Epoch 11 Iter 3800, train entropy gap 0.8811 bits (loss 20.262, data 19.381) 
Epoch 11 Iter 4000, train entropy gap 0.7848 bits (loss 20.166, data 19.381) 
Epoch 11 Iter 4200, train entropy gap 0.7219 bits (loss 20.103, data 19.381) 
Epoch 11 Iter 4400, train entropy gap 0.8599 bits (loss 20.241, data 19.381) 
Epoch 11 Iter 4600, train entropy gap 0.6511 bits (loss 20.032, data 19.381) 
Epoch 11 Iter 4800, train entropy gap 0.8558 bits (loss 20.237, data 19.381) 
Epoch 11 Iter 5000, train entropy gap 0.6492 bits (loss 20.030, data 19.381) 
Epoch 11 Iter 5200, train entropy gap 0.5981 bits (loss 19.979, data 19.381) 
Epoch 11 Iter 5400, train entropy gap 0.7327 bits (loss 20.114, data 19.381) 
Epoch 11 Iter 5600, train entropy gap 0.6944 bits (loss 20.075, data 19.381) 
Epoch 11 Iter 5800, train entropy gap 0.6637 bits (loss 20.045, data 19.381) 
Epoch 11 Iter 6000, train entropy gap 0.6929 bits (loss 20.074, data 19.381) 
Epoch 11 Iter 6200, train entropy gap 0.7532 bits (loss 20.134, data 19.381) 
Epoch 11 Iter 6400, train entropy gap 0.7597 bits (loss 20.141, data 19.381) 
Epoch 11 Iter 6600, train entropy gap 0.8953 bits (loss 20.276, data 19.381) 
Epoch 11 Iter 6800, train entropy gap 0.8591 bits (loss 20.240, data 19.381) 
Epoch 11 Iter 7000, train entropy gap 0.9543 bits (loss 20.335, data 19.381) 
Epoch 11 Iter 7200, train entropy gap 0.7426 bits (loss 20.123, data 19.381) 
epoch 11 train loss 13.9408 nats / 20.1123 bits
time since start: 17172.2 secs
Epoch 12 Iter 0, train entropy gap 0.7180 bits (loss 20.099, data 19.381) 
Epoch 12 Iter 200, train entropy gap 0.8238 bits (loss 20.205, data 19.381) 
Epoch 12 Iter 400, train entropy gap 0.7925 bits (loss 20.173, data 19.381) 
Epoch 12 Iter 600, train entropy gap 0.6009 bits (loss 19.982, data 19.381) 
Epoch 12 Iter 800, train entropy gap 0.6158 bits (loss 19.997, data 19.381) 
Epoch 12 Iter 1000, train entropy gap 0.5628 bits (loss 19.944, data 19.381) 
Epoch 12 Iter 1200, train entropy gap 0.6422 bits (loss 20.023, data 19.381) 
Epoch 12 Iter 1400, train entropy gap 0.7890 bits (loss 20.170, data 19.381) 
Epoch 12 Iter 1600, train entropy gap 0.7488 bits (loss 20.130, data 19.381) 
Epoch 12 Iter 1800, train entropy gap 0.6636 bits (loss 20.044, data 19.381) 
Epoch 12 Iter 2000, train entropy gap 0.6466 bits (loss 20.027, data 19.381) 
Epoch 12 Iter 2200, train entropy gap 0.6239 bits (loss 20.005, data 19.381) 
Epoch 12 Iter 2400, train entropy gap 0.6582 bits (loss 20.039, data 19.381) 
Epoch 12 Iter 2600, train entropy gap 0.6903 bits (loss 20.071, data 19.381) 
Epoch 12 Iter 2800, train entropy gap 0.6380 bits (loss 20.019, data 19.381) 
Epoch 12 Iter 3000, train entropy gap 0.6841 bits (loss 20.065, data 19.381) 
Epoch 12 Iter 3200, train entropy gap 0.7135 bits (loss 20.094, data 19.381) 
Epoch 12 Iter 3400, train entropy gap 0.5858 bits (loss 19.967, data 19.381) 
Epoch 12 Iter 3600, train entropy gap 0.8312 bits (loss 20.212, data 19.381) 
Epoch 12 Iter 3800, train entropy gap 0.7942 bits (loss 20.175, data 19.381) 
Epoch 12 Iter 4000, train entropy gap 0.6920 bits (loss 20.073, data 19.381) 
Epoch 12 Iter 4200, train entropy gap 0.7883 bits (loss 20.169, data 19.381) 
Epoch 12 Iter 4400, train entropy gap 0.5326 bits (loss 19.913, data 19.381) 
Epoch 12 Iter 4600, train entropy gap 0.7708 bits (loss 20.152, data 19.381) 
Epoch 12 Iter 4800, train entropy gap 0.6485 bits (loss 20.029, data 19.381) 
Epoch 12 Iter 5000, train entropy gap 0.8185 bits (loss 20.199, data 19.381) 
Epoch 12 Iter 5200, train entropy gap 0.6315 bits (loss 20.012, data 19.381) 
Epoch 12 Iter 5400, train entropy gap 0.5813 bits (loss 19.962, data 19.381) 
Epoch 12 Iter 5600, train entropy gap 0.8322 bits (loss 20.213, data 19.381) 
Epoch 12 Iter 5800, train entropy gap 0.8635 bits (loss 20.244, data 19.381) 
Epoch 12 Iter 6000, train entropy gap 0.6368 bits (loss 20.018, data 19.381) 
Epoch 12 Iter 6200, train entropy gap 0.9733 bits (loss 20.354, data 19.381) 
Epoch 12 Iter 6400, train entropy gap 0.8405 bits (loss 20.221, data 19.381) 
Epoch 12 Iter 6600, train entropy gap 0.6704 bits (loss 20.051, data 19.381) 
Epoch 12 Iter 6800, train entropy gap 0.9321 bits (loss 20.313, data 19.381) 
Epoch 12 Iter 7000, train entropy gap 0.7506 bits (loss 20.131, data 19.381) 
Epoch 12 Iter 7200, train entropy gap 0.8531 bits (loss 20.234, data 19.381) 
epoch 12 train loss 13.9340 nats / 20.1026 bits
time since start: 18603.8 secs
Epoch 13 Iter 0, train entropy gap 0.7190 bits (loss 20.100, data 19.381) 
Epoch 13 Iter 200, train entropy gap 0.6277 bits (loss 20.009, data 19.381) 
Epoch 13 Iter 400, train entropy gap 0.7278 bits (loss 20.109, data 19.381) 
Epoch 13 Iter 600, train entropy gap 0.8518 bits (loss 20.233, data 19.381) 
Epoch 13 Iter 800, train entropy gap 0.6463 bits (loss 20.027, data 19.381) 
Epoch 13 Iter 1000, train entropy gap 0.6081 bits (loss 19.989, data 19.381) 
Epoch 13 Iter 1200, train entropy gap 0.7439 bits (loss 20.125, data 19.381) 
Epoch 13 Iter 1400, train entropy gap 0.6948 bits (loss 20.076, data 19.381) 
Epoch 13 Iter 1600, train entropy gap 0.5213 bits (loss 19.902, data 19.381) 
Epoch 13 Iter 1800, train entropy gap 0.5867 bits (loss 19.968, data 19.381) 
Epoch 13 Iter 2000, train entropy gap 0.6236 bits (loss 20.004, data 19.381) 
Epoch 13 Iter 2200, train entropy gap 0.7429 bits (loss 20.124, data 19.381) 
Epoch 13 Iter 2400, train entropy gap 0.6589 bits (loss 20.040, data 19.381) 
Epoch 13 Iter 2600, train entropy gap 0.7552 bits (loss 20.136, data 19.381) 
Epoch 13 Iter 2800, train entropy gap 0.7264 bits (loss 20.107, data 19.381) 
Epoch 13 Iter 3000, train entropy gap 0.5944 bits (loss 19.975, data 19.381) 
Epoch 13 Iter 3200, train entropy gap 0.5436 bits (loss 19.924, data 19.381) 
Epoch 13 Iter 3400, train entropy gap 0.7494 bits (loss 20.130, data 19.381) 
Epoch 13 Iter 3600, train entropy gap 0.6470 bits (loss 20.028, data 19.381) 
Epoch 13 Iter 3800, train entropy gap 0.7220 bits (loss 20.103, data 19.381) 
Epoch 13 Iter 4000, train entropy gap 0.6357 bits (loss 20.016, data 19.381) 
Epoch 13 Iter 4200, train entropy gap 0.8313 bits (loss 20.212, data 19.381) 
Epoch 13 Iter 4400, train entropy gap 0.5766 bits (loss 19.957, data 19.381) 
Epoch 13 Iter 4600, train entropy gap 0.5817 bits (loss 19.963, data 19.381) 
Epoch 13 Iter 4800, train entropy gap 0.6260 bits (loss 20.007, data 19.381) 
Epoch 13 Iter 5000, train entropy gap 0.7414 bits (loss 20.122, data 19.381) 
Epoch 13 Iter 5200, train entropy gap 0.6168 bits (loss 19.998, data 19.381) 
Epoch 13 Iter 5400, train entropy gap 0.9004 bits (loss 20.281, data 19.381) 
Epoch 13 Iter 5600, train entropy gap 0.8388 bits (loss 20.220, data 19.381) 
Epoch 13 Iter 5800, train entropy gap 0.5894 bits (loss 19.970, data 19.381) 
Epoch 13 Iter 6000, train entropy gap 0.7142 bits (loss 20.095, data 19.381) 
Epoch 13 Iter 6200, train entropy gap 0.5414 bits (loss 19.922, data 19.381) 
Epoch 13 Iter 6400, train entropy gap 0.6705 bits (loss 20.051, data 19.381) 
Epoch 13 Iter 6600, train entropy gap 0.6004 bits (loss 19.981, data 19.381) 
Epoch 13 Iter 6800, train entropy gap 0.5617 bits (loss 19.942, data 19.381) 
Epoch 13 Iter 7000, train entropy gap 0.7236 bits (loss 20.104, data 19.381) 
Epoch 13 Iter 7200, train entropy gap 0.9510 bits (loss 20.332, data 19.381) 
epoch 13 train loss 13.9273 nats / 20.0928 bits
time since start: 20035.2 secs
Epoch 14 Iter 0, train entropy gap 0.7604 bits (loss 20.141, data 19.381) 
Epoch 14 Iter 200, train entropy gap 0.5354 bits (loss 19.916, data 19.381) 
Epoch 14 Iter 400, train entropy gap 0.6519 bits (loss 20.033, data 19.381) 
Epoch 14 Iter 600, train entropy gap 0.6935 bits (loss 20.074, data 19.381) 
Epoch 14 Iter 800, train entropy gap 0.7476 bits (loss 20.128, data 19.381) 
Epoch 14 Iter 1000, train entropy gap 0.7882 bits (loss 20.169, data 19.381) 
Epoch 14 Iter 1200, train entropy gap 0.6174 bits (loss 19.998, data 19.381) 
Epoch 14 Iter 1400, train entropy gap 0.4859 bits (loss 19.867, data 19.381) 
Epoch 14 Iter 1600, train entropy gap 0.6332 bits (loss 20.014, data 19.381) 
Epoch 14 Iter 1800, train entropy gap 0.4417 bits (loss 19.823, data 19.381) 
Epoch 14 Iter 2000, train entropy gap 0.4198 bits (loss 19.801, data 19.381) 
Epoch 14 Iter 2200, train entropy gap 0.7696 bits (loss 20.150, data 19.381) 
Epoch 14 Iter 2400, train entropy gap 0.6111 bits (loss 19.992, data 19.381) 
Epoch 14 Iter 2600, train entropy gap 0.6385 bits (loss 20.019, data 19.381) 
Epoch 14 Iter 2800, train entropy gap 0.8458 bits (loss 20.227, data 19.381) 
Epoch 14 Iter 3000, train entropy gap 0.7166 bits (loss 20.097, data 19.381) 
Epoch 14 Iter 3200, train entropy gap 0.7783 bits (loss 20.159, data 19.381) 
Epoch 14 Iter 3400, train entropy gap 0.8614 bits (loss 20.242, data 19.381) 
Epoch 14 Iter 3600, train entropy gap 0.7291 bits (loss 20.110, data 19.381) 
Epoch 14 Iter 3800, train entropy gap 0.8073 bits (loss 20.188, data 19.381) 
Epoch 14 Iter 4000, train entropy gap 0.8963 bits (loss 20.277, data 19.381) 
Epoch 14 Iter 4200, train entropy gap 0.8041 bits (loss 20.185, data 19.381) 
Epoch 14 Iter 4400, train entropy gap 0.6658 bits (loss 20.047, data 19.381) 
Epoch 14 Iter 4600, train entropy gap 0.7299 bits (loss 20.111, data 19.381) 
Epoch 14 Iter 4800, train entropy gap 0.6817 bits (loss 20.063, data 19.381) 
Epoch 14 Iter 5000, train entropy gap 0.7075 bits (loss 20.088, data 19.381) 
Epoch 14 Iter 5200, train entropy gap 0.5409 bits (loss 19.922, data 19.381) 
Epoch 14 Iter 5400, train entropy gap 0.7702 bits (loss 20.151, data 19.381) 
Epoch 14 Iter 5600, train entropy gap 0.8578 bits (loss 20.239, data 19.381) 
Epoch 14 Iter 5800, train entropy gap 0.8290 bits (loss 20.210, data 19.381) 
Epoch 14 Iter 6000, train entropy gap 0.6143 bits (loss 19.995, data 19.381) 
Epoch 14 Iter 6200, train entropy gap 0.6161 bits (loss 19.997, data 19.381) 
Epoch 14 Iter 6400, train entropy gap 0.8036 bits (loss 20.184, data 19.381) 
Epoch 14 Iter 6600, train entropy gap 0.9077 bits (loss 20.289, data 19.381) 
Epoch 14 Iter 6800, train entropy gap 0.7234 bits (loss 20.104, data 19.381) 
Epoch 14 Iter 7000, train entropy gap 0.6741 bits (loss 20.055, data 19.381) 
Epoch 14 Iter 7200, train entropy gap 0.5301 bits (loss 19.911, data 19.381) 
epoch 14 train loss 13.9207 nats / 20.0833 bits
time since start: 21468.2 secs
Epoch 15 Iter 0, train entropy gap 0.7960 bits (loss 20.177, data 19.381) 
Epoch 15 Iter 200, train entropy gap 0.9386 bits (loss 20.319, data 19.381) 
Epoch 15 Iter 400, train entropy gap 0.6472 bits (loss 20.028, data 19.381) 
Epoch 15 Iter 600, train entropy gap 0.4367 bits (loss 19.818, data 19.381) 
Epoch 15 Iter 800, train entropy gap 0.7331 bits (loss 20.114, data 19.381) 
Epoch 15 Iter 1000, train entropy gap 0.4672 bits (loss 19.848, data 19.381) 
Epoch 15 Iter 1200, train entropy gap 0.5133 bits (loss 19.894, data 19.381) 
Epoch 15 Iter 1400, train entropy gap 0.4987 bits (loss 19.880, data 19.381) 
Epoch 15 Iter 1600, train entropy gap 0.6189 bits (loss 20.000, data 19.381) 
Epoch 15 Iter 1800, train entropy gap 0.6179 bits (loss 19.999, data 19.381) 
Epoch 15 Iter 2000, train entropy gap 0.8107 bits (loss 20.192, data 19.381) 
Epoch 15 Iter 2200, train entropy gap 0.6042 bits (loss 19.985, data 19.381) 
Epoch 15 Iter 2400, train entropy gap 0.5520 bits (loss 19.933, data 19.381) 
Epoch 15 Iter 2600, train entropy gap 0.6698 bits (loss 20.051, data 19.381) 
Epoch 15 Iter 2800, train entropy gap 0.4832 bits (loss 19.864, data 19.381) 
Epoch 15 Iter 3000, train entropy gap 0.5814 bits (loss 19.962, data 19.381) 
Epoch 15 Iter 3200, train entropy gap 0.6567 bits (loss 20.037, data 19.381) 
Epoch 15 Iter 3400, train entropy gap 0.7435 bits (loss 20.124, data 19.381) 
Epoch 15 Iter 3600, train entropy gap 0.7409 bits (loss 20.122, data 19.381) 
Epoch 15 Iter 3800, train entropy gap 0.7847 bits (loss 20.165, data 19.381) 
Epoch 15 Iter 4000, train entropy gap 0.7277 bits (loss 20.109, data 19.381) 
Epoch 15 Iter 4200, train entropy gap 0.6523 bits (loss 20.033, data 19.381) 
Epoch 15 Iter 4400, train entropy gap 0.8985 bits (loss 20.279, data 19.381) 
Epoch 15 Iter 4600, train entropy gap 0.6558 bits (loss 20.037, data 19.381) 
Epoch 15 Iter 4800, train entropy gap 0.7263 bits (loss 20.107, data 19.381) 
Epoch 15 Iter 5000, train entropy gap 0.5750 bits (loss 19.956, data 19.381) 
Epoch 15 Iter 5200, train entropy gap 0.7595 bits (loss 20.140, data 19.381) 
Epoch 15 Iter 5400, train entropy gap 0.6895 bits (loss 20.070, data 19.381) 
Epoch 15 Iter 5600, train entropy gap 0.7845 bits (loss 20.165, data 19.381) 
Epoch 15 Iter 5800, train entropy gap 0.4837 bits (loss 19.865, data 19.381) 
Epoch 15 Iter 6000, train entropy gap 0.7472 bits (loss 20.128, data 19.381) 
Epoch 15 Iter 6200, train entropy gap 0.6373 bits (loss 20.018, data 19.381) 
Epoch 15 Iter 6400, train entropy gap 0.7870 bits (loss 20.168, data 19.381) 
Epoch 15 Iter 6600, train entropy gap 0.9530 bits (loss 20.334, data 19.381) 
Epoch 15 Iter 6800, train entropy gap 0.7500 bits (loss 20.131, data 19.381) 
Epoch 15 Iter 7000, train entropy gap 0.6320 bits (loss 20.013, data 19.381) 
Epoch 15 Iter 7200, train entropy gap 0.8063 bits (loss 20.187, data 19.381) 
epoch 15 train loss 13.9142 nats / 20.0739 bits
time since start: 22980.7 secs
Epoch 16 Iter 0, train entropy gap 0.7593 bits (loss 20.140, data 19.381) 
Epoch 16 Iter 200, train entropy gap 0.8408 bits (loss 20.222, data 19.381) 
Epoch 16 Iter 400, train entropy gap 0.6524 bits (loss 20.033, data 19.381) 
Epoch 16 Iter 600, train entropy gap 0.6043 bits (loss 19.985, data 19.381) 
Epoch 16 Iter 800, train entropy gap 0.8025 bits (loss 20.183, data 19.381) 
Epoch 16 Iter 1000, train entropy gap 0.6667 bits (loss 20.047, data 19.381) 
Epoch 16 Iter 1200, train entropy gap 0.6118 bits (loss 19.993, data 19.381) 
Epoch 16 Iter 1400, train entropy gap 0.7133 bits (loss 20.094, data 19.381) 
Epoch 16 Iter 1600, train entropy gap 0.6112 bits (loss 19.992, data 19.381) 
Epoch 16 Iter 1800, train entropy gap 0.7394 bits (loss 20.120, data 19.381) 
Epoch 16 Iter 2000, train entropy gap 0.7252 bits (loss 20.106, data 19.381) 
Epoch 16 Iter 2200, train entropy gap 0.5312 bits (loss 19.912, data 19.381) 
Epoch 16 Iter 2400, train entropy gap 0.6539 bits (loss 20.035, data 19.381) 
Epoch 16 Iter 2600, train entropy gap 0.6593 bits (loss 20.040, data 19.381) 
Epoch 16 Iter 2800, train entropy gap 0.5741 bits (loss 19.955, data 19.381) 
Epoch 16 Iter 3000, train entropy gap 0.5711 bits (loss 19.952, data 19.381) 
Epoch 16 Iter 3200, train entropy gap 0.7317 bits (loss 20.113, data 19.381) 
Epoch 16 Iter 3400, train entropy gap 0.5777 bits (loss 19.959, data 19.381) 
Epoch 16 Iter 3600, train entropy gap 0.8550 bits (loss 20.236, data 19.381) 
Epoch 16 Iter 3800, train entropy gap 0.7067 bits (loss 20.087, data 19.381) 
Epoch 16 Iter 4000, train entropy gap 0.7477 bits (loss 20.129, data 19.381) 
Epoch 16 Iter 4200, train entropy gap 0.7969 bits (loss 20.178, data 19.381) 
Epoch 16 Iter 4400, train entropy gap 0.5018 bits (loss 19.883, data 19.381) 
Epoch 16 Iter 4600, train entropy gap 0.8938 bits (loss 20.275, data 19.381) 
Epoch 16 Iter 4800, train entropy gap 0.4919 bits (loss 19.873, data 19.381) 
Epoch 16 Iter 5000, train entropy gap 0.7392 bits (loss 20.120, data 19.381) 
Epoch 16 Iter 5200, train entropy gap 0.7314 bits (loss 20.112, data 19.381) 
Epoch 16 Iter 5400, train entropy gap 0.7925 bits (loss 20.173, data 19.381) 
Epoch 16 Iter 5600, train entropy gap 0.8081 bits (loss 20.189, data 19.381) 
Epoch 16 Iter 5800, train entropy gap 0.6025 bits (loss 19.983, data 19.381) 
Epoch 16 Iter 6000, train entropy gap 0.6960 bits (loss 20.077, data 19.381) 
Epoch 16 Iter 6200, train entropy gap 0.5391 bits (loss 19.920, data 19.381) 
Epoch 16 Iter 6400, train entropy gap 0.7090 bits (loss 20.090, data 19.381) 
Epoch 16 Iter 6600, train entropy gap 0.7208 bits (loss 20.102, data 19.381) 
Epoch 16 Iter 6800, train entropy gap 0.7276 bits (loss 20.108, data 19.381) 
Epoch 16 Iter 7000, train entropy gap 0.7172 bits (loss 20.098, data 19.381) 
Epoch 16 Iter 7200, train entropy gap 0.6841 bits (loss 20.065, data 19.381) 
epoch 16 train loss 13.9085 nats / 20.0657 bits
time since start: 24722.1 secs
Epoch 17 Iter 0, train entropy gap 0.8794 bits (loss 20.260, data 19.381) 
Epoch 17 Iter 200, train entropy gap 0.6359 bits (loss 20.017, data 19.381) 
Epoch 17 Iter 400, train entropy gap 0.6924 bits (loss 20.073, data 19.381) 
Epoch 17 Iter 600, train entropy gap 0.7579 bits (loss 20.139, data 19.381) 
Epoch 17 Iter 800, train entropy gap 0.5088 bits (loss 19.890, data 19.381) 
Epoch 17 Iter 1000, train entropy gap 0.7334 bits (loss 20.114, data 19.381) 
Epoch 17 Iter 1200, train entropy gap 0.6764 bits (loss 20.057, data 19.381) 
Epoch 17 Iter 1400, train entropy gap 0.4846 bits (loss 19.865, data 19.381) 
Epoch 17 Iter 1600, train entropy gap 0.4965 bits (loss 19.877, data 19.381) 