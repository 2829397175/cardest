Device cuda
Loading csv... done, took 6.2s
Parsing... done, took 5.0s
Entropy of DMV([Column(Record Type, distribution_size=8), Column(Registration Class, distribution_size=72), Column(State, distribution_size=79), Column(County, distribution_size=64), Column(Body Type, distribution_size=59), Column(Fuel Type, distribution_size=10), Column(Reg Valid Date, distribution_size=2884), Column(Color, distribution_size=222), Column(Scofflaw Indicator, distribution_size=3), Column(Suspension Indicator, distribution_size=3), Column(Revocation Indicator, distribution_size=3)]): 19.3808 bits
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7389597 entries, 0 to 7389596
Data columns (total 11 columns):
 #   Column                Dtype         
---  ------                -----         
 0   Record Type           object        
 1   Registration Class    object        
 2   State                 object        
 3   County                object        
 4   Body Type             object        
 5   Fuel Type             object        
 6   Reg Valid Date        datetime64[ns]
 7   Color                 object        
 8   Scofflaw Indicator    object        
 9   Suspension Indicator  object        
 10  Revocation Indicator  object        
dtypes: datetime64[ns](1), object(10)
memory usage: 620.2+ MB
None
MASK_SCHEME 0
ordering [ 0  1  2  3  4  5  6  7  8  9 10]
using orig mask
 tensor([[ True, False, False, False, False, False, False, False, False, False,
         False],
        [ True,  True, False, False, False, False, False, False, False, False,
         False],
        [ True,  True,  True, False, False, False, False, False, False, False,
         False],
        [ True,  True,  True,  True, False, False, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True, False, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True]])
Number of model parameters: 418816 (~= 1.6MB)
Transformer(
  (blocks): Sequential(
    (0): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=64, out_features=192, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
    )
    (1): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=64, out_features=192, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
    )
    (2): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=64, out_features=192, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
    )
    (3): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=64, out_features=192, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
    )
  )
  (norm): LayerNorm()
  (embeddings): ModuleList(
    (0): Embedding(8, 64)
    (1): Embedding(72, 64)
    (2): Embedding(79, 64)
    (3): Embedding(64, 64)
    (4): Embedding(59, 64)
    (5): Embedding(10, 64)
    (6): Embedding(2884, 64)
    (7): Embedding(222, 64)
    (8): Embedding(3, 64)
    (9): Embedding(3, 64)
    (10): Embedding(3, 64)
  )
  (pos_embeddings): Embedding(11, 64)
)
Discretizing table... done, took 4.7s
Epoch 0 Iter 0, train entropy gap 35.0831 bits (loss 54.464, data 19.381) 
Epoch 0 Iter 200, train entropy gap 34.6905 bits (loss 54.071, data 19.381) 
Epoch 0 Iter 400, train entropy gap 33.5519 bits (loss 52.933, data 19.381) 
Epoch 0 Iter 600, train entropy gap 31.6334 bits (loss 51.014, data 19.381) 
Epoch 0 Iter 800, train entropy gap 29.2298 bits (loss 48.611, data 19.381) 
Epoch 0 Iter 1000, train entropy gap 26.5935 bits (loss 45.974, data 19.381) 
Epoch 0 Iter 1200, train entropy gap 23.7467 bits (loss 43.127, data 19.381) 
Epoch 0 Iter 1400, train entropy gap 20.8361 bits (loss 40.217, data 19.381) 
Epoch 0 Iter 1600, train entropy gap 17.2842 bits (loss 36.665, data 19.381) 
Epoch 0 Iter 1800, train entropy gap 14.2083 bits (loss 33.589, data 19.381) 
Epoch 0 Iter 2000, train entropy gap 11.3964 bits (loss 30.777, data 19.381) 
Epoch 0 Iter 2200, train entropy gap 8.7990 bits (loss 28.180, data 19.381) 
Epoch 0 Iter 2400, train entropy gap 6.3671 bits (loss 25.748, data 19.381) 
Epoch 0 Iter 2600, train entropy gap 4.3118 bits (loss 23.693, data 19.381) 
Epoch 0 Iter 2800, train entropy gap 2.4034 bits (loss 21.784, data 19.381) 
Epoch 0 Iter 3000, train entropy gap 1.1099 bits (loss 20.491, data 19.381) 
Epoch 0 Iter 3200, train entropy gap -0.0794 bits (loss 19.301, data 19.381) 
Epoch 0 Iter 3400, train entropy gap -1.2113 bits (loss 18.170, data 19.381) 
Epoch 0 Iter 3600, train entropy gap -2.4984 bits (loss 16.882, data 19.381) 
Epoch 0 Iter 3800, train entropy gap -3.4528 bits (loss 15.928, data 19.381) 
Epoch 0 Iter 4000, train entropy gap -4.4410 bits (loss 14.940, data 19.381) 
Epoch 0 Iter 4200, train entropy gap -5.5999 bits (loss 13.781, data 19.381) 
Epoch 0 Iter 4400, train entropy gap -6.4470 bits (loss 12.934, data 19.381) 
Epoch 0 Iter 4600, train entropy gap -7.1452 bits (loss 12.236, data 19.381) 
Epoch 0 Iter 4800, train entropy gap -7.6685 bits (loss 11.712, data 19.381) 
Epoch 0 Iter 5000, train entropy gap -8.4425 bits (loss 10.938, data 19.381) 
Epoch 0 Iter 5200, train entropy gap -9.1292 bits (loss 10.252, data 19.381) 
Epoch 0 Iter 5400, train entropy gap -9.6442 bits (loss 9.737, data 19.381) 
Epoch 0 Iter 5600, train entropy gap -10.2863 bits (loss 9.095, data 19.381) 
Epoch 0 Iter 5800, train entropy gap -10.5000 bits (loss 8.881, data 19.381) 
Epoch 0 Iter 6000, train entropy gap -11.1396 bits (loss 8.241, data 19.381) 
Epoch 0 Iter 6200, train entropy gap -11.6851 bits (loss 7.696, data 19.381) 
Epoch 0 Iter 6400, train entropy gap -12.1877 bits (loss 7.193, data 19.381) 
Epoch 0 Iter 6600, train entropy gap -12.8751 bits (loss 6.506, data 19.381) 
Epoch 0 Iter 6800, train entropy gap -13.2430 bits (loss 6.138, data 19.381) 
Epoch 0 Iter 7000, train entropy gap -13.7302 bits (loss 5.651, data 19.381) 
Epoch 0 Iter 7200, train entropy gap -14.2750 bits (loss 5.106, data 19.381) 
epoch 0 train loss 15.6409 nats / 22.5650 bits
time since start: 91.1 secs
Epoch 1 Iter 0, train entropy gap -14.2265 bits (loss 5.154, data 19.381) 
Epoch 1 Iter 200, train entropy gap -14.3561 bits (loss 5.025, data 19.381) 
Epoch 1 Iter 400, train entropy gap -14.3026 bits (loss 5.078, data 19.381) 
Epoch 1 Iter 600, train entropy gap -14.4539 bits (loss 4.927, data 19.381) 
Epoch 1 Iter 800, train entropy gap -14.4377 bits (loss 4.943, data 19.381) 
Epoch 1 Iter 1000, train entropy gap -14.5936 bits (loss 4.787, data 19.381) 
Epoch 1 Iter 1200, train entropy gap -14.6501 bits (loss 4.731, data 19.381) 
Epoch 1 Iter 1400, train entropy gap -14.7441 bits (loss 4.637, data 19.381) 
Epoch 1 Iter 1600, train entropy gap -14.6910 bits (loss 4.690, data 19.381) 
Epoch 1 Iter 1800, train entropy gap -14.9392 bits (loss 4.442, data 19.381) 
Epoch 1 Iter 2000, train entropy gap -15.0047 bits (loss 4.376, data 19.381) 
Epoch 1 Iter 2200, train entropy gap -15.1159 bits (loss 4.265, data 19.381) 
Epoch 1 Iter 2400, train entropy gap -15.1065 bits (loss 4.274, data 19.381) 
Epoch 1 Iter 2600, train entropy gap -15.3997 bits (loss 3.981, data 19.381) 
Epoch 1 Iter 2800, train entropy gap -15.5528 bits (loss 3.828, data 19.381) 
Epoch 1 Iter 3000, train entropy gap -15.6767 bits (loss 3.704, data 19.381) 
Epoch 1 Iter 3200, train entropy gap -15.9734 bits (loss 3.407, data 19.381) 
Epoch 1 Iter 3400, train entropy gap -15.9230 bits (loss 3.458, data 19.381) 
Epoch 1 Iter 3600, train entropy gap -16.2361 bits (loss 3.145, data 19.381) 
Epoch 1 Iter 3800, train entropy gap -16.2432 bits (loss 3.138, data 19.381) 
Epoch 1 Iter 4000, train entropy gap -16.2969 bits (loss 3.084, data 19.381) 
Epoch 1 Iter 4200, train entropy gap -16.7008 bits (loss 2.680, data 19.381) 
Epoch 1 Iter 4400, train entropy gap -16.7745 bits (loss 2.606, data 19.381) 
Epoch 1 Iter 4600, train entropy gap -16.9637 bits (loss 2.417, data 19.381) 
Epoch 1 Iter 4800, train entropy gap -17.0518 bits (loss 2.329, data 19.381) 
Epoch 1 Iter 5000, train entropy gap -17.1520 bits (loss 2.229, data 19.381) 
Epoch 1 Iter 5200, train entropy gap -17.3373 bits (loss 2.043, data 19.381) 
Epoch 1 Iter 5400, train entropy gap -17.4887 bits (loss 1.892, data 19.381) 
Epoch 1 Iter 5600, train entropy gap -17.8008 bits (loss 1.580, data 19.381) 
Epoch 1 Iter 5800, train entropy gap -17.7667 bits (loss 1.614, data 19.381) 
Epoch 1 Iter 6000, train entropy gap -17.8405 bits (loss 1.540, data 19.381) 
Epoch 1 Iter 6200, train entropy gap -18.1335 bits (loss 1.247, data 19.381) 
Epoch 1 Iter 6400, train entropy gap -18.0124 bits (loss 1.368, data 19.381) 
Epoch 1 Iter 6600, train entropy gap -18.3265 bits (loss 1.054, data 19.381) 
Epoch 1 Iter 6800, train entropy gap -18.2161 bits (loss 1.165, data 19.381) 
Epoch 1 Iter 7000, train entropy gap -18.4187 bits (loss 0.962, data 19.381) 
Epoch 1 Iter 7200, train entropy gap -18.4373 bits (loss 0.943, data 19.381) 
epoch 1 train loss 2.1945 nats / 3.1660 bits
time since start: 181.5 secs
Epoch 2 Iter 0, train entropy gap -18.4926 bits (loss 0.888, data 19.381) 
Epoch 2 Iter 200, train entropy gap -18.4466 bits (loss 0.934, data 19.381) 
Epoch 2 Iter 400, train entropy gap -18.4960 bits (loss 0.885, data 19.381) 
Epoch 2 Iter 600, train entropy gap -18.4984 bits (loss 0.882, data 19.381) 
Epoch 2 Iter 800, train entropy gap -18.4235 bits (loss 0.957, data 19.381) 
Epoch 2 Iter 1000, train entropy gap -18.5087 bits (loss 0.872, data 19.381) 
Epoch 2 Iter 1200, train entropy gap -18.5357 bits (loss 0.845, data 19.381) 
Epoch 2 Iter 1400, train entropy gap -18.5126 bits (loss 0.868, data 19.381) 
Epoch 2 Iter 1600, train entropy gap -18.5553 bits (loss 0.826, data 19.381) 
Epoch 2 Iter 1800, train entropy gap -18.6026 bits (loss 0.778, data 19.381) 
Epoch 2 Iter 2000, train entropy gap -18.6478 bits (loss 0.733, data 19.381) 
Epoch 2 Iter 2200, train entropy gap -18.6885 bits (loss 0.692, data 19.381) 
Epoch 2 Iter 2400, train entropy gap -18.5715 bits (loss 0.809, data 19.381) 
Epoch 2 Iter 2600, train entropy gap -18.6144 bits (loss 0.766, data 19.381) 
Epoch 2 Iter 2800, train entropy gap -18.6957 bits (loss 0.685, data 19.381) 
Epoch 2 Iter 3000, train entropy gap -18.5959 bits (loss 0.785, data 19.381) 
Epoch 2 Iter 3200, train entropy gap -18.8013 bits (loss 0.579, data 19.381) 
Epoch 2 Iter 3400, train entropy gap -18.6101 bits (loss 0.771, data 19.381) 
Epoch 2 Iter 3600, train entropy gap -18.6889 bits (loss 0.692, data 19.381) 
Epoch 2 Iter 3800, train entropy gap -18.8062 bits (loss 0.575, data 19.381) 
Epoch 2 Iter 4000, train entropy gap -18.7707 bits (loss 0.610, data 19.381) 
Epoch 2 Iter 4200, train entropy gap -18.7861 bits (loss 0.595, data 19.381) 
Epoch 2 Iter 4400, train entropy gap -18.7152 bits (loss 0.666, data 19.381) 
Epoch 2 Iter 4600, train entropy gap -18.9001 bits (loss 0.481, data 19.381) 
Epoch 2 Iter 4800, train entropy gap -18.8856 bits (loss 0.495, data 19.381) 
Epoch 2 Iter 5000, train entropy gap -18.8466 bits (loss 0.534, data 19.381) 
Epoch 2 Iter 5200, train entropy gap -18.8694 bits (loss 0.511, data 19.381) 
Epoch 2 Iter 5400, train entropy gap -18.8614 bits (loss 0.519, data 19.381) 
Epoch 2 Iter 5600, train entropy gap -18.8496 bits (loss 0.531, data 19.381) 
Epoch 2 Iter 5800, train entropy gap -18.9557 bits (loss 0.425, data 19.381) 
Epoch 2 Iter 6000, train entropy gap -18.9131 bits (loss 0.468, data 19.381) 
Epoch 2 Iter 6200, train entropy gap -18.9768 bits (loss 0.404, data 19.381) 
Epoch 2 Iter 6400, train entropy gap -18.9484 bits (loss 0.432, data 19.381) 
Epoch 2 Iter 6600, train entropy gap -18.9629 bits (loss 0.418, data 19.381) 
Epoch 2 Iter 6800, train entropy gap -18.9745 bits (loss 0.406, data 19.381) 
Epoch 2 Iter 7000, train entropy gap -18.9314 bits (loss 0.449, data 19.381) 
Epoch 2 Iter 7200, train entropy gap -18.9871 bits (loss 0.394, data 19.381) 
epoch 2 train loss 0.4643 nats / 0.6698 bits
time since start: 271.8 secs
Epoch 3 Iter 0, train entropy gap -18.9821 bits (loss 0.399, data 19.381) 
Epoch 3 Iter 200, train entropy gap -19.0052 bits (loss 0.376, data 19.381) 
Epoch 3 Iter 400, train entropy gap -19.0002 bits (loss 0.381, data 19.381) 
Epoch 3 Iter 600, train entropy gap -18.9865 bits (loss 0.394, data 19.381) 
Epoch 3 Iter 800, train entropy gap -19.0532 bits (loss 0.328, data 19.381) 
Epoch 3 Iter 1000, train entropy gap -19.0101 bits (loss 0.371, data 19.381) 
Epoch 3 Iter 1200, train entropy gap -18.9567 bits (loss 0.424, data 19.381) 
Epoch 3 Iter 1400, train entropy gap -18.9575 bits (loss 0.423, data 19.381) 
Epoch 3 Iter 1600, train entropy gap -19.0718 bits (loss 0.309, data 19.381) 
Epoch 3 Iter 1800, train entropy gap -19.0406 bits (loss 0.340, data 19.381) 
Epoch 3 Iter 2000, train entropy gap -19.0238 bits (loss 0.357, data 19.381) 
Epoch 3 Iter 2200, train entropy gap -19.0321 bits (loss 0.349, data 19.381) 
Epoch 3 Iter 2400, train entropy gap -19.0054 bits (loss 0.375, data 19.381) 
Epoch 3 Iter 2600, train entropy gap -18.9910 bits (loss 0.390, data 19.381) 
Epoch 3 Iter 2800, train entropy gap -19.0465 bits (loss 0.334, data 19.381) 
Epoch 3 Iter 3000, train entropy gap -19.0270 bits (loss 0.354, data 19.381) 
Epoch 3 Iter 3200, train entropy gap -19.0027 bits (loss 0.378, data 19.381) 
Epoch 3 Iter 3400, train entropy gap -19.0872 bits (loss 0.294, data 19.381) 
Epoch 3 Iter 3600, train entropy gap -19.0246 bits (loss 0.356, data 19.381) 
Epoch 3 Iter 3800, train entropy gap -19.0437 bits (loss 0.337, data 19.381) 
Epoch 3 Iter 4000, train entropy gap -19.1040 bits (loss 0.277, data 19.381) 
Epoch 3 Iter 4200, train entropy gap -19.1140 bits (loss 0.267, data 19.381) 
Epoch 3 Iter 4400, train entropy gap -19.0188 bits (loss 0.362, data 19.381) 
Epoch 3 Iter 4600, train entropy gap -19.0976 bits (loss 0.283, data 19.381) 
Epoch 3 Iter 4800, train entropy gap -19.0440 bits (loss 0.337, data 19.381) 
Epoch 3 Iter 5000, train entropy gap -19.0672 bits (loss 0.314, data 19.381) 
Epoch 3 Iter 5200, train entropy gap -19.0646 bits (loss 0.316, data 19.381) 
Epoch 3 Iter 5400, train entropy gap -19.1050 bits (loss 0.276, data 19.381) 
Epoch 3 Iter 5600, train entropy gap -19.1108 bits (loss 0.270, data 19.381) 
Epoch 3 Iter 5800, train entropy gap -19.1654 bits (loss 0.215, data 19.381) 
Epoch 3 Iter 6000, train entropy gap -19.1558 bits (loss 0.225, data 19.381) 
Epoch 3 Iter 6200, train entropy gap -19.1496 bits (loss 0.231, data 19.381) 
Epoch 3 Iter 6400, train entropy gap -19.0933 bits (loss 0.287, data 19.381) 
Epoch 3 Iter 6600, train entropy gap -19.0766 bits (loss 0.304, data 19.381) 
Epoch 3 Iter 6800, train entropy gap -19.0715 bits (loss 0.309, data 19.381) 
Epoch 3 Iter 7000, train entropy gap -19.1407 bits (loss 0.240, data 19.381) 
Epoch 3 Iter 7200, train entropy gap -19.1151 bits (loss 0.266, data 19.381) 
epoch 3 train loss 0.2214 nats / 0.3194 bits
time since start: 361.0 secs
Epoch 4 Iter 0, train entropy gap -19.1602 bits (loss 0.221, data 19.381) 
Epoch 4 Iter 200, train entropy gap -19.0614 bits (loss 0.319, data 19.381) 
Epoch 4 Iter 400, train entropy gap -19.2025 bits (loss 0.178, data 19.381) 
Epoch 4 Iter 600, train entropy gap -19.1805 bits (loss 0.200, data 19.381) 
Epoch 4 Iter 800, train entropy gap -19.1174 bits (loss 0.263, data 19.381) 
Epoch 4 Iter 1000, train entropy gap -19.1534 bits (loss 0.227, data 19.381) 
Epoch 4 Iter 1200, train entropy gap -19.1466 bits (loss 0.234, data 19.381) 
Epoch 4 Iter 1400, train entropy gap -19.1701 bits (loss 0.211, data 19.381) 
Epoch 4 Iter 1600, train entropy gap -19.0759 bits (loss 0.305, data 19.381) 
Epoch 4 Iter 1800, train entropy gap -19.1577 bits (loss 0.223, data 19.381) 
Epoch 4 Iter 2000, train entropy gap -19.1047 bits (loss 0.276, data 19.381) 
Epoch 4 Iter 2200, train entropy gap -19.2105 bits (loss 0.170, data 19.381) 
Epoch 4 Iter 2400, train entropy gap -19.1938 bits (loss 0.187, data 19.381) 
Epoch 4 Iter 2600, train entropy gap -19.1537 bits (loss 0.227, data 19.381) 
Epoch 4 Iter 2800, train entropy gap -19.1524 bits (loss 0.228, data 19.381) 
Epoch 4 Iter 3000, train entropy gap -19.1958 bits (loss 0.185, data 19.381) 
Epoch 4 Iter 3200, train entropy gap -19.1427 bits (loss 0.238, data 19.381) 
Epoch 4 Iter 3400, train entropy gap -19.1506 bits (loss 0.230, data 19.381) 
Epoch 4 Iter 3600, train entropy gap -19.1544 bits (loss 0.226, data 19.381) 
Epoch 4 Iter 3800, train entropy gap -19.1694 bits (loss 0.211, data 19.381) 
Epoch 4 Iter 4000, train entropy gap -19.1261 bits (loss 0.255, data 19.381) 
Epoch 4 Iter 4200, train entropy gap -19.1633 bits (loss 0.218, data 19.381) 
Epoch 4 Iter 4400, train entropy gap -19.1174 bits (loss 0.263, data 19.381) 
Epoch 4 Iter 4600, train entropy gap -19.1775 bits (loss 0.203, data 19.381) 
Epoch 4 Iter 4800, train entropy gap -19.1608 bits (loss 0.220, data 19.381) 
Epoch 4 Iter 5000, train entropy gap -19.1816 bits (loss 0.199, data 19.381) 
Epoch 4 Iter 5200, train entropy gap -19.1626 bits (loss 0.218, data 19.381) 
Epoch 4 Iter 5400, train entropy gap -19.2184 bits (loss 0.162, data 19.381) 
Epoch 4 Iter 5600, train entropy gap -19.1578 bits (loss 0.223, data 19.381) 
Epoch 4 Iter 5800, train entropy gap -19.1463 bits (loss 0.234, data 19.381) 
Epoch 4 Iter 6000, train entropy gap -19.1306 bits (loss 0.250, data 19.381) 
Epoch 4 Iter 6200, train entropy gap -19.2417 bits (loss 0.139, data 19.381) 
Epoch 4 Iter 6400, train entropy gap -19.2028 bits (loss 0.178, data 19.381) 
Epoch 4 Iter 6600, train entropy gap -19.1914 bits (loss 0.189, data 19.381) 
Epoch 4 Iter 6800, train entropy gap -19.0956 bits (loss 0.285, data 19.381) 
Epoch 4 Iter 7000, train entropy gap -19.2095 bits (loss 0.171, data 19.381) 
Epoch 4 Iter 7200, train entropy gap -19.1917 bits (loss 0.189, data 19.381) 
epoch 4 train loss 0.1532 nats / 0.2210 bits
time since start: 450.4 secs
Epoch 5 Iter 0, train entropy gap -19.1549 bits (loss 0.226, data 19.381) 
Epoch 5 Iter 200, train entropy gap -19.2508 bits (loss 0.130, data 19.381) 
Epoch 5 Iter 400, train entropy gap -19.1982 bits (loss 0.183, data 19.381) 
Epoch 5 Iter 600, train entropy gap -19.1759 bits (loss 0.205, data 19.381) 
Epoch 5 Iter 800, train entropy gap -19.1466 bits (loss 0.234, data 19.381) 
Epoch 5 Iter 1000, train entropy gap -19.2327 bits (loss 0.148, data 19.381) 
Epoch 5 Iter 1200, train entropy gap -19.1872 bits (loss 0.194, data 19.381) 
Epoch 5 Iter 1400, train entropy gap -19.1551 bits (loss 0.226, data 19.381) 
Epoch 5 Iter 1600, train entropy gap -19.2389 bits (loss 0.142, data 19.381) 
Epoch 5 Iter 1800, train entropy gap -19.1913 bits (loss 0.190, data 19.381) 
Epoch 5 Iter 2000, train entropy gap -19.1844 bits (loss 0.196, data 19.381) 
Epoch 5 Iter 2200, train entropy gap -19.2317 bits (loss 0.149, data 19.381) 
Epoch 5 Iter 2400, train entropy gap -19.1852 bits (loss 0.196, data 19.381) 
Epoch 5 Iter 2600, train entropy gap -19.2099 bits (loss 0.171, data 19.381) 
Epoch 5 Iter 2800, train entropy gap -19.1659 bits (loss 0.215, data 19.381) 
Epoch 5 Iter 3000, train entropy gap -19.1749 bits (loss 0.206, data 19.381) 
Epoch 5 Iter 3200, train entropy gap -19.1576 bits (loss 0.223, data 19.381) 
Epoch 5 Iter 3400, train entropy gap -19.1187 bits (loss 0.262, data 19.381) 
Epoch 5 Iter 3600, train entropy gap -19.1468 bits (loss 0.234, data 19.381) 
Epoch 5 Iter 3800, train entropy gap -19.1776 bits (loss 0.203, data 19.381) 
Epoch 5 Iter 4000, train entropy gap -19.2179 bits (loss 0.163, data 19.381) 
Epoch 5 Iter 4200, train entropy gap -19.2016 bits (loss 0.179, data 19.381) 
Epoch 5 Iter 4400, train entropy gap -19.1450 bits (loss 0.236, data 19.381) 
Epoch 5 Iter 4600, train entropy gap -19.1710 bits (loss 0.210, data 19.381) 
Epoch 5 Iter 4800, train entropy gap -19.2040 bits (loss 0.177, data 19.381) 
Epoch 5 Iter 5000, train entropy gap -19.2002 bits (loss 0.181, data 19.381) 
Epoch 5 Iter 5200, train entropy gap -19.2116 bits (loss 0.169, data 19.381) 
Epoch 5 Iter 5400, train entropy gap -19.1453 bits (loss 0.236, data 19.381) 
Epoch 5 Iter 5600, train entropy gap -19.1974 bits (loss 0.183, data 19.381) 
Epoch 5 Iter 5800, train entropy gap -19.2152 bits (loss 0.166, data 19.381) 
Epoch 5 Iter 6000, train entropy gap -19.2319 bits (loss 0.149, data 19.381) 
Epoch 5 Iter 6200, train entropy gap -19.2012 bits (loss 0.180, data 19.381) 
Epoch 5 Iter 6400, train entropy gap -19.2102 bits (loss 0.171, data 19.381) 
Epoch 5 Iter 6600, train entropy gap -19.2165 bits (loss 0.164, data 19.381) 
Epoch 5 Iter 6800, train entropy gap -19.2170 bits (loss 0.164, data 19.381) 
Epoch 5 Iter 7000, train entropy gap -19.1933 bits (loss 0.187, data 19.381) 
Epoch 5 Iter 7200, train entropy gap -19.1702 bits (loss 0.211, data 19.381) 
epoch 5 train loss 0.1250 nats / 0.1804 bits
time since start: 540.1 secs
Epoch 6 Iter 0, train entropy gap -19.2520 bits (loss 0.129, data 19.381) 
Epoch 6 Iter 200, train entropy gap -19.1007 bits (loss 0.280, data 19.381) 
Epoch 6 Iter 400, train entropy gap -19.2466 bits (loss 0.134, data 19.381) 
Epoch 6 Iter 600, train entropy gap -19.1821 bits (loss 0.199, data 19.381) 
Epoch 6 Iter 800, train entropy gap -19.1848 bits (loss 0.196, data 19.381) 
Epoch 6 Iter 1000, train entropy gap -19.2105 bits (loss 0.170, data 19.381) 
Epoch 6 Iter 1200, train entropy gap -19.2360 bits (loss 0.145, data 19.381) 
Epoch 6 Iter 1400, train entropy gap -19.1767 bits (loss 0.204, data 19.381) 
Epoch 6 Iter 1600, train entropy gap -19.2239 bits (loss 0.157, data 19.381) 
Epoch 6 Iter 1800, train entropy gap -19.1668 bits (loss 0.214, data 19.381) 
Epoch 6 Iter 2000, train entropy gap -19.2139 bits (loss 0.167, data 19.381) 
Epoch 6 Iter 2200, train entropy gap -19.2189 bits (loss 0.162, data 19.381) 
Epoch 6 Iter 2400, train entropy gap -19.1891 bits (loss 0.192, data 19.381) 
Epoch 6 Iter 2600, train entropy gap -19.1394 bits (loss 0.241, data 19.381) 
Epoch 6 Iter 2800, train entropy gap -19.2420 bits (loss 0.139, data 19.381) 
Epoch 6 Iter 3000, train entropy gap -19.1794 bits (loss 0.201, data 19.381) 
Epoch 6 Iter 3200, train entropy gap -19.2664 bits (loss 0.114, data 19.381) 
Epoch 6 Iter 3400, train entropy gap -19.2419 bits (loss 0.139, data 19.381) 
Epoch 6 Iter 3600, train entropy gap -19.2102 bits (loss 0.171, data 19.381) 
Epoch 6 Iter 3800, train entropy gap -19.2468 bits (loss 0.134, data 19.381) 
Epoch 6 Iter 4000, train entropy gap -19.2600 bits (loss 0.121, data 19.381) 
Epoch 6 Iter 4200, train entropy gap -19.2378 bits (loss 0.143, data 19.381) 
Epoch 6 Iter 4400, train entropy gap -19.2174 bits (loss 0.163, data 19.381) 
Epoch 6 Iter 4600, train entropy gap -19.2635 bits (loss 0.117, data 19.381) 
Epoch 6 Iter 4800, train entropy gap -19.2205 bits (loss 0.160, data 19.381) 
Epoch 6 Iter 5000, train entropy gap -19.1972 bits (loss 0.184, data 19.381) 
Epoch 6 Iter 5200, train entropy gap -19.2400 bits (loss 0.141, data 19.381) 
Epoch 6 Iter 5400, train entropy gap -19.2148 bits (loss 0.166, data 19.381) 
Epoch 6 Iter 5600, train entropy gap -19.1898 bits (loss 0.191, data 19.381) 
Epoch 6 Iter 5800, train entropy gap -19.2266 bits (loss 0.154, data 19.381) 
Epoch 6 Iter 6000, train entropy gap -19.2334 bits (loss 0.147, data 19.381) 
Epoch 6 Iter 6200, train entropy gap -19.2564 bits (loss 0.124, data 19.381) 
Epoch 6 Iter 6400, train entropy gap -19.2170 bits (loss 0.164, data 19.381) 
Epoch 6 Iter 6600, train entropy gap -19.2235 bits (loss 0.157, data 19.381) 
Epoch 6 Iter 6800, train entropy gap -19.2527 bits (loss 0.128, data 19.381) 
Epoch 6 Iter 7000, train entropy gap -19.2065 bits (loss 0.174, data 19.381) 
Epoch 6 Iter 7200, train entropy gap -19.2373 bits (loss 0.144, data 19.381) 
epoch 6 train loss 0.1099 nats / 0.1586 bits
time since start: 629.3 secs
Epoch 7 Iter 0, train entropy gap -19.1841 bits (loss 0.197, data 19.381) 
Epoch 7 Iter 200, train entropy gap -19.2915 bits (loss 0.089, data 19.381) 
Epoch 7 Iter 400, train entropy gap -19.2003 bits (loss 0.180, data 19.381) 
Epoch 7 Iter 600, train entropy gap -19.2715 bits (loss 0.109, data 19.381) 
Epoch 7 Iter 800, train entropy gap -19.2910 bits (loss 0.090, data 19.381) 
Epoch 7 Iter 1000, train entropy gap -19.2420 bits (loss 0.139, data 19.381) 
Epoch 7 Iter 1200, train entropy gap -19.2557 bits (loss 0.125, data 19.381) 
Epoch 7 Iter 1400, train entropy gap -19.2731 bits (loss 0.108, data 19.381) 
Epoch 7 Iter 1600, train entropy gap -19.2832 bits (loss 0.098, data 19.381) 
Epoch 7 Iter 1800, train entropy gap -19.2576 bits (loss 0.123, data 19.381) 
Epoch 7 Iter 2000, train entropy gap -19.2609 bits (loss 0.120, data 19.381) 
Epoch 7 Iter 2200, train entropy gap -19.2322 bits (loss 0.149, data 19.381) 
Epoch 7 Iter 2400, train entropy gap -19.2424 bits (loss 0.138, data 19.381) 
Epoch 7 Iter 2600, train entropy gap -19.2704 bits (loss 0.110, data 19.381) 
Epoch 7 Iter 2800, train entropy gap -19.2228 bits (loss 0.158, data 19.381) 
Epoch 7 Iter 3000, train entropy gap -19.2393 bits (loss 0.142, data 19.381) 
Epoch 7 Iter 3200, train entropy gap -19.2463 bits (loss 0.135, data 19.381) 
Epoch 7 Iter 3400, train entropy gap -19.2407 bits (loss 0.140, data 19.381) 
Epoch 7 Iter 3600, train entropy gap -19.2487 bits (loss 0.132, data 19.381) 
Epoch 7 Iter 3800, train entropy gap -19.2384 bits (loss 0.142, data 19.381) 
Epoch 7 Iter 4000, train entropy gap -19.2790 bits (loss 0.102, data 19.381) 
Epoch 7 Iter 4200, train entropy gap -19.2407 bits (loss 0.140, data 19.381) 
Epoch 7 Iter 4400, train entropy gap -19.2068 bits (loss 0.174, data 19.381) 
Epoch 7 Iter 4600, train entropy gap -19.2430 bits (loss 0.138, data 19.381) 
Epoch 7 Iter 4800, train entropy gap -19.2347 bits (loss 0.146, data 19.381) 
Epoch 7 Iter 5000, train entropy gap -19.2416 bits (loss 0.139, data 19.381) 
Epoch 7 Iter 5200, train entropy gap -19.2887 bits (loss 0.092, data 19.381) 
Epoch 7 Iter 5400, train entropy gap -19.2392 bits (loss 0.142, data 19.381) 
Epoch 7 Iter 5600, train entropy gap -19.2414 bits (loss 0.139, data 19.381) 
Epoch 7 Iter 5800, train entropy gap -19.2202 bits (loss 0.161, data 19.381) 
Epoch 7 Iter 6000, train entropy gap -19.1863 bits (loss 0.194, data 19.381) 
Epoch 7 Iter 6200, train entropy gap -19.2820 bits (loss 0.099, data 19.381) 
Epoch 7 Iter 6400, train entropy gap -19.2262 bits (loss 0.155, data 19.381) 
Epoch 7 Iter 6600, train entropy gap -19.2431 bits (loss 0.138, data 19.381) 
Epoch 7 Iter 6800, train entropy gap -19.2168 bits (loss 0.164, data 19.381) 
Epoch 7 Iter 7000, train entropy gap -19.2451 bits (loss 0.136, data 19.381) 
Epoch 7 Iter 7200, train entropy gap -19.2051 bits (loss 0.176, data 19.381) 
epoch 7 train loss 0.0989 nats / 0.1426 bits
time since start: 720.3 secs
Epoch 8 Iter 0, train entropy gap -19.2790 bits (loss 0.102, data 19.381) 
Epoch 8 Iter 200, train entropy gap -19.2581 bits (loss 0.123, data 19.381) 
Epoch 8 Iter 400, train entropy gap -19.2682 bits (loss 0.113, data 19.381) 
Epoch 8 Iter 600, train entropy gap -19.3017 bits (loss 0.079, data 19.381) 
Epoch 8 Iter 800, train entropy gap -19.2636 bits (loss 0.117, data 19.381) 
Epoch 8 Iter 1000, train entropy gap -19.2396 bits (loss 0.141, data 19.381) 
Epoch 8 Iter 1200, train entropy gap -19.2107 bits (loss 0.170, data 19.381) 
Epoch 8 Iter 1400, train entropy gap -19.1871 bits (loss 0.194, data 19.381) 
Epoch 8 Iter 1600, train entropy gap -19.2592 bits (loss 0.122, data 19.381) 
Epoch 8 Iter 1800, train entropy gap -19.2746 bits (loss 0.106, data 19.381) 
Epoch 8 Iter 2000, train entropy gap -19.2569 bits (loss 0.124, data 19.381) 
Epoch 8 Iter 2200, train entropy gap -19.2795 bits (loss 0.101, data 19.381) 
Epoch 8 Iter 2400, train entropy gap -19.2219 bits (loss 0.159, data 19.381) 
Epoch 8 Iter 2600, train entropy gap -19.2085 bits (loss 0.172, data 19.381) 
Epoch 8 Iter 2800, train entropy gap -19.2429 bits (loss 0.138, data 19.381) 
Epoch 8 Iter 3000, train entropy gap -19.2845 bits (loss 0.096, data 19.381) 
Epoch 8 Iter 3200, train entropy gap -19.2499 bits (loss 0.131, data 19.381) 
Epoch 8 Iter 3400, train entropy gap -19.2472 bits (loss 0.134, data 19.381) 
Epoch 8 Iter 3600, train entropy gap -19.2647 bits (loss 0.116, data 19.381) 
Epoch 8 Iter 3800, train entropy gap -19.2029 bits (loss 0.178, data 19.381) 
Epoch 8 Iter 4000, train entropy gap -19.2508 bits (loss 0.130, data 19.381) 
Epoch 8 Iter 4200, train entropy gap -19.2853 bits (loss 0.096, data 19.381) 
Epoch 8 Iter 4400, train entropy gap -19.2999 bits (loss 0.081, data 19.381) 
Epoch 8 Iter 4600, train entropy gap -19.2627 bits (loss 0.118, data 19.381) 
Epoch 8 Iter 4800, train entropy gap -19.2945 bits (loss 0.086, data 19.381) 
Epoch 8 Iter 5000, train entropy gap -19.2615 bits (loss 0.119, data 19.381) 
Epoch 8 Iter 5200, train entropy gap -19.2755 bits (loss 0.105, data 19.381) 
Epoch 8 Iter 5400, train entropy gap -19.2167 bits (loss 0.164, data 19.381) 
Epoch 8 Iter 5600, train entropy gap -19.2560 bits (loss 0.125, data 19.381) 
Epoch 8 Iter 5800, train entropy gap -19.2568 bits (loss 0.124, data 19.381) 
Epoch 8 Iter 6000, train entropy gap -19.2669 bits (loss 0.114, data 19.381) 
Epoch 8 Iter 6200, train entropy gap -19.2790 bits (loss 0.102, data 19.381) 
Epoch 8 Iter 6400, train entropy gap -19.2495 bits (loss 0.131, data 19.381) 
Epoch 8 Iter 6600, train entropy gap -19.2779 bits (loss 0.103, data 19.381) 
Epoch 8 Iter 6800, train entropy gap -19.2210 bits (loss 0.160, data 19.381) 
Epoch 8 Iter 7000, train entropy gap -19.2571 bits (loss 0.124, data 19.381) 
Epoch 8 Iter 7200, train entropy gap -19.2349 bits (loss 0.146, data 19.381) 
epoch 8 train loss 0.0911 nats / 0.1315 bits
time since start: 810.2 secs
Epoch 9 Iter 0, train entropy gap -19.2706 bits (loss 0.110, data 19.381) 
Epoch 9 Iter 200, train entropy gap -19.2478 bits (loss 0.133, data 19.381) 
Epoch 9 Iter 400, train entropy gap -19.2793 bits (loss 0.102, data 19.381) 
Epoch 9 Iter 600, train entropy gap -19.2917 bits (loss 0.089, data 19.381) 
Epoch 9 Iter 800, train entropy gap -19.2526 bits (loss 0.128, data 19.381) 
Epoch 9 Iter 1000, train entropy gap -19.2653 bits (loss 0.116, data 19.381) 
Epoch 9 Iter 1200, train entropy gap -19.2669 bits (loss 0.114, data 19.381) 
Epoch 9 Iter 1400, train entropy gap -19.2286 bits (loss 0.152, data 19.381) 
Epoch 9 Iter 1600, train entropy gap -19.2585 bits (loss 0.122, data 19.381) 
Epoch 9 Iter 1800, train entropy gap -19.2630 bits (loss 0.118, data 19.381) 
Epoch 9 Iter 2000, train entropy gap -19.2514 bits (loss 0.129, data 19.381) 
Epoch 9 Iter 2200, train entropy gap -19.2560 bits (loss 0.125, data 19.381) 
Epoch 9 Iter 2400, train entropy gap -19.2719 bits (loss 0.109, data 19.381) 
Epoch 9 Iter 2600, train entropy gap -19.3096 bits (loss 0.071, data 19.381) 
Epoch 9 Iter 2800, train entropy gap -19.2819 bits (loss 0.099, data 19.381) 
Epoch 9 Iter 3000, train entropy gap -19.2609 bits (loss 0.120, data 19.381) 
Epoch 9 Iter 3200, train entropy gap -19.2807 bits (loss 0.100, data 19.381) 
Epoch 9 Iter 3400, train entropy gap -19.2473 bits (loss 0.134, data 19.381) 
Epoch 9 Iter 3600, train entropy gap -19.2759 bits (loss 0.105, data 19.381) 
Epoch 9 Iter 3800, train entropy gap -19.2370 bits (loss 0.144, data 19.381) 
Epoch 9 Iter 4000, train entropy gap -19.2140 bits (loss 0.167, data 19.381) 
Epoch 9 Iter 4200, train entropy gap -19.2538 bits (loss 0.127, data 19.381) 
Epoch 9 Iter 4400, train entropy gap -19.2673 bits (loss 0.113, data 19.381) 
Epoch 9 Iter 4600, train entropy gap -19.2550 bits (loss 0.126, data 19.381) 
Epoch 9 Iter 4800, train entropy gap -19.2145 bits (loss 0.166, data 19.381) 
Epoch 9 Iter 5000, train entropy gap -19.2515 bits (loss 0.129, data 19.381) 
Epoch 9 Iter 5200, train entropy gap -19.2651 bits (loss 0.116, data 19.381) 
Epoch 9 Iter 5400, train entropy gap -19.2696 bits (loss 0.111, data 19.381) 
Epoch 9 Iter 5600, train entropy gap -19.2847 bits (loss 0.096, data 19.381) 
Epoch 9 Iter 5800, train entropy gap -19.2415 bits (loss 0.139, data 19.381) 
Epoch 9 Iter 6000, train entropy gap -19.2500 bits (loss 0.131, data 19.381) 
Epoch 9 Iter 6200, train entropy gap -19.2350 bits (loss 0.146, data 19.381) 
Epoch 9 Iter 6400, train entropy gap -19.2276 bits (loss 0.153, data 19.381) 
Epoch 9 Iter 6600, train entropy gap -19.2711 bits (loss 0.110, data 19.381) 
Epoch 9 Iter 6800, train entropy gap -19.2525 bits (loss 0.128, data 19.381) 
Epoch 9 Iter 7000, train entropy gap -19.2933 bits (loss 0.088, data 19.381) 
Epoch 9 Iter 7200, train entropy gap -19.2935 bits (loss 0.087, data 19.381) 
epoch 9 train loss 0.0857 nats / 0.1236 bits
time since start: 900.5 secs
Epoch 10 Iter 0, train entropy gap -19.2445 bits (loss 0.136, data 19.381) 
Epoch 10 Iter 200, train entropy gap -19.2725 bits (loss 0.108, data 19.381) 
Epoch 10 Iter 400, train entropy gap -19.2516 bits (loss 0.129, data 19.381) 
Epoch 10 Iter 600, train entropy gap -19.2765 bits (loss 0.104, data 19.381) 
Epoch 10 Iter 800, train entropy gap -19.2515 bits (loss 0.129, data 19.381) 
Epoch 10 Iter 1000, train entropy gap -19.2391 bits (loss 0.142, data 19.381) 
Epoch 10 Iter 1200, train entropy gap -19.2754 bits (loss 0.105, data 19.381) 
Epoch 10 Iter 1400, train entropy gap -19.2850 bits (loss 0.096, data 19.381) 
Epoch 10 Iter 1600, train entropy gap -19.2725 bits (loss 0.108, data 19.381) 
Epoch 10 Iter 1800, train entropy gap -19.2815 bits (loss 0.099, data 19.381) 
Epoch 10 Iter 2000, train entropy gap -19.2870 bits (loss 0.094, data 19.381) 
Epoch 10 Iter 2200, train entropy gap -19.2288 bits (loss 0.152, data 19.381) 
Epoch 10 Iter 2400, train entropy gap -19.2494 bits (loss 0.131, data 19.381) 
Epoch 10 Iter 2600, train entropy gap -19.3386 bits (loss 0.042, data 19.381) 
Epoch 10 Iter 2800, train entropy gap -19.2567 bits (loss 0.124, data 19.381) 
Epoch 10 Iter 3000, train entropy gap -19.3041 bits (loss 0.077, data 19.381) 
Epoch 10 Iter 3200, train entropy gap -19.3395 bits (loss 0.041, data 19.381) 
Epoch 10 Iter 3400, train entropy gap -19.2494 bits (loss 0.131, data 19.381) 
Epoch 10 Iter 3600, train entropy gap -19.2631 bits (loss 0.118, data 19.381) 
Epoch 10 Iter 3800, train entropy gap -19.2544 bits (loss 0.126, data 19.381) 
Epoch 10 Iter 4000, train entropy gap -19.2319 bits (loss 0.149, data 19.381) 
Epoch 10 Iter 4200, train entropy gap -19.2829 bits (loss 0.098, data 19.381) 
Epoch 10 Iter 4400, train entropy gap -19.2737 bits (loss 0.107, data 19.381) 
Epoch 10 Iter 4600, train entropy gap -19.3130 bits (loss 0.068, data 19.381) 
Epoch 10 Iter 4800, train entropy gap -19.2575 bits (loss 0.123, data 19.381) 
Epoch 10 Iter 5000, train entropy gap -19.2221 bits (loss 0.159, data 19.381) 
Epoch 10 Iter 5200, train entropy gap -19.2305 bits (loss 0.150, data 19.381) 
Epoch 10 Iter 5400, train entropy gap -19.2176 bits (loss 0.163, data 19.381) 
Epoch 10 Iter 5600, train entropy gap -19.2670 bits (loss 0.114, data 19.381) 
Epoch 10 Iter 5800, train entropy gap -19.2626 bits (loss 0.118, data 19.381) 
Epoch 10 Iter 6000, train entropy gap -19.2612 bits (loss 0.120, data 19.381) 
Epoch 10 Iter 6200, train entropy gap -19.2659 bits (loss 0.115, data 19.381) 
Epoch 10 Iter 6400, train entropy gap -19.2526 bits (loss 0.128, data 19.381) 
Epoch 10 Iter 6600, train entropy gap -19.2781 bits (loss 0.103, data 19.381) 
Epoch 10 Iter 6800, train entropy gap -19.2958 bits (loss 0.085, data 19.381) 
Epoch 10 Iter 7000, train entropy gap -19.1960 bits (loss 0.185, data 19.381) 
Epoch 10 Iter 7200, train entropy gap -19.1974 bits (loss 0.183, data 19.381) 
epoch 10 train loss 0.0813 nats / 0.1173 bits
time since start: 990.8 secs
Epoch 11 Iter 0, train entropy gap -19.2536 bits (loss 0.127, data 19.381) 
Epoch 11 Iter 200, train entropy gap -19.2458 bits (loss 0.135, data 19.381) 
Epoch 11 Iter 400, train entropy gap -19.2596 bits (loss 0.121, data 19.381) 
Epoch 11 Iter 600, train entropy gap -19.2576 bits (loss 0.123, data 19.381) 
Epoch 11 Iter 800, train entropy gap -19.2326 bits (loss 0.148, data 19.381) 
Epoch 11 Iter 1000, train entropy gap -19.2672 bits (loss 0.114, data 19.381) 
Epoch 11 Iter 1200, train entropy gap -19.3094 bits (loss 0.071, data 19.381) 
Epoch 11 Iter 1400, train entropy gap -19.3128 bits (loss 0.068, data 19.381) 
Epoch 11 Iter 1600, train entropy gap -19.2869 bits (loss 0.094, data 19.381) 
Epoch 11 Iter 1800, train entropy gap -19.2452 bits (loss 0.136, data 19.381) 
Epoch 11 Iter 2000, train entropy gap -19.2594 bits (loss 0.121, data 19.381) 
Epoch 11 Iter 2200, train entropy gap -19.2592 bits (loss 0.122, data 19.381) 
Epoch 11 Iter 2400, train entropy gap -19.2969 bits (loss 0.084, data 19.381) 
Epoch 11 Iter 2600, train entropy gap -19.3045 bits (loss 0.076, data 19.381) 
Epoch 11 Iter 2800, train entropy gap -19.2905 bits (loss 0.090, data 19.381) 
Epoch 11 Iter 3000, train entropy gap -19.2883 bits (loss 0.092, data 19.381) 
Epoch 11 Iter 3200, train entropy gap -19.2836 bits (loss 0.097, data 19.381) 
Epoch 11 Iter 3400, train entropy gap -19.2610 bits (loss 0.120, data 19.381) 
Epoch 11 Iter 3600, train entropy gap -19.2428 bits (loss 0.138, data 19.381) 
Epoch 11 Iter 3800, train entropy gap -19.2695 bits (loss 0.111, data 19.381) 
Epoch 11 Iter 4000, train entropy gap -19.2958 bits (loss 0.085, data 19.381) 
Epoch 11 Iter 4200, train entropy gap -19.2685 bits (loss 0.112, data 19.381) 
Epoch 11 Iter 4400, train entropy gap -19.2760 bits (loss 0.105, data 19.381) 
Epoch 11 Iter 4600, train entropy gap -19.2629 bits (loss 0.118, data 19.381) 
Epoch 11 Iter 4800, train entropy gap -19.2726 bits (loss 0.108, data 19.381) 
Epoch 11 Iter 5000, train entropy gap -19.2634 bits (loss 0.117, data 19.381) 
Epoch 11 Iter 5200, train entropy gap -19.2349 bits (loss 0.146, data 19.381) 
Epoch 11 Iter 5400, train entropy gap -19.2941 bits (loss 0.087, data 19.381) 
Epoch 11 Iter 5600, train entropy gap -19.2963 bits (loss 0.085, data 19.381) 
Epoch 11 Iter 5800, train entropy gap -19.2232 bits (loss 0.158, data 19.381) 
Epoch 11 Iter 6000, train entropy gap -19.2543 bits (loss 0.127, data 19.381) 
Epoch 11 Iter 6200, train entropy gap -19.2726 bits (loss 0.108, data 19.381) 
Epoch 11 Iter 6400, train entropy gap -19.1950 bits (loss 0.186, data 19.381) 
Epoch 11 Iter 6600, train entropy gap -19.3113 bits (loss 0.070, data 19.381) 
Epoch 11 Iter 6800, train entropy gap -19.2960 bits (loss 0.085, data 19.381) 
Epoch 11 Iter 7000, train entropy gap -19.3238 bits (loss 0.057, data 19.381) 
Epoch 11 Iter 7200, train entropy gap -19.2405 bits (loss 0.140, data 19.381) 
epoch 11 train loss 0.0778 nats / 0.1122 bits
time since start: 1080.6 secs
Epoch 12 Iter 0, train entropy gap -19.2431 bits (loss 0.138, data 19.381) 
Epoch 12 Iter 200, train entropy gap -19.2760 bits (loss 0.105, data 19.381) 
Epoch 12 Iter 400, train entropy gap -19.3087 bits (loss 0.072, data 19.381) 
Epoch 12 Iter 600, train entropy gap -19.2656 bits (loss 0.115, data 19.381) 
Epoch 12 Iter 800, train entropy gap -19.2543 bits (loss 0.126, data 19.381) 
Epoch 12 Iter 1000, train entropy gap -19.3175 bits (loss 0.063, data 19.381) 
Epoch 12 Iter 1200, train entropy gap -19.2945 bits (loss 0.086, data 19.381) 
Epoch 12 Iter 1400, train entropy gap -19.2607 bits (loss 0.120, data 19.381) 
Epoch 12 Iter 1600, train entropy gap -19.2990 bits (loss 0.082, data 19.381) 
Epoch 12 Iter 1800, train entropy gap -19.2854 bits (loss 0.095, data 19.381) 
Epoch 12 Iter 2000, train entropy gap -19.2717 bits (loss 0.109, data 19.381) 
Epoch 12 Iter 2200, train entropy gap -19.3137 bits (loss 0.067, data 19.381) 
Epoch 12 Iter 2400, train entropy gap -19.2919 bits (loss 0.089, data 19.381) 
Epoch 12 Iter 2600, train entropy gap -19.2633 bits (loss 0.117, data 19.381) 
Epoch 12 Iter 2800, train entropy gap -19.2669 bits (loss 0.114, data 19.381) 
Epoch 12 Iter 3000, train entropy gap -19.2555 bits (loss 0.125, data 19.381) 
Epoch 12 Iter 3200, train entropy gap -19.2453 bits (loss 0.136, data 19.381) 
Epoch 12 Iter 3400, train entropy gap -19.2726 bits (loss 0.108, data 19.381) 
Epoch 12 Iter 3600, train entropy gap -19.2585 bits (loss 0.122, data 19.381) 
Epoch 12 Iter 3800, train entropy gap -19.2731 bits (loss 0.108, data 19.381) 
Epoch 12 Iter 4000, train entropy gap -19.3207 bits (loss 0.060, data 19.381) 
Epoch 12 Iter 4200, train entropy gap -19.3105 bits (loss 0.070, data 19.381) 
Epoch 12 Iter 4400, train entropy gap -19.2720 bits (loss 0.109, data 19.381) 
Epoch 12 Iter 4600, train entropy gap -19.2947 bits (loss 0.086, data 19.381) 
Epoch 12 Iter 4800, train entropy gap -19.2645 bits (loss 0.116, data 19.381) 
Epoch 12 Iter 5000, train entropy gap -19.2469 bits (loss 0.134, data 19.381) 
Epoch 12 Iter 5200, train entropy gap -19.1786 bits (loss 0.202, data 19.381) 
Epoch 12 Iter 5400, train entropy gap -19.2613 bits (loss 0.119, data 19.381) 
Epoch 12 Iter 5600, train entropy gap -19.2345 bits (loss 0.146, data 19.381) 
Epoch 12 Iter 5800, train entropy gap -19.2332 bits (loss 0.148, data 19.381) 
Epoch 12 Iter 6000, train entropy gap -19.2455 bits (loss 0.135, data 19.381) 
Epoch 12 Iter 6200, train entropy gap -19.3099 bits (loss 0.071, data 19.381) 
Epoch 12 Iter 6400, train entropy gap -19.2631 bits (loss 0.118, data 19.381) 
Epoch 12 Iter 6600, train entropy gap -19.2489 bits (loss 0.132, data 19.381) 
Epoch 12 Iter 6800, train entropy gap -19.2763 bits (loss 0.105, data 19.381) 
Epoch 12 Iter 7000, train entropy gap -19.2728 bits (loss 0.108, data 19.381) 
Epoch 12 Iter 7200, train entropy gap -19.2801 bits (loss 0.101, data 19.381) 
epoch 12 train loss 0.0746 nats / 0.1077 bits
time since start: 1170.0 secs
Epoch 13 Iter 0, train entropy gap -19.2958 bits (loss 0.085, data 19.381) 
Epoch 13 Iter 200, train entropy gap -19.2941 bits (loss 0.087, data 19.381) 
Epoch 13 Iter 400, train entropy gap -19.3335 bits (loss 0.047, data 19.381) 
Epoch 13 Iter 600, train entropy gap -19.2582 bits (loss 0.123, data 19.381) 
Epoch 13 Iter 800, train entropy gap -19.2870 bits (loss 0.094, data 19.381) 
Epoch 13 Iter 1000, train entropy gap -19.2785 bits (loss 0.102, data 19.381) 
Epoch 13 Iter 1200, train entropy gap -19.3037 bits (loss 0.077, data 19.381) 
Epoch 13 Iter 1400, train entropy gap -19.2741 bits (loss 0.107, data 19.381) 
Epoch 13 Iter 1600, train entropy gap -19.2671 bits (loss 0.114, data 19.381) 
Epoch 13 Iter 1800, train entropy gap -19.2770 bits (loss 0.104, data 19.381) 
Epoch 13 Iter 2000, train entropy gap -19.2625 bits (loss 0.118, data 19.381) 
Epoch 13 Iter 2200, train entropy gap -19.2298 bits (loss 0.151, data 19.381) 
Epoch 13 Iter 2400, train entropy gap -19.3077 bits (loss 0.073, data 19.381) 
Epoch 13 Iter 2600, train entropy gap -19.3027 bits (loss 0.078, data 19.381) 
Epoch 13 Iter 2800, train entropy gap -19.2899 bits (loss 0.091, data 19.381) 
Epoch 13 Iter 3000, train entropy gap -19.2625 bits (loss 0.118, data 19.381) 
Epoch 13 Iter 3200, train entropy gap -19.2587 bits (loss 0.122, data 19.381) 
Epoch 13 Iter 3400, train entropy gap -19.2888 bits (loss 0.092, data 19.381) 
Epoch 13 Iter 3600, train entropy gap -19.3263 bits (loss 0.054, data 19.381) 
Epoch 13 Iter 3800, train entropy gap -19.3194 bits (loss 0.061, data 19.381) 
Epoch 13 Iter 4000, train entropy gap -19.3080 bits (loss 0.073, data 19.381) 
Epoch 13 Iter 4200, train entropy gap -19.2546 bits (loss 0.126, data 19.381) 
Epoch 13 Iter 4400, train entropy gap -19.2847 bits (loss 0.096, data 19.381) 
Epoch 13 Iter 4600, train entropy gap -19.3465 bits (loss 0.034, data 19.381) 
Epoch 13 Iter 4800, train entropy gap -19.2962 bits (loss 0.085, data 19.381) 
Epoch 13 Iter 5000, train entropy gap -19.3169 bits (loss 0.064, data 19.381) 
Epoch 13 Iter 5200, train entropy gap -19.2951 bits (loss 0.086, data 19.381) 
Epoch 13 Iter 5400, train entropy gap -19.2584 bits (loss 0.122, data 19.381) 
Epoch 13 Iter 5600, train entropy gap -19.3293 bits (loss 0.052, data 19.381) 
Epoch 13 Iter 5800, train entropy gap -19.2660 bits (loss 0.115, data 19.381) 
Epoch 13 Iter 6000, train entropy gap -19.3133 bits (loss 0.067, data 19.381) 
Epoch 13 Iter 6200, train entropy gap -19.2775 bits (loss 0.103, data 19.381) 
Epoch 13 Iter 6400, train entropy gap -19.3098 bits (loss 0.071, data 19.381) 
Epoch 13 Iter 6600, train entropy gap -19.2834 bits (loss 0.097, data 19.381) 
Epoch 13 Iter 6800, train entropy gap -19.1945 bits (loss 0.186, data 19.381) 
Epoch 13 Iter 7000, train entropy gap -19.2805 bits (loss 0.100, data 19.381) 
Epoch 13 Iter 7200, train entropy gap -19.2585 bits (loss 0.122, data 19.381) 
epoch 13 train loss 0.0722 nats / 0.1042 bits
time since start: 1259.3 secs
Epoch 14 Iter 0, train entropy gap -19.2826 bits (loss 0.098, data 19.381) 
Epoch 14 Iter 200, train entropy gap -19.2460 bits (loss 0.135, data 19.381) 
Epoch 14 Iter 400, train entropy gap -19.2352 bits (loss 0.146, data 19.381) 
Epoch 14 Iter 600, train entropy gap -19.3009 bits (loss 0.080, data 19.381) 
Epoch 14 Iter 800, train entropy gap -19.3016 bits (loss 0.079, data 19.381) 
Epoch 14 Iter 1000, train entropy gap -19.2938 bits (loss 0.087, data 19.381) 
Epoch 14 Iter 1200, train entropy gap -19.3006 bits (loss 0.080, data 19.381) 
Epoch 14 Iter 1400, train entropy gap -19.3241 bits (loss 0.057, data 19.381) 
Epoch 14 Iter 1600, train entropy gap -19.2889 bits (loss 0.092, data 19.381) 
Epoch 14 Iter 1800, train entropy gap -19.2569 bits (loss 0.124, data 19.381) 
Epoch 14 Iter 2000, train entropy gap -19.2842 bits (loss 0.097, data 19.381) 
Epoch 14 Iter 2200, train entropy gap -19.3176 bits (loss 0.063, data 19.381) 
Epoch 14 Iter 2400, train entropy gap -19.2836 bits (loss 0.097, data 19.381) 
Epoch 14 Iter 2600, train entropy gap -19.2747 bits (loss 0.106, data 19.381) 
Epoch 14 Iter 2800, train entropy gap -19.2390 bits (loss 0.142, data 19.381) 
Epoch 14 Iter 3000, train entropy gap -19.2950 bits (loss 0.086, data 19.381) 
Epoch 14 Iter 3200, train entropy gap -19.2332 bits (loss 0.148, data 19.381) 
Epoch 14 Iter 3400, train entropy gap -19.2897 bits (loss 0.091, data 19.381) 
Epoch 14 Iter 3600, train entropy gap -19.3035 bits (loss 0.077, data 19.381) 
Epoch 14 Iter 3800, train entropy gap -19.2622 bits (loss 0.119, data 19.381) 
Epoch 14 Iter 4000, train entropy gap -19.3119 bits (loss 0.069, data 19.381) 
Epoch 14 Iter 4200, train entropy gap -19.2910 bits (loss 0.090, data 19.381) 
Epoch 14 Iter 4400, train entropy gap -19.2557 bits (loss 0.125, data 19.381) 
Epoch 14 Iter 4600, train entropy gap -19.2162 bits (loss 0.165, data 19.381) 
Epoch 14 Iter 4800, train entropy gap -19.2658 bits (loss 0.115, data 19.381) 
Epoch 14 Iter 5000, train entropy gap -19.2645 bits (loss 0.116, data 19.381) 
Epoch 14 Iter 5200, train entropy gap -19.3225 bits (loss 0.058, data 19.381) 
Epoch 14 Iter 5400, train entropy gap -19.2765 bits (loss 0.104, data 19.381) 
Epoch 14 Iter 5600, train entropy gap -19.2908 bits (loss 0.090, data 19.381) 
Epoch 14 Iter 5800, train entropy gap -19.2575 bits (loss 0.123, data 19.381) 
Epoch 14 Iter 6000, train entropy gap -19.2947 bits (loss 0.086, data 19.381) 
Epoch 14 Iter 6200, train entropy gap -19.2524 bits (loss 0.128, data 19.381) 
Epoch 14 Iter 6400, train entropy gap -19.3053 bits (loss 0.076, data 19.381) 
Epoch 14 Iter 6600, train entropy gap -19.3000 bits (loss 0.081, data 19.381) 
Epoch 14 Iter 6800, train entropy gap -19.2917 bits (loss 0.089, data 19.381) 
Epoch 14 Iter 7000, train entropy gap -19.2616 bits (loss 0.119, data 19.381) 
Epoch 14 Iter 7200, train entropy gap -19.2511 bits (loss 0.130, data 19.381) 
epoch 14 train loss 0.0705 nats / 0.1017 bits
time since start: 1349.5 secs
Epoch 15 Iter 0, train entropy gap -19.2422 bits (loss 0.139, data 19.381) 
Epoch 15 Iter 200, train entropy gap -19.2792 bits (loss 0.102, data 19.381) 
Epoch 15 Iter 400, train entropy gap -19.3118 bits (loss 0.069, data 19.381) 
Epoch 15 Iter 600, train entropy gap -19.3212 bits (loss 0.060, data 19.381) 
Epoch 15 Iter 800, train entropy gap -19.2765 bits (loss 0.104, data 19.381) 
Epoch 15 Iter 1000, train entropy gap -19.2987 bits (loss 0.082, data 19.381) 
Epoch 15 Iter 1200, train entropy gap -19.2573 bits (loss 0.123, data 19.381) 
Epoch 15 Iter 1400, train entropy gap -19.3139 bits (loss 0.067, data 19.381) 
Epoch 15 Iter 1600, train entropy gap -19.2820 bits (loss 0.099, data 19.381) 
Epoch 15 Iter 1800, train entropy gap -19.2696 bits (loss 0.111, data 19.381) 
Epoch 15 Iter 2000, train entropy gap -19.3223 bits (loss 0.058, data 19.381) 
Epoch 15 Iter 2200, train entropy gap -19.3020 bits (loss 0.079, data 19.381) 
Epoch 15 Iter 2400, train entropy gap -19.3124 bits (loss 0.068, data 19.381) 
Epoch 15 Iter 2600, train entropy gap -19.3318 bits (loss 0.049, data 19.381) 
Epoch 15 Iter 2800, train entropy gap -19.3318 bits (loss 0.049, data 19.381) 
Epoch 15 Iter 3000, train entropy gap -19.2920 bits (loss 0.089, data 19.381) 
Epoch 15 Iter 3200, train entropy gap -19.2951 bits (loss 0.086, data 19.381) 
Epoch 15 Iter 3400, train entropy gap -19.2795 bits (loss 0.101, data 19.381) 
Epoch 15 Iter 3600, train entropy gap -19.3106 bits (loss 0.070, data 19.381) 
Epoch 15 Iter 3800, train entropy gap -19.2501 bits (loss 0.131, data 19.381) 
Epoch 15 Iter 4000, train entropy gap -19.3039 bits (loss 0.077, data 19.381) 
Epoch 15 Iter 4200, train entropy gap -19.2823 bits (loss 0.099, data 19.381) 
Epoch 15 Iter 4400, train entropy gap -19.2814 bits (loss 0.099, data 19.381) 
Epoch 15 Iter 4600, train entropy gap -19.2364 bits (loss 0.144, data 19.381) 
Epoch 15 Iter 4800, train entropy gap -19.3061 bits (loss 0.075, data 19.381) 
Epoch 15 Iter 5000, train entropy gap -19.2572 bits (loss 0.124, data 19.381) 
Epoch 15 Iter 5200, train entropy gap -19.3214 bits (loss 0.059, data 19.381) 
Epoch 15 Iter 5400, train entropy gap -19.2891 bits (loss 0.092, data 19.381) 
Epoch 15 Iter 5600, train entropy gap -19.2751 bits (loss 0.106, data 19.381) 
Epoch 15 Iter 5800, train entropy gap -19.2624 bits (loss 0.118, data 19.381) 
Epoch 15 Iter 6000, train entropy gap -19.2442 bits (loss 0.137, data 19.381) 
Epoch 15 Iter 6200, train entropy gap -19.2597 bits (loss 0.121, data 19.381) 
Epoch 15 Iter 6400, train entropy gap -19.3252 bits (loss 0.056, data 19.381) 
Epoch 15 Iter 6600, train entropy gap -19.2280 bits (loss 0.153, data 19.381) 
Epoch 15 Iter 6800, train entropy gap -19.2910 bits (loss 0.090, data 19.381) 
Epoch 15 Iter 7000, train entropy gap -19.3073 bits (loss 0.074, data 19.381) 
Epoch 15 Iter 7200, train entropy gap -19.2828 bits (loss 0.098, data 19.381) 
epoch 15 train loss 0.0692 nats / 0.0998 bits
time since start: 1438.8 secs
Epoch 16 Iter 0, train entropy gap -19.2780 bits (loss 0.103, data 19.381) 
Epoch 16 Iter 200, train entropy gap -19.3235 bits (loss 0.057, data 19.381) 
Epoch 16 Iter 400, train entropy gap -19.2849 bits (loss 0.096, data 19.381) 
Epoch 16 Iter 600, train entropy gap -19.2850 bits (loss 0.096, data 19.381) 
Epoch 16 Iter 800, train entropy gap -19.2888 bits (loss 0.092, data 19.381) 
Epoch 16 Iter 1000, train entropy gap -19.3060 bits (loss 0.075, data 19.381) 
Epoch 16 Iter 1200, train entropy gap -19.2937 bits (loss 0.087, data 19.381) 
Epoch 16 Iter 1400, train entropy gap -19.2806 bits (loss 0.100, data 19.381) 
Epoch 16 Iter 1600, train entropy gap -19.3220 bits (loss 0.059, data 19.381) 
Epoch 16 Iter 1800, train entropy gap -19.2822 bits (loss 0.099, data 19.381) 
Epoch 16 Iter 2000, train entropy gap -19.3137 bits (loss 0.067, data 19.381) 
Epoch 16 Iter 2200, train entropy gap -19.3411 bits (loss 0.040, data 19.381) 
Epoch 16 Iter 2400, train entropy gap -19.2760 bits (loss 0.105, data 19.381) 
Epoch 16 Iter 2600, train entropy gap -19.2896 bits (loss 0.091, data 19.381) 
Epoch 16 Iter 2800, train entropy gap -19.3097 bits (loss 0.071, data 19.381) 
Epoch 16 Iter 3000, train entropy gap -19.2622 bits (loss 0.119, data 19.381) 
Epoch 16 Iter 3200, train entropy gap -19.2869 bits (loss 0.094, data 19.381) 
Epoch 16 Iter 3400, train entropy gap -19.3195 bits (loss 0.061, data 19.381) 
Epoch 16 Iter 3600, train entropy gap -19.2727 bits (loss 0.108, data 19.381) 
Epoch 16 Iter 3800, train entropy gap -19.2885 bits (loss 0.092, data 19.381) 
Epoch 16 Iter 4000, train entropy gap -19.2801 bits (loss 0.101, data 19.381) 
Epoch 16 Iter 4200, train entropy gap -19.2931 bits (loss 0.088, data 19.381) 
Epoch 16 Iter 4400, train entropy gap -19.2418 bits (loss 0.139, data 19.381) 
Epoch 16 Iter 4600, train entropy gap -19.2745 bits (loss 0.106, data 19.381) 
Epoch 16 Iter 4800, train entropy gap -19.3043 bits (loss 0.077, data 19.381) 
Epoch 16 Iter 5000, train entropy gap -19.2851 bits (loss 0.096, data 19.381) 
Epoch 16 Iter 5200, train entropy gap -19.2248 bits (loss 0.156, data 19.381) 
Epoch 16 Iter 5400, train entropy gap -19.3005 bits (loss 0.080, data 19.381) 
Epoch 16 Iter 5600, train entropy gap -19.2797 bits (loss 0.101, data 19.381) 
Epoch 16 Iter 5800, train entropy gap -19.2801 bits (loss 0.101, data 19.381) 
Epoch 16 Iter 6000, train entropy gap -19.2737 bits (loss 0.107, data 19.381) 
Epoch 16 Iter 6200, train entropy gap -19.3165 bits (loss 0.064, data 19.381) 
Epoch 16 Iter 6400, train entropy gap -19.2129 bits (loss 0.168, data 19.381) 
Epoch 16 Iter 6600, train entropy gap -19.2692 bits (loss 0.112, data 19.381) 
Epoch 16 Iter 6800, train entropy gap -19.2854 bits (loss 0.095, data 19.381) 
Epoch 16 Iter 7000, train entropy gap -19.2885 bits (loss 0.092, data 19.381) 
Epoch 16 Iter 7200, train entropy gap -19.2617 bits (loss 0.119, data 19.381) 
epoch 16 train loss 0.0684 nats / 0.0986 bits
time since start: 1528.7 secs
Epoch 17 Iter 0, train entropy gap -19.2929 bits (loss 0.088, data 19.381) 
Epoch 17 Iter 200, train entropy gap -19.2903 bits (loss 0.091, data 19.381) 
Epoch 17 Iter 400, train entropy gap -19.2600 bits (loss 0.121, data 19.381) 
Epoch 17 Iter 600, train entropy gap -19.2683 bits (loss 0.113, data 19.381) 
Epoch 17 Iter 800, train entropy gap -19.2451 bits (loss 0.136, data 19.381) 
Epoch 17 Iter 1000, train entropy gap -19.2811 bits (loss 0.100, data 19.381) 
Epoch 17 Iter 1200, train entropy gap -19.2692 bits (loss 0.112, data 19.381) 
Epoch 17 Iter 1400, train entropy gap -19.2976 bits (loss 0.083, data 19.381) 
Epoch 17 Iter 1600, train entropy gap -19.2926 bits (loss 0.088, data 19.381) 
Epoch 17 Iter 1800, train entropy gap -19.2979 bits (loss 0.083, data 19.381) 
Epoch 17 Iter 2000, train entropy gap -19.3302 bits (loss 0.051, data 19.381) 
Epoch 17 Iter 2200, train entropy gap -19.3131 bits (loss 0.068, data 19.381) 
Epoch 17 Iter 2400, train entropy gap -19.2941 bits (loss 0.087, data 19.381) 
Epoch 17 Iter 2600, train entropy gap -19.2816 bits (loss 0.099, data 19.381) 
Epoch 17 Iter 2800, train entropy gap -19.2991 bits (loss 0.082, data 19.381) 
Epoch 17 Iter 3000, train entropy gap -19.2509 bits (loss 0.130, data 19.381) 
Epoch 17 Iter 3200, train entropy gap -19.2809 bits (loss 0.100, data 19.381) 
Epoch 17 Iter 3400, train entropy gap -19.3510 bits (loss 0.030, data 19.381) 
Epoch 17 Iter 3600, train entropy gap -19.2856 bits (loss 0.095, data 19.381) 
Epoch 17 Iter 3800, train entropy gap -19.2620 bits (loss 0.119, data 19.381) 
Epoch 17 Iter 4000, train entropy gap -19.2713 bits (loss 0.110, data 19.381) 
Epoch 17 Iter 4200, train entropy gap -19.2786 bits (loss 0.102, data 19.381) 
Epoch 17 Iter 4400, train entropy gap -19.3090 bits (loss 0.072, data 19.381) 
Epoch 17 Iter 4600, train entropy gap -19.2976 bits (loss 0.083, data 19.381) 
Epoch 17 Iter 4800, train entropy gap -19.2541 bits (loss 0.127, data 19.381) 
Epoch 17 Iter 5000, train entropy gap -19.2173 bits (loss 0.164, data 19.381) 
Epoch 17 Iter 5200, train entropy gap -19.2827 bits (loss 0.098, data 19.381) 
Epoch 17 Iter 5400, train entropy gap -19.3143 bits (loss 0.067, data 19.381) 
Epoch 17 Iter 5600, train entropy gap -19.2122 bits (loss 0.169, data 19.381) 
Epoch 17 Iter 5800, train entropy gap -19.3069 bits (loss 0.074, data 19.381) 
Epoch 17 Iter 6000, train entropy gap -19.3164 bits (loss 0.064, data 19.381) 
Epoch 17 Iter 6200, train entropy gap -19.2821 bits (loss 0.099, data 19.381) 
Epoch 17 Iter 6400, train entropy gap -19.2871 bits (loss 0.094, data 19.381) 
Epoch 17 Iter 6600, train entropy gap -19.2933 bits (loss 0.088, data 19.381) 
Epoch 17 Iter 6800, train entropy gap -19.2651 bits (loss 0.116, data 19.381) 
Epoch 17 Iter 7000, train entropy gap -19.2720 bits (loss 0.109, data 19.381) 
Epoch 17 Iter 7200, train entropy gap -19.2792 bits (loss 0.102, data 19.381) 
epoch 17 train loss 0.0677 nats / 0.0977 bits
time since start: 1618.6 secs
Epoch 18 Iter 0, train entropy gap -19.2945 bits (loss 0.086, data 19.381) 
Epoch 18 Iter 200, train entropy gap -19.2980 bits (loss 0.083, data 19.381) 
Epoch 18 Iter 400, train entropy gap -19.3013 bits (loss 0.080, data 19.381) 
Epoch 18 Iter 600, train entropy gap -19.2514 bits (loss 0.129, data 19.381) 
Epoch 18 Iter 800, train entropy gap -19.2698 bits (loss 0.111, data 19.381) 
Epoch 18 Iter 1000, train entropy gap -19.2878 bits (loss 0.093, data 19.381) 
Epoch 18 Iter 1200, train entropy gap -19.2780 bits (loss 0.103, data 19.381) 
Epoch 18 Iter 1400, train entropy gap -19.3009 bits (loss 0.080, data 19.381) 
Epoch 18 Iter 1600, train entropy gap -19.3215 bits (loss 0.059, data 19.381) 
Epoch 18 Iter 1800, train entropy gap -19.3089 bits (loss 0.072, data 19.381) 
Epoch 18 Iter 2000, train entropy gap -19.2637 bits (loss 0.117, data 19.381) 
Epoch 18 Iter 2200, train entropy gap -19.2412 bits (loss 0.140, data 19.381) 
Epoch 18 Iter 2400, train entropy gap -19.2906 bits (loss 0.090, data 19.381) 
Epoch 18 Iter 2600, train entropy gap -19.2609 bits (loss 0.120, data 19.381) 
Epoch 18 Iter 2800, train entropy gap -19.2921 bits (loss 0.089, data 19.381) 
Epoch 18 Iter 3000, train entropy gap -19.2725 bits (loss 0.108, data 19.381) 
Epoch 18 Iter 3200, train entropy gap -19.3300 bits (loss 0.051, data 19.381) 
Epoch 18 Iter 3400, train entropy gap -19.2974 bits (loss 0.083, data 19.381) 
Epoch 18 Iter 3600, train entropy gap -19.2825 bits (loss 0.098, data 19.381) 
Epoch 18 Iter 3800, train entropy gap -19.2572 bits (loss 0.124, data 19.381) 
Epoch 18 Iter 4000, train entropy gap -19.2679 bits (loss 0.113, data 19.381) 
Epoch 18 Iter 4200, train entropy gap -19.2395 bits (loss 0.141, data 19.381) 
Epoch 18 Iter 4400, train entropy gap -19.2822 bits (loss 0.099, data 19.381) 
Epoch 18 Iter 4600, train entropy gap -19.2659 bits (loss 0.115, data 19.381) 
Epoch 18 Iter 4800, train entropy gap -19.2765 bits (loss 0.104, data 19.381) 
Epoch 18 Iter 5000, train entropy gap -19.3108 bits (loss 0.070, data 19.381) 
Epoch 18 Iter 5200, train entropy gap -19.2871 bits (loss 0.094, data 19.381) 
Epoch 18 Iter 5400, train entropy gap -19.2437 bits (loss 0.137, data 19.381) 
Epoch 18 Iter 5600, train entropy gap -19.3042 bits (loss 0.077, data 19.381) 
Epoch 18 Iter 5800, train entropy gap -19.2445 bits (loss 0.136, data 19.381) 
Epoch 18 Iter 6000, train entropy gap -19.2788 bits (loss 0.102, data 19.381) 
Epoch 18 Iter 6200, train entropy gap -19.3348 bits (loss 0.046, data 19.381) 
Epoch 18 Iter 6400, train entropy gap -19.2432 bits (loss 0.138, data 19.381) 
Epoch 18 Iter 6600, train entropy gap -19.3124 bits (loss 0.068, data 19.381) 
Epoch 18 Iter 6800, train entropy gap -19.2688 bits (loss 0.112, data 19.381) 
Epoch 18 Iter 7000, train entropy gap -19.3078 bits (loss 0.073, data 19.381) 
Epoch 18 Iter 7200, train entropy gap -19.3251 bits (loss 0.056, data 19.381) 
epoch 18 train loss 0.0674 nats / 0.0973 bits
time since start: 1708.7 secs
Epoch 19 Iter 0, train entropy gap -19.2634 bits (loss 0.117, data 19.381) 
Epoch 19 Iter 200, train entropy gap -19.2567 bits (loss 0.124, data 19.381) 
Epoch 19 Iter 400, train entropy gap -19.2685 bits (loss 0.112, data 19.381) 
Epoch 19 Iter 600, train entropy gap -19.2974 bits (loss 0.083, data 19.381) 
Epoch 19 Iter 800, train entropy gap -19.2572 bits (loss 0.124, data 19.381) 
Epoch 19 Iter 1000, train entropy gap -19.3250 bits (loss 0.056, data 19.381) 
Epoch 19 Iter 1200, train entropy gap -19.3006 bits (loss 0.080, data 19.381) 
Epoch 19 Iter 1400, train entropy gap -19.2331 bits (loss 0.148, data 19.381) 
Epoch 19 Iter 1600, train entropy gap -19.2408 bits (loss 0.140, data 19.381) 
Epoch 19 Iter 1800, train entropy gap -19.3131 bits (loss 0.068, data 19.381) 
Epoch 19 Iter 2000, train entropy gap -19.3371 bits (loss 0.044, data 19.381) 
Epoch 19 Iter 2200, train entropy gap -19.2964 bits (loss 0.084, data 19.381) 
Epoch 19 Iter 2400, train entropy gap -19.3000 bits (loss 0.081, data 19.381) 
Epoch 19 Iter 2600, train entropy gap -19.2752 bits (loss 0.106, data 19.381) 
Epoch 19 Iter 2800, train entropy gap -19.2958 bits (loss 0.085, data 19.381) 
Epoch 19 Iter 3000, train entropy gap -19.2848 bits (loss 0.096, data 19.381) 
Epoch 19 Iter 3200, train entropy gap -19.2603 bits (loss 0.121, data 19.381) 
Epoch 19 Iter 3400, train entropy gap -19.3246 bits (loss 0.056, data 19.381) 
Epoch 19 Iter 3600, train entropy gap -19.2621 bits (loss 0.119, data 19.381) 
Epoch 19 Iter 3800, train entropy gap -19.2946 bits (loss 0.086, data 19.381) 
Epoch 19 Iter 4000, train entropy gap -19.2916 bits (loss 0.089, data 19.381) 
Epoch 19 Iter 4200, train entropy gap -19.2646 bits (loss 0.116, data 19.381) 
Epoch 19 Iter 4400, train entropy gap -19.2897 bits (loss 0.091, data 19.381) 
Epoch 19 Iter 4600, train entropy gap -19.2630 bits (loss 0.118, data 19.381) 
Epoch 19 Iter 4800, train entropy gap -19.3253 bits (loss 0.056, data 19.381) 
Epoch 19 Iter 5000, train entropy gap -19.2789 bits (loss 0.102, data 19.381) 
Epoch 19 Iter 5200, train entropy gap -19.3057 bits (loss 0.075, data 19.381) 
Epoch 19 Iter 5400, train entropy gap -19.3065 bits (loss 0.074, data 19.381) 
Epoch 19 Iter 5600, train entropy gap -19.3244 bits (loss 0.056, data 19.381) 
Epoch 19 Iter 5800, train entropy gap -19.2776 bits (loss 0.103, data 19.381) 
Epoch 19 Iter 6000, train entropy gap -19.2953 bits (loss 0.086, data 19.381) 
Epoch 19 Iter 6200, train entropy gap -19.2746 bits (loss 0.106, data 19.381) 
Epoch 19 Iter 6400, train entropy gap -19.2268 bits (loss 0.154, data 19.381) 
Epoch 19 Iter 6600, train entropy gap -19.3189 bits (loss 0.062, data 19.381) 
Epoch 19 Iter 6800, train entropy gap -19.2344 bits (loss 0.146, data 19.381) 
Epoch 19 Iter 7000, train entropy gap -19.2357 bits (loss 0.145, data 19.381) 
Epoch 19 Iter 7200, train entropy gap -19.2491 bits (loss 0.132, data 19.381) 
epoch 19 train loss 0.0675 nats / 0.0974 bits
time since start: 1798.0 secs
Training done; evaluating likelihood on full data:
Epoch None Iter 0, test loss 0.3780 nats / 0.5453 bits
Epoch None Iter 500, test loss 0.0145 nats / 0.0210 bits
Epoch None Iter 1000, test loss 0.0116 nats / 0.0168 bits
Epoch None Iter 1500, test loss 0.0117 nats / 0.0169 bits
Epoch None Iter 2000, test loss 0.1826 nats / 0.2634 bits
Epoch None Iter 2500, test loss 0.0068 nats / 0.0098 bits
Epoch None Iter 3000, test loss 0.0203 nats / 0.0293 bits
Epoch None Iter 3500, test loss 0.0344 nats / 0.0497 bits
Epoch None Iter 4000, test loss 0.0017 nats / 0.0024 bits
Epoch None Iter 4500, test loss 0.5409 nats / 0.7803 bits
Epoch None Iter 5000, test loss 0.0272 nats / 0.0392 bits
Epoch None Iter 5500, test loss 0.0122 nats / 0.0175 bits
Epoch None Iter 6000, test loss 0.0019 nats / 0.0028 bits
Epoch None Iter 6500, test loss 0.0051 nats / 0.0074 bits
Epoch None Iter 7000, test loss 0.0768 nats / 0.1107 bits
Saved to:
models/dmv-1.6MB-model0.103-data19.381-transformer-blocks4-model64-ff256-heads4-use_flash_attnTrue-posEmb-gelu-20epochs-seed0.pt
Device cuda
Loading csv... Device cuda
Loading csv... done, took 6.0s
Parsing... done, took 4.9s
Entropy of DMV([Column(Record Type, distribution_size=2), Column(Registration Class, distribution_size=69), Column(State, distribution_size=77), Column(County, distribution_size=63), Column(Body Type, distribution_size=57), Column(Fuel Type, distribution_size=8), Column(Reg Valid Date, distribution_size=2828), Column(Color, distribution_size=218), Column(Scofflaw Indicator, distribution_size=2), Column(Suspension Indicator, distribution_size=2), Column(Revocation Indicator, distribution_size=2)]): 19.3435 bits
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7315785 entries, 0 to 7315784
Data columns (total 11 columns):
 #   Column                Dtype         
---  ------                -----         
 0   Record Type           object        
 1   Registration Class    object        
 2   State                 object        
 3   County                object        
 4   Body Type             object        
 5   Fuel Type             object        
 6   Reg Valid Date        datetime64[ns]
 7   Color                 object        
 8   Scofflaw Indicator    object        
 9   Suspension Indicator  object        
 10  Revocation Indicator  object        
dtypes: datetime64[ns](1), object(10)
memory usage: 614.0+ MB
None
MASK_SCHEME 0
ordering [ 0  1  2  3  4  5  6  7  8  9 10]
using orig mask
 tensor([[ True, False, False, False, False, False, False, False, False, False,
         False],
        [ True,  True, False, False, False, False, False, False, False, False,
         False],
        [ True,  True,  True, False, False, False, False, False, False, False,
         False],
        [ True,  True,  True,  True, False, False, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True, False, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True]])
Number of model parameters: 414464 (~= 1.6MB)
Transformer(
  (blocks): Sequential(
    (0): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=64, out_features=192, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
    )
    (1): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=64, out_features=192, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
    )
    (2): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=64, out_features=192, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
    )
    (3): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=64, out_features=192, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
    )
  )
  (norm): LayerNorm()
  (embeddings): ModuleList(
    (0): Embedding(2, 64)
    (1): Embedding(69, 64)
    (2): Embedding(77, 64)
    (3): Embedding(63, 64)
    (4): Embedding(57, 64)
    (5): Embedding(8, 64)
    (6): Embedding(2828, 64)
    (7): Embedding(218, 64)
    (8): Embedding(2, 64)
    (9): Embedding(2, 64)
    (10): Embedding(2, 64)
  )
  (pos_embeddings): Embedding(11, 64)
  (unk_embeddings): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
      (2): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
      (3): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
      (4): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
      (5): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
      (6): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
      (7): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
      (8): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
      (9): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
      (10): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]
  )
)
Discretizing table... done, took 3.7s
Epoch 0 Iter 0, train entropy gap 30.2862 bits (loss 49.630, data 19.343) 
Epoch 0 Iter 200, train entropy gap 29.9713 bits (loss 49.315, data 19.343) 
Epoch 0 Iter 400, train entropy gap 28.9491 bits (loss 48.293, data 19.343) 
Epoch 0 Iter 600, train entropy gap 27.2472 bits (loss 46.591, data 19.343) 
Epoch 0 Iter 800, train entropy gap 25.0768 bits (loss 44.420, data 19.343) 
Epoch 0 Iter 1000, train entropy gap 22.7632 bits (loss 42.107, data 19.343) 
Epoch 0 Iter 1200, train entropy gap 20.3797 bits (loss 39.723, data 19.343) 
Epoch 0 Iter 1400, train entropy gap 17.5107 bits (loss 36.854, data 19.343) 
Epoch 0 Iter 1600, train entropy gap 15.1889 bits (loss 34.532, data 19.343) 
Epoch 0 Iter 1800, train entropy gap 12.7036 bits (loss 32.047, data 19.343) 
Epoch 0 Iter 2000, train entropy gap 10.2062 bits (loss 29.550, data 19.343) 
Epoch 0 Iter 2200, train entropy gap 8.3127 bits (loss 27.656, data 19.343) 
Epoch 0 Iter 2400, train entropy gap 6.1276 bits (loss 25.471, data 19.343) 
Epoch 0 Iter 2600, train entropy gap 5.0346 bits (loss 24.378, data 19.343) 
Epoch 0 Iter 2800, train entropy gap 3.9826 bits (loss 23.326, data 19.343) 
Epoch 0 Iter 3000, train entropy gap 3.6640 bits (loss 23.007, data 19.343) 
Epoch 0 Iter 3200, train entropy gap 3.0235 bits (loss 22.367, data 19.343) 
Epoch 0 Iter 3400, train entropy gap 3.2767 bits (loss 22.620, data 19.343) 
Epoch 0 Iter 3600, train entropy gap 3.4558 bits (loss 22.799, data 19.343) 
Epoch 0 Iter 3800, train entropy gap 2.3895 bits (loss 21.733, data 19.343) 
Epoch 0 Iter 4000, train entropy gap 2.3962 bits (loss 21.740, data 19.343) 
Epoch 0 Iter 4200, train entropy gap 2.6878 bits (loss 22.031, data 19.343) 
Epoch 0 Iter 4400, train entropy gap 2.2061 bits (loss 21.550, data 19.343) 
Epoch 0 Iter 4600, train entropy gap 3.7967 bits (loss 23.140, data 19.343) 
Epoch 0 Iter 4800, train entropy gap 2.5981 bits (loss 21.942, data 19.343) 
Epoch 0 Iter 5000, train entropy gap 1.8801 bits (loss 21.224, data 19.343) 
Epoch 0 Iter 5200, train entropy gap 3.2288 bits (loss 22.572, data 19.343) 
Epoch 0 Iter 5400, train entropy gap 2.3195 bits (loss 21.663, data 19.343) 
Epoch 0 Iter 5600, train entropy gap 2.4326 bits (loss 21.776, data 19.343) 
Epoch 0 Iter 5800, train entropy gap 1.7508 bits (loss 21.094, data 19.343) 
Epoch 0 Iter 6000, train entropy gap 2.9255 bits (loss 22.269, data 19.343) 
Epoch 0 Iter 6200, train entropy gap 1.8106 bits (loss 21.154, data 19.343) 
Epoch 0 Iter 6400, train entropy gap 3.0186 bits (loss 22.362, data 19.343) 
Epoch 0 Iter 6600, train entropy gap 2.2351 bits (loss 21.579, data 19.343) 
Epoch 0 Iter 6800, train entropy gap 1.2436 bits (loss 20.587, data 19.343) 
Epoch 0 Iter 7000, train entropy gap 1.9396 bits (loss 21.283, data 19.343) 
epoch 0 train loss 19.3311 nats / 27.8889 bits
time since start: 101.2 secs
Epoch 1 Iter 0, train entropy gap 3.1351 bits (loss 22.479, data 19.343) 
Epoch 1 Iter 200, train entropy gap 3.3869 bits (loss 22.730, data 19.343) 
Epoch 1 Iter 400, train entropy gap 1.3492 bits (loss 20.693, data 19.343) 
Epoch 1 Iter 600, train entropy gap 2.1855 bits (loss 21.529, data 19.343) 
Epoch 1 Iter 800, train entropy gap 3.4433 bits (loss 22.787, data 19.343) 
Epoch 1 Iter 1000, train entropy gap 1.4298 bits (loss 20.773, data 19.343) 
Epoch 1 Iter 1200, train entropy gap 2.0759 bits (loss 21.419, data 19.343) 
Epoch 1 Iter 1400, train entropy gap 2.0415 bits (loss 21.385, data 19.343) 
Epoch 1 Iter 1600, train entropy gap 1.2103 bits (loss 20.554, data 19.343) 
Epoch 1 Iter 1800, train entropy gap 1.9914 bits (loss 21.335, data 19.343) 
Epoch 1 Iter 2000, train entropy gap 2.2085 bits (loss 21.552, data 19.343) 
Epoch 1 Iter 2200, train entropy gap 2.4307 bits (loss 21.774, data 19.343) 
Epoch 1 Iter 2400, train entropy gap 3.3283 bits (loss 22.672, data 19.343) 
Epoch 1 Iter 2600, train entropy gap 1.5469 bits (loss 20.890, data 19.343) 
Epoch 1 Iter 2800, train entropy gap 1.7955 bits (loss 21.139, data 19.343) 
Epoch 1 Iter 3000, train entropy gap 3.6533 bits (loss 22.997, data 19.343) 
Epoch 1 Iter 3200, train entropy gap 1.1215 bits (loss 20.465, data 19.343) 
Epoch 1 Iter 3400, train entropy gap 2.4110 bits (loss 21.754, data 19.343) 
Epoch 1 Iter 3600, train entropy gap 1.7582 bits (loss 21.102, data 19.343) 
Epoch 1 Iter 3800, train entropy gap 1.9889 bits (loss 21.332, data 19.343) 
Epoch 1 Iter 4000, train entropy gap 1.9546 bits (loss 21.298, data 19.343) 
Epoch 1 Iter 4200, train entropy gap 3.0937 bits (loss 22.437, data 19.343) 
Epoch 1 Iter 4400, train entropy gap 4.0216 bits (loss 23.365, data 19.343) 
Epoch 1 Iter 4600, train entropy gap 3.3272 bits (loss 22.671, data 19.343) 
Epoch 1 Iter 4800, train entropy gap 1.8894 bits (loss 21.233, data 19.343) 
Epoch 1 Iter 5000, train entropy gap 1.8616 bits (loss 21.205, data 19.343) 
Epoch 1 Iter 5200, train entropy gap 2.8592 bits (loss 22.203, data 19.343) 
Epoch 1 Iter 5400, train entropy gap 1.8982 bits (loss 21.242, data 19.343) 
Epoch 1 Iter 5600, train entropy gap 2.3208 bits (loss 21.664, data 19.343) 
Epoch 1 Iter 5800, train entropy gap 1.7025 bits (loss 21.046, data 19.343) 
Epoch 1 Iter 6000, train entropy gap 1.6462 bits (loss 20.990, data 19.343) 
Epoch 1 Iter 6200, train entropy gap 1.4207 bits (loss 20.764, data 19.343) 
Epoch 1 Iter 6400, train entropy gap 3.3217 bits (loss 22.665, data 19.343) 
Epoch 1 Iter 6600, train entropy gap 2.9626 bits (loss 22.306, data 19.343) 
Epoch 1 Iter 6800, train entropy gap 1.1646 bits (loss 20.508, data 19.343) 
Epoch 1 Iter 7000, train entropy gap 1.4749 bits (loss 20.818, data 19.343) 
epoch 1 train loss 14.9432 nats / 21.5584 bits
time since start: 201.1 secs
Epoch 2 Iter 0, train entropy gap 2.2447 bits (loss 21.588, data 19.343) 
Epoch 2 Iter 200, train entropy gap 1.9502 bits (loss 21.294, data 19.343) 
Epoch 2 Iter 400, train entropy gap 1.9969 bits (loss 21.340, data 19.343) 
Epoch 2 Iter 600, train entropy gap 2.4042 bits (loss 21.748, data 19.343) 
Epoch 2 Iter 800, train entropy gap 1.7316 bits (loss 21.075, data 19.343) 
Epoch 2 Iter 1000, train entropy gap 1.4740 bits (loss 20.817, data 19.343) 
Epoch 2 Iter 1200, train entropy gap 1.8044 bits (loss 21.148, data 19.343) 
Epoch 2 Iter 1400, train entropy gap 3.1195 bits (loss 22.463, data 19.343) 
Epoch 2 Iter 1600, train entropy gap 1.0593 bits (loss 20.403, data 19.343) 
Epoch 2 Iter 1800, train entropy gap 1.7593 bits (loss 21.103, data 19.343) 
Epoch 2 Iter 2000, train entropy gap 3.1318 bits (loss 22.475, data 19.343) 
Epoch 2 Iter 2200, train entropy gap 2.6000 bits (loss 21.943, data 19.343) 
Epoch 2 Iter 2400, train entropy gap 2.7426 bits (loss 22.086, data 19.343) 
Epoch 2 Iter 2600, train entropy gap 2.6040 bits (loss 21.947, data 19.343) 
Epoch 2 Iter 2800, train entropy gap 2.6910 bits (loss 22.034, data 19.343) 
Epoch 2 Iter 3000, train entropy gap 1.5317 bits (loss 20.875, data 19.343) 
Epoch 2 Iter 3200, train entropy gap 1.9866 bits (loss 21.330, data 19.343) 
Epoch 2 Iter 3400, train entropy gap 2.9081 bits (loss 22.252, data 19.343) 
Epoch 2 Iter 3600, train entropy gap 2.7310 bits (loss 22.074, data 19.343) 
Epoch 2 Iter 3800, train entropy gap 2.5276 bits (loss 21.871, data 19.343) 
Epoch 2 Iter 4000, train entropy gap 3.1486 bits (loss 22.492, data 19.343) 
Epoch 2 Iter 4200, train entropy gap 1.8050 bits (loss 21.148, data 19.343) 
Epoch 2 Iter 4400, train entropy gap 2.4770 bits (loss 21.820, data 19.343) 
Epoch 2 Iter 4600, train entropy gap 1.3651 bits (loss 20.709, data 19.343) 
Epoch 2 Iter 4800, train entropy gap 1.3275 bits (loss 20.671, data 19.343) 
Epoch 2 Iter 5000, train entropy gap 3.5054 bits (loss 22.849, data 19.343) 
Epoch 2 Iter 5200, train entropy gap 2.7523 bits (loss 22.096, data 19.343) 
Epoch 2 Iter 5400, train entropy gap 1.9001 bits (loss 21.244, data 19.343) 
Epoch 2 Iter 5600, train entropy gap 2.0444 bits (loss 21.388, data 19.343) 
Epoch 2 Iter 5800, train entropy gap 2.9448 bits (loss 22.288, data 19.343) 
Epoch 2 Iter 6000, train entropy gap 1.6118 bits (loss 20.955, data 19.343) 
Epoch 2 Iter 6200, train entropy gap 1.7532 bits (loss 21.097, data 19.343) 
Epoch 2 Iter 6400, train entropy gap 1.8623 bits (loss 21.206, data 19.343) 
Epoch 2 Iter 6600, train entropy gap 1.6921 bits (loss 21.036, data 19.343) 
Epoch 2 Iter 6800, train entropy gap 1.2016 bits (loss 20.545, data 19.343) 
Epoch 2 Iter 7000, train entropy gap 2.3319 bits (loss 21.675, data 19.343) 
epoch 2 train loss 14.8489 nats / 21.4225 bits
time since start: 301.4 secs
Epoch 3 Iter 0, train entropy gap 1.2393 bits (loss 20.583, data 19.343) 
Epoch 3 Iter 200, train entropy gap 3.5443 bits (loss 22.888, data 19.343) 
Epoch 3 Iter 400, train entropy gap 2.8201 bits (loss 22.164, data 19.343) 
Epoch 3 Iter 600, train entropy gap 1.4430 bits (loss 20.786, data 19.343) 
Epoch 3 Iter 800, train entropy gap 1.0473 bits (loss 20.391, data 19.343) 
Epoch 3 Iter 1000, train entropy gap 2.6100 bits (loss 21.953, data 19.343) 
Epoch 3 Iter 1200, train entropy gap 1.4240 bits (loss 20.767, data 19.343) 
Epoch 3 Iter 1400, train entropy gap 1.9854 bits (loss 21.329, data 19.343) 
Epoch 3 Iter 1600, train entropy gap 1.1774 bits (loss 20.521, data 19.343) 
Epoch 3 Iter 1800, train entropy gap 2.4892 bits (loss 21.833, data 19.343) 
Epoch 3 Iter 2000, train entropy gap 2.2679 bits (loss 21.611, data 19.343) 
Epoch 3 Iter 2200, train entropy gap 2.0460 bits (loss 21.389, data 19.343) 
Epoch 3 Iter 2400, train entropy gap 1.9295 bits (loss 21.273, data 19.343) 
Epoch 3 Iter 2600, train entropy gap 2.9145 bits (loss 22.258, data 19.343) 
Epoch 3 Iter 2800, train entropy gap 1.5952 bits (loss 20.939, data 19.343) 
Epoch 3 Iter 3000, train entropy gap 1.5797 bits (loss 20.923, data 19.343) 
Epoch 3 Iter 3200, train entropy gap 0.7946 bits (loss 20.138, data 19.343) 
Epoch 3 Iter 3400, train entropy gap 1.8428 bits (loss 21.186, data 19.343) 
Epoch 3 Iter 3600, train entropy gap 1.2196 bits (loss 20.563, data 19.343) 
Epoch 3 Iter 3800, train entropy gap 2.3597 bits (loss 21.703, data 19.343) 
Epoch 3 Iter 4000, train entropy gap 1.3549 bits (loss 20.698, data 19.343) 
Epoch 3 Iter 4200, train entropy gap 2.2674 bits (loss 21.611, data 19.343) 
Epoch 3 Iter 4400, train entropy gap 1.9660 bits (loss 21.309, data 19.343) 
Epoch 3 Iter 4600, train entropy gap 1.8495 bits (loss 21.193, data 19.343) 
Epoch 3 Iter 4800, train entropy gap 3.1327 bits (loss 22.476, data 19.343) 
Epoch 3 Iter 5000, train entropy gap 1.9375 bits (loss 21.281, data 19.343) 
Epoch 3 Iter 5200, train entropy gap 3.6700 bits (loss 23.013, data 19.343) 
Epoch 3 Iter 5400, train entropy gap 2.7011 bits (loss 22.045, data 19.343) 
Epoch 3 Iter 5600, train entropy gap 2.9031 bits (loss 22.247, data 19.343) 
Epoch 3 Iter 5800, train entropy gap 2.9004 bits (loss 22.244, data 19.343) 
Epoch 3 Iter 6000, train entropy gap 2.9700 bits (loss 22.313, data 19.343) 
Epoch 3 Iter 6200, train entropy gap 1.9635 bits (loss 21.307, data 19.343) 
Epoch 3 Iter 6400, train entropy gap 2.3430 bits (loss 21.687, data 19.343) 
Epoch 3 Iter 6600, train entropy gap 3.7546 bits (loss 23.098, data 19.343) 
Epoch 3 Iter 6800, train entropy gap 1.7979 bits (loss 21.141, data 19.343) 
Epoch 3 Iter 7000, train entropy gap 1.2204 bits (loss 20.564, data 19.343) 
epoch 3 train loss 14.8217 nats / 21.3832 bits
time since start: 400.8 secs
Epoch 4 Iter 0, train entropy gap 1.1177 bits (loss 20.461, data 19.343) 
Epoch 4 Iter 200, train entropy gap 2.8196 bits (loss 22.163, data 19.343) 
Epoch 4 Iter 400, train entropy gap 1.1107 bits (loss 20.454, data 19.343) 
Epoch 4 Iter 600, train entropy gap 3.5188 bits (loss 22.862, data 19.343) 
Epoch 4 Iter 800, train entropy gap 2.6936 bits (loss 22.037, data 19.343) 
Epoch 4 Iter 1000, train entropy gap 1.9239 bits (loss 21.267, data 19.343) 
Epoch 4 Iter 1200, train entropy gap 2.6082 bits (loss 21.952, data 19.343) 
Epoch 4 Iter 1400, train entropy gap 1.5443 bits (loss 20.888, data 19.343) 
Epoch 4 Iter 1600, train entropy gap 1.0899 bits (loss 20.433, data 19.343) 
Epoch 4 Iter 1800, train entropy gap 1.6269 bits (loss 20.970, data 19.343) 
Epoch 4 Iter 2000, train entropy gap 2.6728 bits (loss 22.016, data 19.343) 
Epoch 4 Iter 2200, train entropy gap 2.1785 bits (loss 21.522, data 19.343) 
Epoch 4 Iter 2400, train entropy gap 1.4218 bits (loss 20.765, data 19.343) 
Epoch 4 Iter 2600, train entropy gap 1.4659 bits (loss 20.809, data 19.343) 
Epoch 4 Iter 2800, train entropy gap 3.1373 bits (loss 22.481, data 19.343) 
Epoch 4 Iter 3000, train entropy gap 1.9892 bits (loss 21.333, data 19.343) 
Epoch 4 Iter 3200, train entropy gap 1.6553 bits (loss 20.999, data 19.343) 
Epoch 4 Iter 3400, train entropy gap 0.9962 bits (loss 20.340, data 19.343) 
Epoch 4 Iter 3600, train entropy gap 1.8503 bits (loss 21.194, data 19.343) 
Epoch 4 Iter 3800, train entropy gap 1.1461 bits (loss 20.490, data 19.343) 
Epoch 4 Iter 4000, train entropy gap 1.6286 bits (loss 20.972, data 19.343) 
Epoch 4 Iter 4200, train entropy gap 2.1770 bits (loss 21.520, data 19.343) 
Epoch 4 Iter 4400, train entropy gap 2.5759 bits (loss 21.919, data 19.343) 
Epoch 4 Iter 4600, train entropy gap 2.6261 bits (loss 21.970, data 19.343) 
Epoch 4 Iter 4800, train entropy gap 2.5541 bits (loss 21.898, data 19.343) 
Epoch 4 Iter 5000, train entropy gap 1.7985 bits (loss 21.142, data 19.343) 
Epoch 4 Iter 5200, train entropy gap 1.8259 bits (loss 21.169, data 19.343) 
Epoch 4 Iter 5400, train entropy gap 0.9492 bits (loss 20.293, data 19.343) 
Epoch 4 Iter 5600, train entropy gap 1.2304 bits (loss 20.574, data 19.343) 
Epoch 4 Iter 5800, train entropy gap 1.7504 bits (loss 21.094, data 19.343) 
Epoch 4 Iter 6000, train entropy gap 2.7970 bits (loss 22.140, data 19.343) 
Epoch 4 Iter 6200, train entropy gap 1.8965 bits (loss 21.240, data 19.343) 
Epoch 4 Iter 6400, train entropy gap 1.0385 bits (loss 20.382, data 19.343) 
Epoch 4 Iter 6600, train entropy gap 2.6570 bits (loss 22.000, data 19.343) 
Epoch 4 Iter 6800, train entropy gap 2.4636 bits (loss 21.807, data 19.343) 
Epoch 4 Iter 7000, train entropy gap 1.8457 bits (loss 21.189, data 19.343) 
epoch 4 train loss 14.8023 nats / 21.3551 bits
time since start: 500.5 secs
Epoch 5 Iter 0, train entropy gap 2.0951 bits (loss 21.439, data 19.343) 
Epoch 5 Iter 200, train entropy gap 3.5377 bits (loss 22.881, data 19.343) 
Epoch 5 Iter 400, train entropy gap 1.2730 bits (loss 20.616, data 19.343) 
Epoch 5 Iter 600, train entropy gap 1.1568 bits (loss 20.500, data 19.343) 
Epoch 5 Iter 800, train entropy gap 2.9509 bits (loss 22.294, data 19.343) 
Epoch 5 Iter 1000, train entropy gap 1.3261 bits (loss 20.670, data 19.343) 
Epoch 5 Iter 1200, train entropy gap 1.1920 bits (loss 20.535, data 19.343) 
Epoch 5 Iter 1400, train entropy gap 2.7942 bits (loss 22.138, data 19.343) 
Epoch 5 Iter 1600, train entropy gap 1.4820 bits (loss 20.825, data 19.343) 
Epoch 5 Iter 1800, train entropy gap 1.6945 bits (loss 21.038, data 19.343) 
Epoch 5 Iter 2000, train entropy gap 1.6409 bits (loss 20.984, data 19.343) 
Epoch 5 Iter 2200, train entropy gap 3.4119 bits (loss 22.755, data 19.343) 
Epoch 5 Iter 2400, train entropy gap 1.6024 bits (loss 20.946, data 19.343) 
Epoch 5 Iter 2600, train entropy gap 2.2190 bits (loss 21.562, data 19.343) 
Epoch 5 Iter 2800, train entropy gap 2.0040 bits (loss 21.347, data 19.343) 
Epoch 5 Iter 3000, train entropy gap 3.2851 bits (loss 22.629, data 19.343) 
Epoch 5 Iter 3200, train entropy gap 2.5606 bits (loss 21.904, data 19.343) 
Epoch 5 Iter 3400, train entropy gap 1.1859 bits (loss 20.529, data 19.343) 
Epoch 5 Iter 3600, train entropy gap 2.1316 bits (loss 21.475, data 19.343) 
Epoch 5 Iter 3800, train entropy gap 2.2295 bits (loss 21.573, data 19.343) 
Epoch 5 Iter 4000, train entropy gap 3.4419 bits (loss 22.785, data 19.343) 
Epoch 5 Iter 4200, train entropy gap 1.7740 bits (loss 21.118, data 19.343) 
Epoch 5 Iter 4400, train entropy gap 1.5273 bits (loss 20.871, data 19.343) 
Epoch 5 Iter 4600, train entropy gap 3.1707 bits (loss 22.514, data 19.343) 
Epoch 5 Iter 4800, train entropy gap 1.0873 bits (loss 20.431, data 19.343) 
Epoch 5 Iter 5000, train entropy gap 2.8007 bits (loss 22.144, data 19.343) 
Epoch 5 Iter 5200, train entropy gap 1.2478 bits (loss 20.591, data 19.343) 
Epoch 5 Iter 5400, train entropy gap 2.5634 bits (loss 21.907, data 19.343) 
Epoch 5 Iter 5600, train entropy gap 2.1931 bits (loss 21.537, data 19.343) 
Epoch 5 Iter 5800, train entropy gap 1.3850 bits (loss 20.728, data 19.343) 
Epoch 5 Iter 6000, train entropy gap 2.1854 bits (loss 21.529, data 19.343) 
Epoch 5 Iter 6200, train entropy gap 1.5125 bits (loss 20.856, data 19.343) 
Epoch 5 Iter 6400, train entropy gap 1.3437 bits (loss 20.687, data 19.343) 
Epoch 5 Iter 6600, train entropy gap 2.8921 bits (loss 22.236, data 19.343) 
Epoch 5 Iter 6800, train entropy gap 1.2255 bits (loss 20.569, data 19.343) 
Epoch 5 Iter 7000, train entropy gap 0.7307 bits (loss 20.074, data 19.343) 
epoch 5 train loss 14.7918 nats / 21.3401 bits
time since start: 600.7 secs
Epoch 6 Iter 0, train entropy gap 0.9422 bits (loss 20.286, data 19.343) 
Epoch 6 Iter 200, train entropy gap 1.0135 bits (loss 20.357, data 19.343) 
Epoch 6 Iter 400, train entropy gap 1.2828 bits (loss 20.626, data 19.343) 
Epoch 6 Iter 600, train entropy gap 0.9604 bits (loss 20.304, data 19.343) 
Epoch 6 Iter 800, train entropy gap 2.2787 bits (loss 21.622, data 19.343) 
Epoch 6 Iter 1000, train entropy gap 2.3922 bits (loss 21.736, data 19.343) 
Epoch 6 Iter 1200, train entropy gap 2.0640 bits (loss 21.407, data 19.343) 
Epoch 6 Iter 1400, train entropy gap 0.9921 bits (loss 20.336, data 19.343) 
Epoch 6 Iter 1600, train entropy gap 3.6314 bits (loss 22.975, data 19.343) 
Epoch 6 Iter 1800, train entropy gap 2.8406 bits (loss 22.184, data 19.343) 
Epoch 6 Iter 2000, train entropy gap 1.0848 bits (loss 20.428, data 19.343) 
Epoch 6 Iter 2200, train entropy gap 3.3739 bits (loss 22.717, data 19.343) 
Epoch 6 Iter 2400, train entropy gap 2.7327 bits (loss 22.076, data 19.343) 
Epoch 6 Iter 2600, train entropy gap 2.1708 bits (loss 21.514, data 19.343) 
Epoch 6 Iter 2800, train entropy gap 3.5433 bits (loss 22.887, data 19.343) 
Epoch 6 Iter 3000, train entropy gap 2.7465 bits (loss 22.090, data 19.343) 
Epoch 6 Iter 3200, train entropy gap 1.8129 bits (loss 21.156, data 19.343) 
Epoch 6 Iter 3400, train entropy gap 1.5898 bits (loss 20.933, data 19.343) 
Epoch 6 Iter 3600, train entropy gap 2.1310 bits (loss 21.474, data 19.343) 
Epoch 6 Iter 3800, train entropy gap 1.7396 bits (loss 21.083, data 19.343) 
Epoch 6 Iter 4000, train entropy gap 1.1110 bits (loss 20.454, data 19.343) 
Epoch 6 Iter 4200, train entropy gap 2.0304 bits (loss 21.374, data 19.343) 
Epoch 6 Iter 4400, train entropy gap 3.5671 bits (loss 22.911, data 19.343) 
Epoch 6 Iter 4600, train entropy gap 1.3240 bits (loss 20.667, data 19.343) 
Epoch 6 Iter 4800, train entropy gap 1.3618 bits (loss 20.705, data 19.343) 
Epoch 6 Iter 5000, train entropy gap 3.4938 bits (loss 22.837, data 19.343) 
Epoch 6 Iter 5200, train entropy gap 1.3183 bits (loss 20.662, data 19.343) 
Epoch 6 Iter 5400, train entropy gap 2.4055 bits (loss 21.749, data 19.343) 
Epoch 6 Iter 5600, train entropy gap 1.3725 bits (loss 20.716, data 19.343) 
Epoch 6 Iter 5800, train entropy gap 1.6078 bits (loss 20.951, data 19.343) 
Epoch 6 Iter 6000, train entropy gap 1.2575 bits (loss 20.601, data 19.343) 
Epoch 6 Iter 6200, train entropy gap 3.2159 bits (loss 22.559, data 19.343) 
Epoch 6 Iter 6400, train entropy gap 2.3757 bits (loss 21.719, data 19.343) 
Epoch 6 Iter 6600, train entropy gap 1.8972 bits (loss 21.241, data 19.343) 
Epoch 6 Iter 6800, train entropy gap 1.0095 bits (loss 20.353, data 19.343) 
Epoch 6 Iter 7000, train entropy gap 3.2973 bits (loss 22.641, data 19.343) 
epoch 6 train loss 14.7779 nats / 21.3201 bits
time since start: 700.1 secs
Epoch 7 Iter 0, train entropy gap 1.4115 bits (loss 20.755, data 19.343) 
Epoch 7 Iter 200, train entropy gap 1.8236 bits (loss 21.167, data 19.343) 
Epoch 7 Iter 400, train entropy gap 0.8309 bits (loss 20.174, data 19.343) 
Epoch 7 Iter 600, train entropy gap 1.1606 bits (loss 20.504, data 19.343) 
Epoch 7 Iter 800, train entropy gap 1.3018 bits (loss 20.645, data 19.343) 
Epoch 7 Iter 1000, train entropy gap 1.1003 bits (loss 20.444, data 19.343) 
Epoch 7 Iter 1200, train entropy gap 0.8768 bits (loss 20.220, data 19.343) 
Epoch 7 Iter 1400, train entropy gap 1.7738 bits (loss 21.117, data 19.343) 
Epoch 7 Iter 1600, train entropy gap 1.9190 bits (loss 21.263, data 19.343) 
Epoch 7 Iter 1800, train entropy gap 2.5173 bits (loss 21.861, data 19.343) 
Epoch 7 Iter 2000, train entropy gap 2.1732 bits (loss 21.517, data 19.343) 
Epoch 7 Iter 2200, train entropy gap 1.3622 bits (loss 20.706, data 19.343) 
Epoch 7 Iter 2400, train entropy gap 1.6652 bits (loss 21.009, data 19.343) 
Epoch 7 Iter 2600, train entropy gap 1.2290 bits (loss 20.572, data 19.343) 
Epoch 7 Iter 2800, train entropy gap 1.6664 bits (loss 21.010, data 19.343) 
Epoch 7 Iter 3000, train entropy gap 0.9544 bits (loss 20.298, data 19.343) 
Epoch 7 Iter 3200, train entropy gap 3.4063 bits (loss 22.750, data 19.343) 
Epoch 7 Iter 3400, train entropy gap 1.3237 bits (loss 20.667, data 19.343) 
Epoch 7 Iter 3600, train entropy gap 1.3167 bits (loss 20.660, data 19.343) 
Epoch 7 Iter 3800, train entropy gap 2.6255 bits (loss 21.969, data 19.343) 
Epoch 7 Iter 4000, train entropy gap 0.7189 bits (loss 20.062, data 19.343) 
Epoch 7 Iter 4200, train entropy gap 3.3815 bits (loss 22.725, data 19.343) 
Epoch 7 Iter 4400, train entropy gap 0.9630 bits (loss 20.306, data 19.343) 
Epoch 7 Iter 4600, train entropy gap 3.0640 bits (loss 22.408, data 19.343) 
Epoch 7 Iter 4800, train entropy gap 1.9274 bits (loss 21.271, data 19.343) 
Epoch 7 Iter 5000, train entropy gap 1.9245 bits (loss 21.268, data 19.343) 
Epoch 7 Iter 5200, train entropy gap 2.6995 bits (loss 22.043, data 19.343) 
Epoch 7 Iter 5400, train entropy gap 2.7892 bits (loss 22.133, data 19.343) 
Epoch 7 Iter 5600, train entropy gap 2.5239 bits (loss 21.867, data 19.343) 
Epoch 7 Iter 5800, train entropy gap 2.0529 bits (loss 21.396, data 19.343) 
Epoch 7 Iter 6000, train entropy gap 1.4074 bits (loss 20.751, data 19.343) 
Epoch 7 Iter 6200, train entropy gap 0.9663 bits (loss 20.310, data 19.343) 
Epoch 7 Iter 6400, train entropy gap 3.1940 bits (loss 22.537, data 19.343) 
Epoch 7 Iter 6600, train entropy gap 1.0364 bits (loss 20.380, data 19.343) 
Epoch 7 Iter 6800, train entropy gap 0.9861 bits (loss 20.330, data 19.343) 
Epoch 7 Iter 7000, train entropy gap 0.9919 bits (loss 20.335, data 19.343) 
epoch 7 train loss 14.7819 nats / 21.3257 bits
time since start: 800.0 secs
Epoch 8 Iter 0, train entropy gap 2.3976 bits (loss 21.741, data 19.343) 
Epoch 8 Iter 200, train entropy gap 1.1528 bits (loss 20.496, data 19.343) 
Epoch 8 Iter 400, train entropy gap 1.6442 bits (loss 20.988, data 19.343) 
Epoch 8 Iter 600, train entropy gap 2.4555 bits (loss 21.799, data 19.343) 
Epoch 8 Iter 800, train entropy gap 3.5032 bits (loss 22.847, data 19.343) 
Epoch 8 Iter 1000, train entropy gap 3.2112 bits (loss 22.555, data 19.343) 
Epoch 8 Iter 1200, train entropy gap 1.4480 bits (loss 20.791, data 19.343) 
Epoch 8 Iter 1400, train entropy gap 0.8797 bits (loss 20.223, data 19.343) 
Epoch 8 Iter 1600, train entropy gap 3.3306 bits (loss 22.674, data 19.343) 
Epoch 8 Iter 1800, train entropy gap 2.6263 bits (loss 21.970, data 19.343) 
Epoch 8 Iter 2000, train entropy gap 2.7986 bits (loss 22.142, data 19.343) 
Epoch 8 Iter 2200, train entropy gap 1.6616 bits (loss 21.005, data 19.343) 
Epoch 8 Iter 2400, train entropy gap 2.5819 bits (loss 21.925, data 19.343) 
Epoch 8 Iter 2600, train entropy gap 1.3072 bits (loss 20.651, data 19.343) 
Epoch 8 Iter 2800, train entropy gap 2.3401 bits (loss 21.684, data 19.343) 
Epoch 8 Iter 3000, train entropy gap 1.7354 bits (loss 21.079, data 19.343) 
Epoch 8 Iter 3200, train entropy gap 1.7397 bits (loss 21.083, data 19.343) 
Epoch 8 Iter 3400, train entropy gap 1.0683 bits (loss 20.412, data 19.343) 
Epoch 8 Iter 3600, train entropy gap 2.5788 bits (loss 21.922, data 19.343) 
Epoch 8 Iter 3800, train entropy gap 1.2412 bits (loss 20.585, data 19.343) 
Epoch 8 Iter 4000, train entropy gap 1.5176 bits (loss 20.861, data 19.343) 
Epoch 8 Iter 4200, train entropy gap 3.2720 bits (loss 22.615, data 19.343) 
Epoch 8 Iter 4400, train entropy gap 1.9415 bits (loss 21.285, data 19.343) 
Epoch 8 Iter 4600, train entropy gap 2.9028 bits (loss 22.246, data 19.343) 
Epoch 8 Iter 4800, train entropy gap 1.6668 bits (loss 21.010, data 19.343) 
Epoch 8 Iter 5000, train entropy gap 3.2514 bits (loss 22.595, data 19.343) 
Epoch 8 Iter 5200, train entropy gap 2.9955 bits (loss 22.339, data 19.343) 
Epoch 8 Iter 5400, train entropy gap 2.7811 bits (loss 22.125, data 19.343) 
Epoch 8 Iter 5600, train entropy gap 2.1516 bits (loss 21.495, data 19.343) 
Epoch 8 Iter 5800, train entropy gap 2.0225 bits (loss 21.366, data 19.343) 
Epoch 8 Iter 6000, train entropy gap 1.2789 bits (loss 20.622, data 19.343) 
Epoch 8 Iter 6200, train entropy gap 2.0440 bits (loss 21.387, data 19.343) 
Epoch 8 Iter 6400, train entropy gap 2.4776 bits (loss 21.821, data 19.343) 
Epoch 8 Iter 6600, train entropy gap 1.1498 bits (loss 20.493, data 19.343) 
Epoch 8 Iter 6800, train entropy gap 1.6752 bits (loss 21.019, data 19.343) 
Epoch 8 Iter 7000, train entropy gap 3.0050 bits (loss 22.348, data 19.343) 
epoch 8 train loss 14.7835 nats / 21.3281 bits
time since start: 899.6 secs
Epoch 9 Iter 0, train entropy gap 1.3852 bits (loss 20.729, data 19.343) 
Epoch 9 Iter 200, train entropy gap 2.4924 bits (loss 21.836, data 19.343) 
Epoch 9 Iter 400, train entropy gap 1.5576 bits (loss 20.901, data 19.343) 
Epoch 9 Iter 600, train entropy gap 2.1506 bits (loss 21.494, data 19.343) 
Epoch 9 Iter 800, train entropy gap 2.0457 bits (loss 21.389, data 19.343) 
Epoch 9 Iter 1000, train entropy gap 1.5806 bits (loss 20.924, data 19.343) 
Epoch 9 Iter 1200, train entropy gap 0.9837 bits (loss 20.327, data 19.343) 
Epoch 9 Iter 1400, train entropy gap 1.3691 bits (loss 20.713, data 19.343) 
Epoch 9 Iter 1600, train entropy gap 2.0262 bits (loss 21.370, data 19.343) 
Epoch 9 Iter 1800, train entropy gap 2.7089 bits (loss 22.052, data 19.343) 
Epoch 9 Iter 2000, train entropy gap 3.2548 bits (loss 22.598, data 19.343) 
Epoch 9 Iter 2200, train entropy gap 1.5469 bits (loss 20.890, data 19.343) 
Epoch 9 Iter 2400, train entropy gap 2.2737 bits (loss 21.617, data 19.343) 
Epoch 9 Iter 2600, train entropy gap 3.1127 bits (loss 22.456, data 19.343) 
Epoch 9 Iter 2800, train entropy gap 3.6066 bits (loss 22.950, data 19.343) 
Epoch 9 Iter 3000, train entropy gap 0.9962 bits (loss 20.340, data 19.343) 
Epoch 9 Iter 3200, train entropy gap 1.6100 bits (loss 20.953, data 19.343) 
Epoch 9 Iter 3400, train entropy gap 1.6020 bits (loss 20.945, data 19.343) 
Epoch 9 Iter 3600, train entropy gap 3.4501 bits (loss 22.794, data 19.343) 
Epoch 9 Iter 3800, train entropy gap 1.5750 bits (loss 20.918, data 19.343) 
Epoch 9 Iter 4000, train entropy gap 1.5414 bits (loss 20.885, data 19.343) 
Epoch 9 Iter 4200, train entropy gap 0.8795 bits (loss 20.223, data 19.343) 
Epoch 9 Iter 4400, train entropy gap 2.3090 bits (loss 21.652, data 19.343) 
Epoch 9 Iter 4600, train entropy gap 1.7729 bits (loss 21.116, data 19.343) 
Epoch 9 Iter 4800, train entropy gap 3.1174 bits (loss 22.461, data 19.343) 
Epoch 9 Iter 5000, train entropy gap 1.8986 bits (loss 21.242, data 19.343) 
Epoch 9 Iter 5200, train entropy gap 1.5382 bits (loss 20.882, data 19.343) 
Epoch 9 Iter 5400, train entropy gap 1.2595 bits (loss 20.603, data 19.343) 
Epoch 9 Iter 5600, train entropy gap 2.1197 bits (loss 21.463, data 19.343) 
Epoch 9 Iter 5800, train entropy gap 2.0459 bits (loss 21.389, data 19.343) 
Epoch 9 Iter 6000, train entropy gap 0.9737 bits (loss 20.317, data 19.343) 
Epoch 9 Iter 6200, train entropy gap 1.0733 bits (loss 20.417, data 19.343) 
Epoch 9 Iter 6400, train entropy gap 1.4065 bits (loss 20.750, data 19.343) 
Epoch 9 Iter 6600, train entropy gap 1.0565 bits (loss 20.400, data 19.343) 
Epoch 9 Iter 6800, train entropy gap 1.0934 bits (loss 20.437, data 19.343) 
Epoch 9 Iter 7000, train entropy gap 2.1925 bits (loss 21.536, data 19.343) 
epoch 9 train loss 14.7713 nats / 21.3104 bits
time since start: 999.8 secs
Epoch 10 Iter 0, train entropy gap 1.3677 bits (loss 20.711, data 19.343) 
Epoch 10 Iter 200, train entropy gap 1.9947 bits (loss 21.338, data 19.343) 
Epoch 10 Iter 400, train entropy gap 2.3614 bits (loss 21.705, data 19.343) 
Epoch 10 Iter 600, train entropy gap 1.9386 bits (loss 21.282, data 19.343) 
Epoch 10 Iter 800, train entropy gap 0.9103 bits (loss 20.254, data 19.343) 
Epoch 10 Iter 1000, train entropy gap 2.3694 bits (loss 21.713, data 19.343) 
Epoch 10 Iter 1200, train entropy gap 3.4167 bits (loss 22.760, data 19.343) 
Epoch 10 Iter 1400, train entropy gap 0.9049 bits (loss 20.248, data 19.343) 
Epoch 10 Iter 1600, train entropy gap 2.8448 bits (loss 22.188, data 19.343) 
Epoch 10 Iter 1800, train entropy gap 2.2144 bits (loss 21.558, data 19.343) 
Epoch 10 Iter 2000, train entropy gap 3.3250 bits (loss 22.668, data 19.343) 
Epoch 10 Iter 2200, train entropy gap 0.8256 bits (loss 20.169, data 19.343) 
Epoch 10 Iter 2400, train entropy gap 1.3739 bits (loss 20.717, data 19.343) 
Epoch 10 Iter 2600, train entropy gap 1.9465 bits (loss 21.290, data 19.343) 
Epoch 10 Iter 2800, train entropy gap 2.3426 bits (loss 21.686, data 19.343) 
Epoch 10 Iter 3000, train entropy gap 2.2891 bits (loss 21.633, data 19.343) 
Epoch 10 Iter 3200, train entropy gap 2.4852 bits (loss 21.829, data 19.343) 
Epoch 10 Iter 3400, train entropy gap 3.3734 bits (loss 22.717, data 19.343) 
Epoch 10 Iter 3600, train entropy gap 2.3354 bits (loss 21.679, data 19.343) 
Epoch 10 Iter 3800, train entropy gap 2.2108 bits (loss 21.554, data 19.343) 
Epoch 10 Iter 4000, train entropy gap 1.6298 bits (loss 20.973, data 19.343) 
Epoch 10 Iter 4200, train entropy gap 2.8797 bits (loss 22.223, data 19.343) 
Epoch 10 Iter 4400, train entropy gap 2.8674 bits (loss 22.211, data 19.343) 
Epoch 10 Iter 4600, train entropy gap 3.0447 bits (loss 22.388, data 19.343) 
Epoch 10 Iter 4800, train entropy gap 2.7395 bits (loss 22.083, data 19.343) 
Epoch 10 Iter 5000, train entropy gap 2.8763 bits (loss 22.220, data 19.343) 
Epoch 10 Iter 5200, train entropy gap 2.5713 bits (loss 21.915, data 19.343) 
Epoch 10 Iter 5400, train entropy gap 3.5189 bits (loss 22.862, data 19.343) 
Epoch 10 Iter 5600, train entropy gap 1.3907 bits (loss 20.734, data 19.343) 
Epoch 10 Iter 5800, train entropy gap 1.2302 bits (loss 20.574, data 19.343) 
Epoch 10 Iter 6000, train entropy gap 1.5982 bits (loss 20.942, data 19.343) 
Epoch 10 Iter 6200, train entropy gap 1.8123 bits (loss 21.156, data 19.343) 
Epoch 10 Iter 6400, train entropy gap 1.7666 bits (loss 21.110, data 19.343) 
Epoch 10 Iter 6600, train entropy gap 3.2239 bits (loss 22.567, data 19.343) 
Epoch 10 Iter 6800, train entropy gap 2.4358 bits (loss 21.779, data 19.343) 
Epoch 10 Iter 7000, train entropy gap 3.0456 bits (loss 22.389, data 19.343) 
epoch 10 train loss 14.7688 nats / 21.3069 bits
time since start: 1099.4 secs
Epoch 11 Iter 0, train entropy gap 3.0947 bits (loss 22.438, data 19.343) 
Epoch 11 Iter 200, train entropy gap 3.0987 bits (loss 22.442, data 19.343) 
Epoch 11 Iter 400, train entropy gap 2.0585 bits (loss 21.402, data 19.343) 
Epoch 11 Iter 600, train entropy gap 1.0765 bits (loss 20.420, data 19.343) 
Epoch 11 Iter 800, train entropy gap 1.5113 bits (loss 20.855, data 19.343) 
Epoch 11 Iter 1000, train entropy gap 1.0197 bits (loss 20.363, data 19.343) 
Epoch 11 Iter 1200, train entropy gap 1.2787 bits (loss 20.622, data 19.343) 
Epoch 11 Iter 1400, train entropy gap 2.3353 bits (loss 21.679, data 19.343) 
Epoch 11 Iter 1600, train entropy gap 1.6896 bits (loss 21.033, data 19.343) 
Epoch 11 Iter 1800, train entropy gap 1.8178 bits (loss 21.161, data 19.343) 
Epoch 11 Iter 2000, train entropy gap 3.5150 bits (loss 22.858, data 19.343) 
Epoch 11 Iter 2200, train entropy gap 2.9604 bits (loss 22.304, data 19.343) 
Epoch 11 Iter 2400, train entropy gap 0.9234 bits (loss 20.267, data 19.343) 
Epoch 11 Iter 2600, train entropy gap 1.1550 bits (loss 20.498, data 19.343) 
Epoch 11 Iter 2800, train entropy gap 3.2993 bits (loss 22.643, data 19.343) 
Epoch 11 Iter 3000, train entropy gap 2.1089 bits (loss 21.452, data 19.343) 
Epoch 11 Iter 3200, train entropy gap 1.2927 bits (loss 20.636, data 19.343) 
Epoch 11 Iter 3400, train entropy gap 1.7840 bits (loss 21.128, data 19.343) 
Epoch 11 Iter 3600, train entropy gap 0.9775 bits (loss 20.321, data 19.343) 
Epoch 11 Iter 3800, train entropy gap 1.7859 bits (loss 21.129, data 19.343) 
Epoch 11 Iter 4000, train entropy gap 3.3498 bits (loss 22.693, data 19.343) 
Epoch 11 Iter 4200, train entropy gap 2.5484 bits (loss 21.892, data 19.343) 
Epoch 11 Iter 4400, train entropy gap 3.4799 bits (loss 22.823, data 19.343) 
Epoch 11 Iter 4600, train entropy gap 2.6032 bits (loss 21.947, data 19.343) 
Epoch 11 Iter 4800, train entropy gap 1.5159 bits (loss 20.859, data 19.343) 
Epoch 11 Iter 5000, train entropy gap 2.0210 bits (loss 21.364, data 19.343) 
Epoch 11 Iter 5200, train entropy gap 2.2665 bits (loss 21.610, data 19.343) 
Epoch 11 Iter 5400, train entropy gap 1.3277 bits (loss 20.671, data 19.343) 
Epoch 11 Iter 5600, train entropy gap 2.2948 bits (loss 21.638, data 19.343) 
Epoch 11 Iter 5800, train entropy gap 2.0925 bits (loss 21.436, data 19.343) 
Epoch 11 Iter 6000, train entropy gap 2.9331 bits (loss 22.277, data 19.343) 
Epoch 11 Iter 6200, train entropy gap 2.3881 bits (loss 21.732, data 19.343) 
Epoch 11 Iter 6400, train entropy gap 2.9343 bits (loss 22.278, data 19.343) 
Epoch 11 Iter 6600, train entropy gap 2.9573 bits (loss 22.301, data 19.343) 
Epoch 11 Iter 6800, train entropy gap 2.4968 bits (loss 21.840, data 19.343) 
Epoch 11 Iter 7000, train entropy gap 1.8139 bits (loss 21.157, data 19.343) 
epoch 11 train loss 14.7642 nats / 21.3003 bits
time since start: 1200.2 secs
Epoch 12 Iter 0, train entropy gap 1.3143 bits (loss 20.658, data 19.343) 
Epoch 12 Iter 200, train entropy gap 1.8326 bits (loss 21.176, data 19.343) 
Epoch 12 Iter 400, train entropy gap 2.5978 bits (loss 21.941, data 19.343) 
Epoch 12 Iter 600, train entropy gap 3.0624 bits (loss 22.406, data 19.343) 
Epoch 12 Iter 800, train entropy gap 2.2557 bits (loss 21.599, data 19.343) 
Epoch 12 Iter 1000, train entropy gap 1.4910 bits (loss 20.834, data 19.343) 
Epoch 12 Iter 1200, train entropy gap 1.5219 bits (loss 20.865, data 19.343) 
Epoch 12 Iter 1400, train entropy gap 1.7432 bits (loss 21.087, data 19.343) 
Epoch 12 Iter 1600, train entropy gap 0.9905 bits (loss 20.334, data 19.343) 
Epoch 12 Iter 1800, train entropy gap 1.1886 bits (loss 20.532, data 19.343) 
Epoch 12 Iter 2000, train entropy gap 2.9270 bits (loss 22.270, data 19.343) 
Epoch 12 Iter 2200, train entropy gap 1.7795 bits (loss 21.123, data 19.343) 
Epoch 12 Iter 2400, train entropy gap 1.5803 bits (loss 20.924, data 19.343) 
Epoch 12 Iter 2600, train entropy gap 2.3899 bits (loss 21.733, data 19.343) 
Epoch 12 Iter 2800, train entropy gap 3.1811 bits (loss 22.525, data 19.343) 
Epoch 12 Iter 3000, train entropy gap 2.8289 bits (loss 22.172, data 19.343) 
Epoch 12 Iter 3200, train entropy gap 2.5811 bits (loss 21.925, data 19.343) 
Epoch 12 Iter 3400, train entropy gap 1.5551 bits (loss 20.899, data 19.343) 
Epoch 12 Iter 3600, train entropy gap 1.1491 bits (loss 20.493, data 19.343) 
Epoch 12 Iter 3800, train entropy gap 2.7877 bits (loss 22.131, data 19.343) 
Epoch 12 Iter 4000, train entropy gap 1.1987 bits (loss 20.542, data 19.343) 
Epoch 12 Iter 4200, train entropy gap 1.5745 bits (loss 20.918, data 19.343) 
Epoch 12 Iter 4400, train entropy gap 3.5779 bits (loss 22.921, data 19.343) 
Epoch 12 Iter 4600, train entropy gap 1.8676 bits (loss 21.211, data 19.343) 
Epoch 12 Iter 4800, train entropy gap 2.9354 bits (loss 22.279, data 19.343) 
Epoch 12 Iter 5000, train entropy gap 2.4475 bits (loss 21.791, data 19.343) 
Epoch 12 Iter 5200, train entropy gap 1.3106 bits (loss 20.654, data 19.343) 
Epoch 12 Iter 5400, train entropy gap 2.1050 bits (loss 21.448, data 19.343) 
Epoch 12 Iter 5600, train entropy gap 1.4410 bits (loss 20.784, data 19.343) 
Epoch 12 Iter 5800, train entropy gap 1.6129 bits (loss 20.956, data 19.343) 
Epoch 12 Iter 6000, train entropy gap 1.8470 bits (loss 21.190, data 19.343) 
Epoch 12 Iter 6200, train entropy gap 1.2400 bits (loss 20.583, data 19.343) 
Epoch 12 Iter 6400, train entropy gap 1.6818 bits (loss 21.025, data 19.343) 
Epoch 12 Iter 6600, train entropy gap 1.6997 bits (loss 21.043, data 19.343) 
Epoch 12 Iter 6800, train entropy gap 1.7963 bits (loss 21.140, data 19.343) 
Epoch 12 Iter 7000, train entropy gap 2.1332 bits (loss 21.477, data 19.343) 
epoch 12 train loss 14.7560 nats / 21.2884 bits
time since start: 1300.4 secs
Epoch 13 Iter 0, train entropy gap 1.7013 bits (loss 21.045, data 19.343) 
Epoch 13 Iter 200, train entropy gap 2.2778 bits (loss 21.621, data 19.343) 
Epoch 13 Iter 400, train entropy gap 1.0349 bits (loss 20.378, data 19.343) 
Epoch 13 Iter 600, train entropy gap 3.0859 bits (loss 22.429, data 19.343) 
Epoch 13 Iter 800, train entropy gap 2.0570 bits (loss 21.400, data 19.343) 
Epoch 13 Iter 1000, train entropy gap 1.5741 bits (loss 20.918, data 19.343) 
Epoch 13 Iter 1200, train entropy gap 1.7261 bits (loss 21.070, data 19.343) 
Epoch 13 Iter 1400, train entropy gap 1.0221 bits (loss 20.366, data 19.343) 
Epoch 13 Iter 1600, train entropy gap 1.5578 bits (loss 20.901, data 19.343) 
Epoch 13 Iter 1800, train entropy gap 2.1282 bits (loss 21.472, data 19.343) 
Epoch 13 Iter 2000, train entropy gap 1.6192 bits (loss 20.963, data 19.343) 
Epoch 13 Iter 2200, train entropy gap 1.9563 bits (loss 21.300, data 19.343) 
Epoch 13 Iter 2400, train entropy gap 1.4698 bits (loss 20.813, data 19.343) 
Epoch 13 Iter 2600, train entropy gap 1.3163 bits (loss 20.660, data 19.343) 
Epoch 13 Iter 2800, train entropy gap 3.2931 bits (loss 22.637, data 19.343) 
Epoch 13 Iter 3000, train entropy gap 2.6884 bits (loss 22.032, data 19.343) 
Epoch 13 Iter 3200, train entropy gap 1.3244 bits (loss 20.668, data 19.343) 
Epoch 13 Iter 3400, train entropy gap 3.4674 bits (loss 22.811, data 19.343) 
Epoch 13 Iter 3600, train entropy gap 0.8542 bits (loss 20.198, data 19.343) 
Epoch 13 Iter 3800, train entropy gap 3.1499 bits (loss 22.493, data 19.343) 
Epoch 13 Iter 4000, train entropy gap 0.8104 bits (loss 20.154, data 19.343) 
Epoch 13 Iter 4200, train entropy gap 3.1167 bits (loss 22.460, data 19.343) 
Epoch 13 Iter 4400, train entropy gap 2.4890 bits (loss 21.832, data 19.343) 
Epoch 13 Iter 4600, train entropy gap 1.3201 bits (loss 20.664, data 19.343) 
Epoch 13 Iter 4800, train entropy gap 1.4624 bits (loss 20.806, data 19.343) 
Epoch 13 Iter 5000, train entropy gap 1.6859 bits (loss 21.029, data 19.343) 
Epoch 13 Iter 5200, train entropy gap 2.0433 bits (loss 21.387, data 19.343) 
Epoch 13 Iter 5400, train entropy gap 1.3877 bits (loss 20.731, data 19.343) 
Epoch 13 Iter 5600, train entropy gap 1.0334 bits (loss 20.377, data 19.343) 
Epoch 13 Iter 5800, train entropy gap 1.2658 bits (loss 20.609, data 19.343) 
Epoch 13 Iter 6000, train entropy gap 1.4675 bits (loss 20.811, data 19.343) 
Epoch 13 Iter 6200, train entropy gap 1.3978 bits (loss 20.741, data 19.343) 
Epoch 13 Iter 6400, train entropy gap 1.8124 bits (loss 21.156, data 19.343) 
Epoch 13 Iter 6600, train entropy gap 3.0506 bits (loss 22.394, data 19.343) 
Epoch 13 Iter 6800, train entropy gap 2.5870 bits (loss 21.930, data 19.343) 
Epoch 13 Iter 7000, train entropy gap 1.4175 bits (loss 20.761, data 19.343) 
epoch 13 train loss 14.7634 nats / 21.2991 bits
time since start: 1400.3 secs
Epoch 14 Iter 0, train entropy gap 0.9323 bits (loss 20.276, data 19.343) 
Epoch 14 Iter 200, train entropy gap 3.3703 bits (loss 22.714, data 19.343) 
Epoch 14 Iter 400, train entropy gap 1.3548 bits (loss 20.698, data 19.343) 
Epoch 14 Iter 600, train entropy gap 2.5543 bits (loss 21.898, data 19.343) 
Epoch 14 Iter 800, train entropy gap 2.0642 bits (loss 21.408, data 19.343) 
Epoch 14 Iter 1000, train entropy gap 3.4206 bits (loss 22.764, data 19.343) 
Epoch 14 Iter 1200, train entropy gap 2.2336 bits (loss 21.577, data 19.343) 
Epoch 14 Iter 1400, train entropy gap 1.6296 bits (loss 20.973, data 19.343) 
Epoch 14 Iter 1600, train entropy gap 1.0670 bits (loss 20.410, data 19.343) 
Epoch 14 Iter 1800, train entropy gap 1.1032 bits (loss 20.447, data 19.343) 
Epoch 14 Iter 2000, train entropy gap 2.6318 bits (loss 21.975, data 19.343) 
Epoch 14 Iter 2200, train entropy gap 2.0631 bits (loss 21.407, data 19.343) 
Epoch 14 Iter 2400, train entropy gap 2.2597 bits (loss 21.603, data 19.343) 
Epoch 14 Iter 2600, train entropy gap 1.2516 bits (loss 20.595, data 19.343) 
Epoch 14 Iter 2800, train entropy gap 1.6383 bits (loss 20.982, data 19.343) 
Epoch 14 Iter 3000, train entropy gap 1.2259 bits (loss 20.569, data 19.343) 
Epoch 14 Iter 3200, train entropy gap 1.6558 bits (loss 20.999, data 19.343) 
Epoch 14 Iter 3400, train entropy gap 2.8666 bits (loss 22.210, data 19.343) 
Epoch 14 Iter 3600, train entropy gap 0.9596 bits (loss 20.303, data 19.343) 
Epoch 14 Iter 3800, train entropy gap 2.6181 bits (loss 21.962, data 19.343) 
Epoch 14 Iter 4000, train entropy gap 1.6275 bits (loss 20.971, data 19.343) 
Epoch 14 Iter 4200, train entropy gap 1.5743 bits (loss 20.918, data 19.343) 
Epoch 14 Iter 4400, train entropy gap 2.6900 bits (loss 22.033, data 19.343) 
Epoch 14 Iter 4600, train entropy gap 1.2812 bits (loss 20.625, data 19.343) 
Epoch 14 Iter 4800, train entropy gap 1.7391 bits (loss 21.083, data 19.343) 
Epoch 14 Iter 5000, train entropy gap 2.6116 bits (loss 21.955, data 19.343) 
Epoch 14 Iter 5200, train entropy gap 2.3684 bits (loss 21.712, data 19.343) 
Epoch 14 Iter 5400, train entropy gap 1.3304 bits (loss 20.674, data 19.343) 
Epoch 14 Iter 5600, train entropy gap 2.2149 bits (loss 21.558, data 19.343) 
Epoch 14 Iter 5800, train entropy gap 1.4981 bits (loss 20.842, data 19.343) 
Epoch 14 Iter 6000, train entropy gap 2.9220 bits (loss 22.265, data 19.343) 
Epoch 14 Iter 6200, train entropy gap 1.0326 bits (loss 20.376, data 19.343) 
Epoch 14 Iter 6400, train entropy gap 2.3421 bits (loss 21.686, data 19.343) 
Epoch 14 Iter 6600, train entropy gap 2.1769 bits (loss 21.520, data 19.343) 
Epoch 14 Iter 6800, train entropy gap 2.3745 bits (loss 21.718, data 19.343) 
Epoch 14 Iter 7000, train entropy gap 1.8287 bits (loss 21.172, data 19.343) 
epoch 14 train loss 14.7567 nats / 21.2894 bits
time since start: 1499.9 secs
Epoch 15 Iter 0, train entropy gap 3.6994 bits (loss 23.043, data 19.343) 
Epoch 15 Iter 200, train entropy gap 1.5323 bits (loss 20.876, data 19.343) 
Epoch 15 Iter 400, train entropy gap 1.2359 bits (loss 20.579, data 19.343) 
Epoch 15 Iter 600, train entropy gap 2.1945 bits (loss 21.538, data 19.343) 
Epoch 15 Iter 800, train entropy gap 1.1303 bits (loss 20.474, data 19.343) 
Epoch 15 Iter 1000, train entropy gap 0.8342 bits (loss 20.178, data 19.343) 
Epoch 15 Iter 1200, train entropy gap 3.2077 bits (loss 22.551, data 19.343) 
Epoch 15 Iter 1400, train entropy gap 2.4186 bits (loss 21.762, data 19.343) 
Epoch 15 Iter 1600, train entropy gap 2.2399 bits (loss 21.583, data 19.343) 
Epoch 15 Iter 1800, train entropy gap 3.2358 bits (loss 22.579, data 19.343) 
Epoch 15 Iter 2000, train entropy gap 1.4306 bits (loss 20.774, data 19.343) 
Epoch 15 Iter 2200, train entropy gap 2.2467 bits (loss 21.590, data 19.343) 
Epoch 15 Iter 2400, train entropy gap 1.8631 bits (loss 21.207, data 19.343) 
Epoch 15 Iter 2600, train entropy gap 1.0998 bits (loss 20.443, data 19.343) 
Epoch 15 Iter 2800, train entropy gap 1.7820 bits (loss 21.125, data 19.343) 
Epoch 15 Iter 3000, train entropy gap 1.6901 bits (loss 21.034, data 19.343) 
Epoch 15 Iter 3200, train entropy gap 1.8287 bits (loss 21.172, data 19.343) 
Epoch 15 Iter 3400, train entropy gap 1.6224 bits (loss 20.966, data 19.343) 
Epoch 15 Iter 3600, train entropy gap 1.0679 bits (loss 20.411, data 19.343) 
Epoch 15 Iter 3800, train entropy gap 2.7514 bits (loss 22.095, data 19.343) 
Epoch 15 Iter 4000, train entropy gap 3.7146 bits (loss 23.058, data 19.343) 
Epoch 15 Iter 4200, train entropy gap 2.5389 bits (loss 21.882, data 19.343) 
Epoch 15 Iter 4400, train entropy gap 0.8910 bits (loss 20.234, data 19.343) 
Epoch 15 Iter 4600, train entropy gap 3.0294 bits (loss 22.373, data 19.343) 
Epoch 15 Iter 4800, train entropy gap 2.5825 bits (loss 21.926, data 19.343) 
Epoch 15 Iter 5000, train entropy gap 1.4867 bits (loss 20.830, data 19.343) 
Epoch 15 Iter 5200, train entropy gap 2.0650 bits (loss 21.408, data 19.343) 
Epoch 15 Iter 5400, train entropy gap 2.6498 bits (loss 21.993, data 19.343) 
Epoch 15 Iter 5600, train entropy gap 1.7184 bits (loss 21.062, data 19.343) 
Epoch 15 Iter 5800, train entropy gap 1.1669 bits (loss 20.510, data 19.343) 
Epoch 15 Iter 6000, train entropy gap 3.3008 bits (loss 22.644, data 19.343) 
Epoch 15 Iter 6200, train entropy gap 1.6486 bits (loss 20.992, data 19.343) 
Epoch 15 Iter 6400, train entropy gap 3.0329 bits (loss 22.376, data 19.343) 
Epoch 15 Iter 6600, train entropy gap 2.2857 bits (loss 21.629, data 19.343) 
Epoch 15 Iter 6800, train entropy gap 1.6677 bits (loss 21.011, data 19.343) 
Epoch 15 Iter 7000, train entropy gap 1.5709 bits (loss 20.914, data 19.343) 
epoch 15 train loss 14.7575 nats / 21.2906 bits
time since start: 1599.9 secs
Epoch 16 Iter 0, train entropy gap 2.5147 bits (loss 21.858, data 19.343) 
Epoch 16 Iter 200, train entropy gap 1.1102 bits (loss 20.454, data 19.343) 
Epoch 16 Iter 400, train entropy gap 3.0646 bits (loss 22.408, data 19.343) 
Epoch 16 Iter 600, train entropy gap 2.9116 bits (loss 22.255, data 19.343) 
Epoch 16 Iter 800, train entropy gap 2.1348 bits (loss 21.478, data 19.343) 
Epoch 16 Iter 1000, train entropy gap 1.6745 bits (loss 21.018, data 19.343) 
Epoch 16 Iter 1200, train entropy gap 2.0238 bits (loss 21.367, data 19.343) 
Epoch 16 Iter 1400, train entropy gap 2.1615 bits (loss 21.505, data 19.343) 
Epoch 16 Iter 1600, train entropy gap 1.7456 bits (loss 21.089, data 19.343) 
Epoch 16 Iter 1800, train entropy gap 2.0583 bits (loss 21.402, data 19.343) 
Epoch 16 Iter 2000, train entropy gap 2.6866 bits (loss 22.030, data 19.343) 
Epoch 16 Iter 2200, train entropy gap 2.6578 bits (loss 22.001, data 19.343) 
Epoch 16 Iter 2400, train entropy gap 1.4984 bits (loss 20.842, data 19.343) 
Epoch 16 Iter 2600, train entropy gap 1.4556 bits (loss 20.799, data 19.343) 
Epoch 16 Iter 2800, train entropy gap 1.5259 bits (loss 20.869, data 19.343) 
Epoch 16 Iter 3000, train entropy gap 1.1860 bits (loss 20.529, data 19.343) 
Epoch 16 Iter 3200, train entropy gap 1.1165 bits (loss 20.460, data 19.343) 
Epoch 16 Iter 3400, train entropy gap 2.0822 bits (loss 21.426, data 19.343) 
Epoch 16 Iter 3600, train entropy gap 0.8662 bits (loss 20.210, data 19.343) 
Epoch 16 Iter 3800, train entropy gap 2.3774 bits (loss 21.721, data 19.343) 
Epoch 16 Iter 4000, train entropy gap 2.0109 bits (loss 21.354, data 19.343) 
Epoch 16 Iter 4200, train entropy gap 2.5868 bits (loss 21.930, data 19.343) 
Epoch 16 Iter 4400, train entropy gap 0.9182 bits (loss 20.262, data 19.343) 
Epoch 16 Iter 4600, train entropy gap 1.1848 bits (loss 20.528, data 19.343) 
Epoch 16 Iter 4800, train entropy gap 0.9422 bits (loss 20.286, data 19.343) 
Epoch 16 Iter 5000, train entropy gap 1.8744 bits (loss 21.218, data 19.343) 
Epoch 16 Iter 5200, train entropy gap 3.0420 bits (loss 22.385, data 19.343) 
Epoch 16 Iter 5400, train entropy gap 1.9821 bits (loss 21.326, data 19.343) 
Epoch 16 Iter 5600, train entropy gap 1.1624 bits (loss 20.506, data 19.343) 
Epoch 16 Iter 5800, train entropy gap 1.7773 bits (loss 21.121, data 19.343) 
Epoch 16 Iter 6000, train entropy gap 3.0949 bits (loss 22.438, data 19.343) 
Epoch 16 Iter 6200, train entropy gap 2.1064 bits (loss 21.450, data 19.343) 
Epoch 16 Iter 6400, train entropy gap 1.7631 bits (loss 21.107, data 19.343) 
Epoch 16 Iter 6600, train entropy gap 1.5549 bits (loss 20.898, data 19.343) 
Epoch 16 Iter 6800, train entropy gap 2.7791 bits (loss 22.123, data 19.343) 
Epoch 16 Iter 7000, train entropy gap 1.0787 bits (loss 20.422, data 19.343) 
epoch 16 train loss 14.7570 nats / 21.2898 bits
time since start: 1699.4 secs
Epoch 17 Iter 0, train entropy gap 0.9120 bits (loss 20.255, data 19.343) 
Epoch 17 Iter 200, train entropy gap 1.3262 bits (loss 20.670, data 19.343) 
Epoch 17 Iter 400, train entropy gap 1.3039 bits (loss 20.647, data 19.343) 
Epoch 17 Iter 600, train entropy gap 1.5517 bits (loss 20.895, data 19.343) 
Epoch 17 Iter 800, train entropy gap 1.0305 bits (loss 20.374, data 19.343) 
Epoch 17 Iter 1000, train entropy gap 1.9983 bits (loss 21.342, data 19.343) 
Epoch 17 Iter 1200, train entropy gap 3.0062 bits (loss 22.350, data 19.343) 
Epoch 17 Iter 1400, train entropy gap 1.1387 bits (loss 20.482, data 19.343) 
Epoch 17 Iter 1600, train entropy gap 1.1723 bits (loss 20.516, data 19.343) 
Epoch 17 Iter 1800, train entropy gap 1.5381 bits (loss 20.882, data 19.343) 
Epoch 17 Iter 2000, train entropy gap 2.5910 bits (loss 21.934, data 19.343) 
Epoch 17 Iter 2200, train entropy gap 3.2103 bits (loss 22.554, data 19.343) 
Epoch 17 Iter 2400, train entropy gap 1.4738 bits (loss 20.817, data 19.343) 
Epoch 17 Iter 2600, train entropy gap 2.3607 bits (loss 21.704, data 19.343) 
Epoch 17 Iter 2800, train entropy gap 1.4304 bits (loss 20.774, data 19.343) 
Epoch 17 Iter 3000, train entropy gap 2.4442 bits (loss 21.788, data 19.343) 
Epoch 17 Iter 3200, train entropy gap 1.5842 bits (loss 20.928, data 19.343) 
Epoch 17 Iter 3400, train entropy gap 2.7321 bits (loss 22.076, data 19.343) 
Epoch 17 Iter 3600, train entropy gap 1.8064 bits (loss 21.150, data 19.343) 
Epoch 17 Iter 3800, train entropy gap 2.1859 bits (loss 21.529, data 19.343) 
Epoch 17 Iter 4000, train entropy gap 1.0629 bits (loss 20.406, data 19.343) 
Epoch 17 Iter 4200, train entropy gap 0.5082 bits (loss 19.852, data 19.343) 
Epoch 17 Iter 4400, train entropy gap 1.9334 bits (loss 21.277, data 19.343) 
Epoch 17 Iter 4600, train entropy gap 1.7891 bits (loss 21.133, data 19.343) 
Epoch 17 Iter 4800, train entropy gap 3.4330 bits (loss 22.776, data 19.343) 
Epoch 17 Iter 5000, train entropy gap 1.3550 bits (loss 20.699, data 19.343) 
Epoch 17 Iter 5200, train entropy gap 1.4679 bits (loss 20.811, data 19.343) 
Epoch 17 Iter 5400, train entropy gap 2.7885 bits (loss 22.132, data 19.343) 
Epoch 17 Iter 5600, train entropy gap 1.4768 bits (loss 20.820, data 19.343) 
Epoch 17 Iter 5800, train entropy gap 2.8487 bits (loss 22.192, data 19.343) 
Epoch 17 Iter 6000, train entropy gap 1.1277 bits (loss 20.471, data 19.343) 
Epoch 17 Iter 6200, train entropy gap 1.9105 bits (loss 21.254, data 19.343) 
Epoch 17 Iter 6400, train entropy gap 2.3446 bits (loss 21.688, data 19.343) 
Epoch 17 Iter 6600, train entropy gap 1.6329 bits (loss 20.976, data 19.343) 
Epoch 17 Iter 6800, train entropy gap 2.1827 bits (loss 21.526, data 19.343) 
Epoch 17 Iter 7000, train entropy gap 1.9730 bits (loss 21.316, data 19.343) 
epoch 17 train loss 14.7524 nats / 21.2833 bits
time since start: 1798.9 secs
Epoch 18 Iter 0, train entropy gap 1.6590 bits (loss 21.002, data 19.343) 
Epoch 18 Iter 200, train entropy gap 2.0673 bits (loss 21.411, data 19.343) 
Epoch 18 Iter 400, train entropy gap 1.3810 bits (loss 20.724, data 19.343) 
Epoch 18 Iter 600, train entropy gap 1.4511 bits (loss 20.795, data 19.343) 
Epoch 18 Iter 800, train entropy gap 1.7013 bits (loss 21.045, data 19.343) 
Epoch 18 Iter 1000, train entropy gap 1.3235 bits (loss 20.667, data 19.343) 
Epoch 18 Iter 1200, train entropy gap 3.0467 bits (loss 22.390, data 19.343) 
Epoch 18 Iter 1400, train entropy gap 1.6318 bits (loss 20.975, data 19.343) 
Epoch 18 Iter 1600, train entropy gap 1.3323 bits (loss 20.676, data 19.343) 
Epoch 18 Iter 1800, train entropy gap 2.7738 bits (loss 22.117, data 19.343) 
Epoch 18 Iter 2000, train entropy gap 3.6447 bits (loss 22.988, data 19.343) 
Epoch 18 Iter 2200, train entropy gap 1.7766 bits (loss 21.120, data 19.343) 
Epoch 18 Iter 2400, train entropy gap 3.2779 bits (loss 22.621, data 19.343) 
Epoch 18 Iter 2600, train entropy gap 0.9184 bits (loss 20.262, data 19.343) 
Epoch 18 Iter 2800, train entropy gap 1.6272 bits (loss 20.971, data 19.343) 
Epoch 18 Iter 3000, train entropy gap 2.0494 bits (loss 21.393, data 19.343) 
Epoch 18 Iter 3200, train entropy gap 2.6956 bits (loss 22.039, data 19.343) 
Epoch 18 Iter 3400, train entropy gap 0.9281 bits (loss 20.272, data 19.343) 
Epoch 18 Iter 3600, train entropy gap 1.6485 bits (loss 20.992, data 19.343) 
Epoch 18 Iter 3800, train entropy gap 3.0509 bits (loss 22.394, data 19.343) 
Epoch 18 Iter 4000, train entropy gap 1.2492 bits (loss 20.593, data 19.343) 
Epoch 18 Iter 4200, train entropy gap 1.8657 bits (loss 21.209, data 19.343) 
Epoch 18 Iter 4400, train entropy gap 3.1395 bits (loss 22.483, data 19.343) 
Epoch 18 Iter 4600, train entropy gap 1.2663 bits (loss 20.610, data 19.343) 
Epoch 18 Iter 4800, train entropy gap 1.5293 bits (loss 20.873, data 19.343) 
Epoch 18 Iter 5000, train entropy gap 2.1281 bits (loss 21.472, data 19.343) 
Epoch 18 Iter 5200, train entropy gap 3.1566 bits (loss 22.500, data 19.343) 
Epoch 18 Iter 5400, train entropy gap 2.3606 bits (loss 21.704, data 19.343) 
Epoch 18 Iter 5600, train entropy gap 1.2849 bits (loss 20.628, data 19.343) 
Epoch 18 Iter 5800, train entropy gap 3.1829 bits (loss 22.526, data 19.343) 
Epoch 18 Iter 6000, train entropy gap 3.0077 bits (loss 22.351, data 19.343) 
Epoch 18 Iter 6200, train entropy gap 2.1648 bits (loss 21.508, data 19.343) 
Epoch 18 Iter 6400, train entropy gap 0.8130 bits (loss 20.156, data 19.343) 
Epoch 18 Iter 6600, train entropy gap 1.4313 bits (loss 20.775, data 19.343) 
Epoch 18 Iter 6800, train entropy gap 1.6535 bits (loss 20.997, data 19.343) 
Epoch 18 Iter 7000, train entropy gap 3.2859 bits (loss 22.629, data 19.343) 
epoch 18 train loss 14.7677 nats / 21.3053 bits
time since start: 1898.5 secs
Epoch 19 Iter 0, train entropy gap 2.1394 bits (loss 21.483, data 19.343) 
Epoch 19 Iter 200, train entropy gap 1.4838 bits (loss 20.827, data 19.343) 
Epoch 19 Iter 400, train entropy gap 2.4158 bits (loss 21.759, data 19.343) 
Epoch 19 Iter 600, train entropy gap 1.2874 bits (loss 20.631, data 19.343) 
Epoch 19 Iter 800, train entropy gap 2.0881 bits (loss 21.432, data 19.343) 
Epoch 19 Iter 1000, train entropy gap 1.9422 bits (loss 21.286, data 19.343) 
Epoch 19 Iter 1200, train entropy gap 2.0165 bits (loss 21.360, data 19.343) 
Epoch 19 Iter 1400, train entropy gap 1.8835 bits (loss 21.227, data 19.343) 
Epoch 19 Iter 1600, train entropy gap 1.4610 bits (loss 20.804, data 19.343) 
Epoch 19 Iter 1800, train entropy gap 0.8554 bits (loss 20.199, data 19.343) 
Epoch 19 Iter 2000, train entropy gap 1.0332 bits (loss 20.377, data 19.343) 
Epoch 19 Iter 2200, train entropy gap 2.7755 bits (loss 22.119, data 19.343) 
Epoch 19 Iter 2400, train entropy gap 1.1000 bits (loss 20.443, data 19.343) 
Epoch 19 Iter 2600, train entropy gap 2.6052 bits (loss 21.949, data 19.343) 
Epoch 19 Iter 2800, train entropy gap 0.9607 bits (loss 20.304, data 19.343) 
Epoch 19 Iter 3000, train entropy gap 1.3601 bits (loss 20.704, data 19.343) 
Epoch 19 Iter 3200, train entropy gap 1.0968 bits (loss 20.440, data 19.343) 
Epoch 19 Iter 3400, train entropy gap 1.8182 bits (loss 21.162, data 19.343) 
Epoch 19 Iter 3600, train entropy gap 1.4418 bits (loss 20.785, data 19.343) 
Epoch 19 Iter 3800, train entropy gap 2.5147 bits (loss 21.858, data 19.343) 
Epoch 19 Iter 4000, train entropy gap 2.4729 bits (loss 21.816, data 19.343) 
Epoch 19 Iter 4200, train entropy gap 1.5847 bits (loss 20.928, data 19.343) 
Epoch 19 Iter 4400, train entropy gap 2.4521 bits (loss 21.796, data 19.343) 
Epoch 19 Iter 4600, train entropy gap 1.9831 bits (loss 21.327, data 19.343) 
Epoch 19 Iter 4800, train entropy gap 2.9250 bits (loss 22.268, data 19.343) 
Epoch 19 Iter 5000, train entropy gap 3.3603 bits (loss 22.704, data 19.343) 
Epoch 19 Iter 5200, train entropy gap 2.8202 bits (loss 22.164, data 19.343) 
Epoch 19 Iter 5400, train entropy gap 1.8076 bits (loss 21.151, data 19.343) 
Epoch 19 Iter 5600, train entropy gap 2.3063 bits (loss 21.650, data 19.343) 
Epoch 19 Iter 5800, train entropy gap 1.2640 bits (loss 20.607, data 19.343) 
Epoch 19 Iter 6000, train entropy gap 1.3688 bits (loss 20.712, data 19.343) 
Epoch 19 Iter 6200, train entropy gap 1.4914 bits (loss 20.835, data 19.343) 
Epoch 19 Iter 6400, train entropy gap 1.1216 bits (loss 20.465, data 19.343) 
Epoch 19 Iter 6600, train entropy gap 3.5763 bits (loss 22.920, data 19.343) 
Epoch 19 Iter 6800, train entropy gap 1.0259 bits (loss 20.369, data 19.343) 
Epoch 19 Iter 7000, train entropy gap 1.9974 bits (loss 21.341, data 19.343) 
epoch 19 train loss 14.7532 nats / 21.2843 bits
time since start: 1997.8 secs
Training done; evaluating likelihood on full data:
Epoch None Iter 0, test loss 17.7872 nats / 25.6615 bits
Epoch None Iter 500, test loss 14.9874 nats / 21.6222 bits
Epoch None Iter 1000, test loss 13.1414 nats / 18.9591 bits
Epoch None Iter 1500, test loss 12.6291 nats / 18.2200 bits
Epoch None Iter 2000, test loss 13.3918 nats / 19.3203 bits
Epoch None Iter 2500, test loss 12.4459 nats / 17.9556 bits
Epoch None Iter 3000, test loss 15.4760 nats / 22.3272 bits
Epoch None Iter 3500, test loss 13.0021 nats / 18.7581 bits
Epoch None Iter 4000, test loss 12.6363 nats / 18.2303 bits
Epoch None Iter 4500, test loss 13.7181 nats / 19.7911 bits
Epoch None Iter 5000, test loss 12.7741 nats / 18.4291 bits
Epoch None Iter 5500, test loss 15.4346 nats / 22.2674 bits
Epoch None Iter 6000, test loss 14.0171 nats / 20.2224 bits
Epoch None Iter 6500, test loss 13.1015 nats / 18.9014 bits
Epoch None Iter 7000, test loss 17.0186 nats / 24.5526 bits
Saved to:
models/dmv-ofnan-1.6MB-model20.263-data19.343-transformer-blocks4-model64-ff256-heads4-use_flash_attnTrue-posEmb-gelu-colmask-20epochs-seed0.pt
