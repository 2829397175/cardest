Device cuda
Loading csv... done, took 6.2s
Parsing... done, took 5.0s
Entropy of DMV([Column(Record Type, distribution_size=8), Column(Registration Class, distribution_size=72), Column(State, distribution_size=79), Column(County, distribution_size=64), Column(Body Type, distribution_size=59), Column(Fuel Type, distribution_size=10), Column(Reg Valid Date, distribution_size=2884), Column(Color, distribution_size=222), Column(Scofflaw Indicator, distribution_size=3), Column(Suspension Indicator, distribution_size=3), Column(Revocation Indicator, distribution_size=3)]): 19.3808 bits
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7389597 entries, 0 to 7389596
Data columns (total 11 columns):
 #   Column                Dtype         
---  ------                -----         
 0   Record Type           object        
 1   Registration Class    object        
 2   State                 object        
 3   County                object        
 4   Body Type             object        
 5   Fuel Type             object        
 6   Reg Valid Date        datetime64[ns]
 7   Color                 object        
 8   Scofflaw Indicator    object        
 9   Suspension Indicator  object        
 10  Revocation Indicator  object        
dtypes: datetime64[ns](1), object(10)
memory usage: 620.2+ MB
None
MASK_SCHEME 0
ordering [ 0  1  2  3  4  5  6  7  8  9 10]
using orig mask
 tensor([[ True, False, False, False, False, False, False, False, False, False,
         False],
        [ True,  True, False, False, False, False, False, False, False, False,
         False],
        [ True,  True,  True, False, False, False, False, False, False, False,
         False],
        [ True,  True,  True,  True, False, False, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True, False, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True]])
Number of model parameters: 418816 (~= 1.6MB)
Transformer(
  (blocks): Sequential(
    (0): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=64, out_features=192, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
    )
    (1): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=64, out_features=192, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
    )
    (2): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=64, out_features=192, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
    )
    (3): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=64, out_features=192, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=64, out_features=64, bias=True)
      )
    )
  )
  (norm): LayerNorm()
  (embeddings): ModuleList(
    (0): Embedding(8, 64)
    (1): Embedding(72, 64)
    (2): Embedding(79, 64)
    (3): Embedding(64, 64)
    (4): Embedding(59, 64)
    (5): Embedding(10, 64)
    (6): Embedding(2884, 64)
    (7): Embedding(222, 64)
    (8): Embedding(3, 64)
    (9): Embedding(3, 64)
    (10): Embedding(3, 64)
  )
  (pos_embeddings): Embedding(11, 64)
)
Discretizing table... done, took 4.7s
Epoch 0 Iter 0, train entropy gap 35.0831 bits (loss 54.464, data 19.381) 
Epoch 0 Iter 200, train entropy gap 34.6905 bits (loss 54.071, data 19.381) 
Epoch 0 Iter 400, train entropy gap 33.5519 bits (loss 52.933, data 19.381) 
Epoch 0 Iter 600, train entropy gap 31.6334 bits (loss 51.014, data 19.381) 
Epoch 0 Iter 800, train entropy gap 29.2298 bits (loss 48.611, data 19.381) 
Epoch 0 Iter 1000, train entropy gap 26.5935 bits (loss 45.974, data 19.381) 
Epoch 0 Iter 1200, train entropy gap 23.7467 bits (loss 43.127, data 19.381) 
Epoch 0 Iter 1400, train entropy gap 20.8361 bits (loss 40.217, data 19.381) 
Epoch 0 Iter 1600, train entropy gap 17.2842 bits (loss 36.665, data 19.381) 
Epoch 0 Iter 1800, train entropy gap 14.2083 bits (loss 33.589, data 19.381) 
Epoch 0 Iter 2000, train entropy gap 11.3964 bits (loss 30.777, data 19.381) 
Epoch 0 Iter 2200, train entropy gap 8.7990 bits (loss 28.180, data 19.381) 
Epoch 0 Iter 2400, train entropy gap 6.3671 bits (loss 25.748, data 19.381) 
Epoch 0 Iter 2600, train entropy gap 4.3118 bits (loss 23.693, data 19.381) 
Epoch 0 Iter 2800, train entropy gap 2.4034 bits (loss 21.784, data 19.381) 
Epoch 0 Iter 3000, train entropy gap 1.1099 bits (loss 20.491, data 19.381) 
Epoch 0 Iter 3200, train entropy gap -0.0794 bits (loss 19.301, data 19.381) 
Epoch 0 Iter 3400, train entropy gap -1.2113 bits (loss 18.170, data 19.381) 
Epoch 0 Iter 3600, train entropy gap -2.4984 bits (loss 16.882, data 19.381) 
Epoch 0 Iter 3800, train entropy gap -3.4528 bits (loss 15.928, data 19.381) 
Epoch 0 Iter 4000, train entropy gap -4.4410 bits (loss 14.940, data 19.381) 
Epoch 0 Iter 4200, train entropy gap -5.5999 bits (loss 13.781, data 19.381) 
Epoch 0 Iter 4400, train entropy gap -6.4470 bits (loss 12.934, data 19.381) 
Epoch 0 Iter 4600, train entropy gap -7.1452 bits (loss 12.236, data 19.381) 
Epoch 0 Iter 4800, train entropy gap -7.6685 bits (loss 11.712, data 19.381) 
Epoch 0 Iter 5000, train entropy gap -8.4425 bits (loss 10.938, data 19.381) 
Epoch 0 Iter 5200, train entropy gap -9.1292 bits (loss 10.252, data 19.381) 
Epoch 0 Iter 5400, train entropy gap -9.6442 bits (loss 9.737, data 19.381) 
Epoch 0 Iter 5600, train entropy gap -10.2863 bits (loss 9.095, data 19.381) 
Epoch 0 Iter 5800, train entropy gap -10.5000 bits (loss 8.881, data 19.381) 
Epoch 0 Iter 6000, train entropy gap -11.1396 bits (loss 8.241, data 19.381) 
Epoch 0 Iter 6200, train entropy gap -11.6851 bits (loss 7.696, data 19.381) 
Epoch 0 Iter 6400, train entropy gap -12.1877 bits (loss 7.193, data 19.381) 
Epoch 0 Iter 6600, train entropy gap -12.8751 bits (loss 6.506, data 19.381) 
Epoch 0 Iter 6800, train entropy gap -13.2430 bits (loss 6.138, data 19.381) 
Epoch 0 Iter 7000, train entropy gap -13.7302 bits (loss 5.651, data 19.381) 
Epoch 0 Iter 7200, train entropy gap -14.2750 bits (loss 5.106, data 19.381) 
epoch 0 train loss 15.6409 nats / 22.5650 bits
time since start: 91.1 secs
Epoch 1 Iter 0, train entropy gap -14.2265 bits (loss 5.154, data 19.381) 
Epoch 1 Iter 200, train entropy gap -14.3561 bits (loss 5.025, data 19.381) 
Epoch 1 Iter 400, train entropy gap -14.3026 bits (loss 5.078, data 19.381) 
Epoch 1 Iter 600, train entropy gap -14.4539 bits (loss 4.927, data 19.381) 
Epoch 1 Iter 800, train entropy gap -14.4377 bits (loss 4.943, data 19.381) 
Epoch 1 Iter 1000, train entropy gap -14.5936 bits (loss 4.787, data 19.381) 
Epoch 1 Iter 1200, train entropy gap -14.6501 bits (loss 4.731, data 19.381) 
Epoch 1 Iter 1400, train entropy gap -14.7441 bits (loss 4.637, data 19.381) 
Epoch 1 Iter 1600, train entropy gap -14.6910 bits (loss 4.690, data 19.381) 
Epoch 1 Iter 1800, train entropy gap -14.9392 bits (loss 4.442, data 19.381) 
Epoch 1 Iter 2000, train entropy gap -15.0047 bits (loss 4.376, data 19.381) 
Epoch 1 Iter 2200, train entropy gap -15.1159 bits (loss 4.265, data 19.381) 
Epoch 1 Iter 2400, train entropy gap -15.1065 bits (loss 4.274, data 19.381) 
Epoch 1 Iter 2600, train entropy gap -15.3997 bits (loss 3.981, data 19.381) 
Epoch 1 Iter 2800, train entropy gap -15.5528 bits (loss 3.828, data 19.381) 
Epoch 1 Iter 3000, train entropy gap -15.6767 bits (loss 3.704, data 19.381) 
Epoch 1 Iter 3200, train entropy gap -15.9734 bits (loss 3.407, data 19.381) 
Epoch 1 Iter 3400, train entropy gap -15.9230 bits (loss 3.458, data 19.381) 
Epoch 1 Iter 3600, train entropy gap -16.2361 bits (loss 3.145, data 19.381) 
Epoch 1 Iter 3800, train entropy gap -16.2432 bits (loss 3.138, data 19.381) 
Epoch 1 Iter 4000, train entropy gap -16.2969 bits (loss 3.084, data 19.381) 
Epoch 1 Iter 4200, train entropy gap -16.7008 bits (loss 2.680, data 19.381) 
Epoch 1 Iter 4400, train entropy gap -16.7745 bits (loss 2.606, data 19.381) 
Epoch 1 Iter 4600, train entropy gap -16.9637 bits (loss 2.417, data 19.381) 
Epoch 1 Iter 4800, train entropy gap -17.0518 bits (loss 2.329, data 19.381) 
Epoch 1 Iter 5000, train entropy gap -17.1520 bits (loss 2.229, data 19.381) 
Epoch 1 Iter 5200, train entropy gap -17.3373 bits (loss 2.043, data 19.381) 
Epoch 1 Iter 5400, train entropy gap -17.4887 bits (loss 1.892, data 19.381) 
Epoch 1 Iter 5600, train entropy gap -17.8008 bits (loss 1.580, data 19.381) 
Epoch 1 Iter 5800, train entropy gap -17.7667 bits (loss 1.614, data 19.381) 
Epoch 1 Iter 6000, train entropy gap -17.8405 bits (loss 1.540, data 19.381) 
Epoch 1 Iter 6200, train entropy gap -18.1335 bits (loss 1.247, data 19.381) 
Epoch 1 Iter 6400, train entropy gap -18.0124 bits (loss 1.368, data 19.381) 
Epoch 1 Iter 6600, train entropy gap -18.3265 bits (loss 1.054, data 19.381) 
Epoch 1 Iter 6800, train entropy gap -18.2161 bits (loss 1.165, data 19.381) 
Epoch 1 Iter 7000, train entropy gap -18.4187 bits (loss 0.962, data 19.381) 
Epoch 1 Iter 7200, train entropy gap -18.4373 bits (loss 0.943, data 19.381) 
epoch 1 train loss 2.1945 nats / 3.1660 bits
time since start: 181.5 secs
Epoch 2 Iter 0, train entropy gap -18.4926 bits (loss 0.888, data 19.381) 
Epoch 2 Iter 200, train entropy gap -18.4466 bits (loss 0.934, data 19.381) 
Epoch 2 Iter 400, train entropy gap -18.4960 bits (loss 0.885, data 19.381) 
Epoch 2 Iter 600, train entropy gap -18.4984 bits (loss 0.882, data 19.381) 
Epoch 2 Iter 800, train entropy gap -18.4235 bits (loss 0.957, data 19.381) 
Epoch 2 Iter 1000, train entropy gap -18.5087 bits (loss 0.872, data 19.381) 
Epoch 2 Iter 1200, train entropy gap -18.5357 bits (loss 0.845, data 19.381) 
Epoch 2 Iter 1400, train entropy gap -18.5126 bits (loss 0.868, data 19.381) 
Epoch 2 Iter 1600, train entropy gap -18.5553 bits (loss 0.826, data 19.381) 
Epoch 2 Iter 1800, train entropy gap -18.6026 bits (loss 0.778, data 19.381) 
Epoch 2 Iter 2000, train entropy gap -18.6478 bits (loss 0.733, data 19.381) 
Epoch 2 Iter 2200, train entropy gap -18.6885 bits (loss 0.692, data 19.381) 
Epoch 2 Iter 2400, train entropy gap -18.5715 bits (loss 0.809, data 19.381) 
Epoch 2 Iter 2600, train entropy gap -18.6144 bits (loss 0.766, data 19.381) 
Epoch 2 Iter 2800, train entropy gap -18.6957 bits (loss 0.685, data 19.381) 
Epoch 2 Iter 3000, train entropy gap -18.5959 bits (loss 0.785, data 19.381) 
Epoch 2 Iter 3200, train entropy gap -18.8013 bits (loss 0.579, data 19.381) 
Epoch 2 Iter 3400, train entropy gap -18.6101 bits (loss 0.771, data 19.381) 
Epoch 2 Iter 3600, train entropy gap -18.6889 bits (loss 0.692, data 19.381) 
Epoch 2 Iter 3800, train entropy gap -18.8062 bits (loss 0.575, data 19.381) 
Epoch 2 Iter 4000, train entropy gap -18.7707 bits (loss 0.610, data 19.381) 
Epoch 2 Iter 4200, train entropy gap -18.7861 bits (loss 0.595, data 19.381) 
Epoch 2 Iter 4400, train entropy gap -18.7152 bits (loss 0.666, data 19.381) 
Epoch 2 Iter 4600, train entropy gap -18.9001 bits (loss 0.481, data 19.381) 
Epoch 2 Iter 4800, train entropy gap -18.8856 bits (loss 0.495, data 19.381) 
Epoch 2 Iter 5000, train entropy gap -18.8466 bits (loss 0.534, data 19.381) 
Epoch 2 Iter 5200, train entropy gap -18.8694 bits (loss 0.511, data 19.381) 
Epoch 2 Iter 5400, train entropy gap -18.8614 bits (loss 0.519, data 19.381) 
Epoch 2 Iter 5600, train entropy gap -18.8496 bits (loss 0.531, data 19.381) 
Epoch 2 Iter 5800, train entropy gap -18.9557 bits (loss 0.425, data 19.381) 
Epoch 2 Iter 6000, train entropy gap -18.9131 bits (loss 0.468, data 19.381) 
Epoch 2 Iter 6200, train entropy gap -18.9768 bits (loss 0.404, data 19.381) 
Epoch 2 Iter 6400, train entropy gap -18.9484 bits (loss 0.432, data 19.381) 
Epoch 2 Iter 6600, train entropy gap -18.9629 bits (loss 0.418, data 19.381) 
Epoch 2 Iter 6800, train entropy gap -18.9745 bits (loss 0.406, data 19.381) 
Epoch 2 Iter 7000, train entropy gap -18.9314 bits (loss 0.449, data 19.381) 
Epoch 2 Iter 7200, train entropy gap -18.9871 bits (loss 0.394, data 19.381) 
epoch 2 train loss 0.4643 nats / 0.6698 bits
time since start: 271.8 secs
Epoch 3 Iter 0, train entropy gap -18.9821 bits (loss 0.399, data 19.381) 
Epoch 3 Iter 200, train entropy gap -19.0052 bits (loss 0.376, data 19.381) 
Epoch 3 Iter 400, train entropy gap -19.0002 bits (loss 0.381, data 19.381) 
Epoch 3 Iter 600, train entropy gap -18.9865 bits (loss 0.394, data 19.381) 
Epoch 3 Iter 800, train entropy gap -19.0532 bits (loss 0.328, data 19.381) 
Epoch 3 Iter 1000, train entropy gap -19.0101 bits (loss 0.371, data 19.381) 
Epoch 3 Iter 1200, train entropy gap -18.9567 bits (loss 0.424, data 19.381) 
Epoch 3 Iter 1400, train entropy gap -18.9575 bits (loss 0.423, data 19.381) 
Epoch 3 Iter 1600, train entropy gap -19.0718 bits (loss 0.309, data 19.381) 
Epoch 3 Iter 1800, train entropy gap -19.0406 bits (loss 0.340, data 19.381) 
Epoch 3 Iter 2000, train entropy gap -19.0238 bits (loss 0.357, data 19.381) 
Epoch 3 Iter 2200, train entropy gap -19.0321 bits (loss 0.349, data 19.381) 
Epoch 3 Iter 2400, train entropy gap -19.0054 bits (loss 0.375, data 19.381) 
Epoch 3 Iter 2600, train entropy gap -18.9910 bits (loss 0.390, data 19.381) 
Epoch 3 Iter 2800, train entropy gap -19.0465 bits (loss 0.334, data 19.381) 
Epoch 3 Iter 3000, train entropy gap -19.0270 bits (loss 0.354, data 19.381) 
Epoch 3 Iter 3200, train entropy gap -19.0027 bits (loss 0.378, data 19.381) 
Epoch 3 Iter 3400, train entropy gap -19.0872 bits (loss 0.294, data 19.381) 
Epoch 3 Iter 3600, train entropy gap -19.0246 bits (loss 0.356, data 19.381) 
Epoch 3 Iter 3800, train entropy gap -19.0437 bits (loss 0.337, data 19.381) 
Epoch 3 Iter 4000, train entropy gap -19.1040 bits (loss 0.277, data 19.381) 
Epoch 3 Iter 4200, train entropy gap -19.1140 bits (loss 0.267, data 19.381) 
Epoch 3 Iter 4400, train entropy gap -19.0188 bits (loss 0.362, data 19.381) 
Epoch 3 Iter 4600, train entropy gap -19.0976 bits (loss 0.283, data 19.381) 
Epoch 3 Iter 4800, train entropy gap -19.0440 bits (loss 0.337, data 19.381) 
Epoch 3 Iter 5000, train entropy gap -19.0672 bits (loss 0.314, data 19.381) 
Epoch 3 Iter 5200, train entropy gap -19.0646 bits (loss 0.316, data 19.381) 
Epoch 3 Iter 5400, train entropy gap -19.1050 bits (loss 0.276, data 19.381) 
Epoch 3 Iter 5600, train entropy gap -19.1108 bits (loss 0.270, data 19.381) 
Epoch 3 Iter 5800, train entropy gap -19.1654 bits (loss 0.215, data 19.381) 
Epoch 3 Iter 6000, train entropy gap -19.1558 bits (loss 0.225, data 19.381) 
Epoch 3 Iter 6200, train entropy gap -19.1496 bits (loss 0.231, data 19.381) 
Epoch 3 Iter 6400, train entropy gap -19.0933 bits (loss 0.287, data 19.381) 
Epoch 3 Iter 6600, train entropy gap -19.0766 bits (loss 0.304, data 19.381) 
Epoch 3 Iter 6800, train entropy gap -19.0715 bits (loss 0.309, data 19.381) 
Epoch 3 Iter 7000, train entropy gap -19.1407 bits (loss 0.240, data 19.381) 
Epoch 3 Iter 7200, train entropy gap -19.1151 bits (loss 0.266, data 19.381) 
epoch 3 train loss 0.2214 nats / 0.3194 bits
time since start: 361.0 secs
Epoch 4 Iter 0, train entropy gap -19.1602 bits (loss 0.221, data 19.381) 
Epoch 4 Iter 200, train entropy gap -19.0614 bits (loss 0.319, data 19.381) 
Epoch 4 Iter 400, train entropy gap -19.2025 bits (loss 0.178, data 19.381) 
Epoch 4 Iter 600, train entropy gap -19.1805 bits (loss 0.200, data 19.381) 
Epoch 4 Iter 800, train entropy gap -19.1174 bits (loss 0.263, data 19.381) 
Epoch 4 Iter 1000, train entropy gap -19.1534 bits (loss 0.227, data 19.381) 
Epoch 4 Iter 1200, train entropy gap -19.1466 bits (loss 0.234, data 19.381) 
Epoch 4 Iter 1400, train entropy gap -19.1701 bits (loss 0.211, data 19.381) 
Epoch 4 Iter 1600, train entropy gap -19.0759 bits (loss 0.305, data 19.381) 
Epoch 4 Iter 1800, train entropy gap -19.1577 bits (loss 0.223, data 19.381) 
Epoch 4 Iter 2000, train entropy gap -19.1047 bits (loss 0.276, data 19.381) 
Epoch 4 Iter 2200, train entropy gap -19.2105 bits (loss 0.170, data 19.381) 
Epoch 4 Iter 2400, train entropy gap -19.1938 bits (loss 0.187, data 19.381) 
Epoch 4 Iter 2600, train entropy gap -19.1537 bits (loss 0.227, data 19.381) 
Epoch 4 Iter 2800, train entropy gap -19.1524 bits (loss 0.228, data 19.381) 
Epoch 4 Iter 3000, train entropy gap -19.1958 bits (loss 0.185, data 19.381) 
Epoch 4 Iter 3200, train entropy gap -19.1427 bits (loss 0.238, data 19.381) 
Epoch 4 Iter 3400, train entropy gap -19.1506 bits (loss 0.230, data 19.381) 
Epoch 4 Iter 3600, train entropy gap -19.1544 bits (loss 0.226, data 19.381) 
Epoch 4 Iter 3800, train entropy gap -19.1694 bits (loss 0.211, data 19.381) 
Epoch 4 Iter 4000, train entropy gap -19.1261 bits (loss 0.255, data 19.381) 
Epoch 4 Iter 4200, train entropy gap -19.1633 bits (loss 0.218, data 19.381) 
Epoch 4 Iter 4400, train entropy gap -19.1174 bits (loss 0.263, data 19.381) 
Epoch 4 Iter 4600, train entropy gap -19.1775 bits (loss 0.203, data 19.381) 
Epoch 4 Iter 4800, train entropy gap -19.1608 bits (loss 0.220, data 19.381) 
Epoch 4 Iter 5000, train entropy gap -19.1816 bits (loss 0.199, data 19.381) 
Epoch 4 Iter 5200, train entropy gap -19.1626 bits (loss 0.218, data 19.381) 
Epoch 4 Iter 5400, train entropy gap -19.2184 bits (loss 0.162, data 19.381) 
Epoch 4 Iter 5600, train entropy gap -19.1578 bits (loss 0.223, data 19.381) 
Epoch 4 Iter 5800, train entropy gap -19.1463 bits (loss 0.234, data 19.381) 
Epoch 4 Iter 6000, train entropy gap -19.1306 bits (loss 0.250, data 19.381) 
Epoch 4 Iter 6200, train entropy gap -19.2417 bits (loss 0.139, data 19.381) 
Epoch 4 Iter 6400, train entropy gap -19.2028 bits (loss 0.178, data 19.381) 
Epoch 4 Iter 6600, train entropy gap -19.1914 bits (loss 0.189, data 19.381) 
Epoch 4 Iter 6800, train entropy gap -19.0956 bits (loss 0.285, data 19.381) 
Epoch 4 Iter 7000, train entropy gap -19.2095 bits (loss 0.171, data 19.381) 
Epoch 4 Iter 7200, train entropy gap -19.1917 bits (loss 0.189, data 19.381) 
epoch 4 train loss 0.1532 nats / 0.2210 bits
time since start: 450.4 secs
Epoch 5 Iter 0, train entropy gap -19.1549 bits (loss 0.226, data 19.381) 
Epoch 5 Iter 200, train entropy gap -19.2508 bits (loss 0.130, data 19.381) 
Epoch 5 Iter 400, train entropy gap -19.1982 bits (loss 0.183, data 19.381) 
Epoch 5 Iter 600, train entropy gap -19.1759 bits (loss 0.205, data 19.381) 
Epoch 5 Iter 800, train entropy gap -19.1466 bits (loss 0.234, data 19.381) 
Epoch 5 Iter 1000, train entropy gap -19.2327 bits (loss 0.148, data 19.381) 
Epoch 5 Iter 1200, train entropy gap -19.1872 bits (loss 0.194, data 19.381) 
Epoch 5 Iter 1400, train entropy gap -19.1551 bits (loss 0.226, data 19.381) 
Epoch 5 Iter 1600, train entropy gap -19.2389 bits (loss 0.142, data 19.381) 
Epoch 5 Iter 1800, train entropy gap -19.1913 bits (loss 0.190, data 19.381) 
Epoch 5 Iter 2000, train entropy gap -19.1844 bits (loss 0.196, data 19.381) 
Epoch 5 Iter 2200, train entropy gap -19.2317 bits (loss 0.149, data 19.381) 
Epoch 5 Iter 2400, train entropy gap -19.1852 bits (loss 0.196, data 19.381) 
Epoch 5 Iter 2600, train entropy gap -19.2099 bits (loss 0.171, data 19.381) 
Epoch 5 Iter 2800, train entropy gap -19.1659 bits (loss 0.215, data 19.381) 
Epoch 5 Iter 3000, train entropy gap -19.1749 bits (loss 0.206, data 19.381) 
Epoch 5 Iter 3200, train entropy gap -19.1576 bits (loss 0.223, data 19.381) 
Epoch 5 Iter 3400, train entropy gap -19.1187 bits (loss 0.262, data 19.381) 
Epoch 5 Iter 3600, train entropy gap -19.1468 bits (loss 0.234, data 19.381) 
Epoch 5 Iter 3800, train entropy gap -19.1776 bits (loss 0.203, data 19.381) 
Epoch 5 Iter 4000, train entropy gap -19.2179 bits (loss 0.163, data 19.381) 
Epoch 5 Iter 4200, train entropy gap -19.2016 bits (loss 0.179, data 19.381) 
Epoch 5 Iter 4400, train entropy gap -19.1450 bits (loss 0.236, data 19.381) 
Epoch 5 Iter 4600, train entropy gap -19.1710 bits (loss 0.210, data 19.381) 
Epoch 5 Iter 4800, train entropy gap -19.2040 bits (loss 0.177, data 19.381) 
Epoch 5 Iter 5000, train entropy gap -19.2002 bits (loss 0.181, data 19.381) 
Epoch 5 Iter 5200, train entropy gap -19.2116 bits (loss 0.169, data 19.381) 
Epoch 5 Iter 5400, train entropy gap -19.1453 bits (loss 0.236, data 19.381) 
Epoch 5 Iter 5600, train entropy gap -19.1974 bits (loss 0.183, data 19.381) 
Epoch 5 Iter 5800, train entropy gap -19.2152 bits (loss 0.166, data 19.381) 
Epoch 5 Iter 6000, train entropy gap -19.2319 bits (loss 0.149, data 19.381) 
Epoch 5 Iter 6200, train entropy gap -19.2012 bits (loss 0.180, data 19.381) 
Epoch 5 Iter 6400, train entropy gap -19.2102 bits (loss 0.171, data 19.381) 
Epoch 5 Iter 6600, train entropy gap -19.2165 bits (loss 0.164, data 19.381) 
Epoch 5 Iter 6800, train entropy gap -19.2170 bits (loss 0.164, data 19.381) 
Epoch 5 Iter 7000, train entropy gap -19.1933 bits (loss 0.187, data 19.381) 
Epoch 5 Iter 7200, train entropy gap -19.1702 bits (loss 0.211, data 19.381) 
epoch 5 train loss 0.1250 nats / 0.1804 bits
time since start: 540.1 secs
Epoch 6 Iter 0, train entropy gap -19.2520 bits (loss 0.129, data 19.381) 
Epoch 6 Iter 200, train entropy gap -19.1007 bits (loss 0.280, data 19.381) 
Epoch 6 Iter 400, train entropy gap -19.2466 bits (loss 0.134, data 19.381) 
Epoch 6 Iter 600, train entropy gap -19.1821 bits (loss 0.199, data 19.381) 
Epoch 6 Iter 800, train entropy gap -19.1848 bits (loss 0.196, data 19.381) 
Epoch 6 Iter 1000, train entropy gap -19.2105 bits (loss 0.170, data 19.381) 
Epoch 6 Iter 1200, train entropy gap -19.2360 bits (loss 0.145, data 19.381) 
Epoch 6 Iter 1400, train entropy gap -19.1767 bits (loss 0.204, data 19.381) 
Epoch 6 Iter 1600, train entropy gap -19.2239 bits (loss 0.157, data 19.381) 
Epoch 6 Iter 1800, train entropy gap -19.1668 bits (loss 0.214, data 19.381) 
Epoch 6 Iter 2000, train entropy gap -19.2139 bits (loss 0.167, data 19.381) 
Epoch 6 Iter 2200, train entropy gap -19.2189 bits (loss 0.162, data 19.381) 
Epoch 6 Iter 2400, train entropy gap -19.1891 bits (loss 0.192, data 19.381) 
Epoch 6 Iter 2600, train entropy gap -19.1394 bits (loss 0.241, data 19.381) 
Epoch 6 Iter 2800, train entropy gap -19.2420 bits (loss 0.139, data 19.381) 
Epoch 6 Iter 3000, train entropy gap -19.1794 bits (loss 0.201, data 19.381) 
Epoch 6 Iter 3200, train entropy gap -19.2664 bits (loss 0.114, data 19.381) 
Epoch 6 Iter 3400, train entropy gap -19.2419 bits (loss 0.139, data 19.381) 
Epoch 6 Iter 3600, train entropy gap -19.2102 bits (loss 0.171, data 19.381) 
Epoch 6 Iter 3800, train entropy gap -19.2468 bits (loss 0.134, data 19.381) 
Epoch 6 Iter 4000, train entropy gap -19.2600 bits (loss 0.121, data 19.381) 
Epoch 6 Iter 4200, train entropy gap -19.2378 bits (loss 0.143, data 19.381) 
Epoch 6 Iter 4400, train entropy gap -19.2174 bits (loss 0.163, data 19.381) 
Epoch 6 Iter 4600, train entropy gap -19.2635 bits (loss 0.117, data 19.381) 
Epoch 6 Iter 4800, train entropy gap -19.2205 bits (loss 0.160, data 19.381) 
Epoch 6 Iter 5000, train entropy gap -19.1972 bits (loss 0.184, data 19.381) 
Epoch 6 Iter 5200, train entropy gap -19.2400 bits (loss 0.141, data 19.381) 
Epoch 6 Iter 5400, train entropy gap -19.2148 bits (loss 0.166, data 19.381) 
Epoch 6 Iter 5600, train entropy gap -19.1898 bits (loss 0.191, data 19.381) 
Epoch 6 Iter 5800, train entropy gap -19.2266 bits (loss 0.154, data 19.381) 
Epoch 6 Iter 6000, train entropy gap -19.2334 bits (loss 0.147, data 19.381) 
Epoch 6 Iter 6200, train entropy gap -19.2564 bits (loss 0.124, data 19.381) 
Epoch 6 Iter 6400, train entropy gap -19.2170 bits (loss 0.164, data 19.381) 
Epoch 6 Iter 6600, train entropy gap -19.2235 bits (loss 0.157, data 19.381) 
Epoch 6 Iter 6800, train entropy gap -19.2527 bits (loss 0.128, data 19.381) 
Epoch 6 Iter 7000, train entropy gap -19.2065 bits (loss 0.174, data 19.381) 
Epoch 6 Iter 7200, train entropy gap -19.2373 bits (loss 0.144, data 19.381) 
epoch 6 train loss 0.1099 nats / 0.1586 bits
time since start: 629.3 secs
Epoch 7 Iter 0, train entropy gap -19.1841 bits (loss 0.197, data 19.381) 
Epoch 7 Iter 200, train entropy gap -19.2915 bits (loss 0.089, data 19.381) 
Epoch 7 Iter 400, train entropy gap -19.2003 bits (loss 0.180, data 19.381) 
Epoch 7 Iter 600, train entropy gap -19.2715 bits (loss 0.109, data 19.381) 
Epoch 7 Iter 800, train entropy gap -19.2910 bits (loss 0.090, data 19.381) 
Epoch 7 Iter 1000, train entropy gap -19.2420 bits (loss 0.139, data 19.381) 
Epoch 7 Iter 1200, train entropy gap -19.2557 bits (loss 0.125, data 19.381) 
Epoch 7 Iter 1400, train entropy gap -19.2731 bits (loss 0.108, data 19.381) 
Epoch 7 Iter 1600, train entropy gap -19.2832 bits (loss 0.098, data 19.381) 
Epoch 7 Iter 1800, train entropy gap -19.2576 bits (loss 0.123, data 19.381) 
Epoch 7 Iter 2000, train entropy gap -19.2609 bits (loss 0.120, data 19.381) 
Epoch 7 Iter 2200, train entropy gap -19.2322 bits (loss 0.149, data 19.381) 
Epoch 7 Iter 2400, train entropy gap -19.2424 bits (loss 0.138, data 19.381) 
Epoch 7 Iter 2600, train entropy gap -19.2704 bits (loss 0.110, data 19.381) 
Epoch 7 Iter 2800, train entropy gap -19.2228 bits (loss 0.158, data 19.381) 
Epoch 7 Iter 3000, train entropy gap -19.2393 bits (loss 0.142, data 19.381) 
Epoch 7 Iter 3200, train entropy gap -19.2463 bits (loss 0.135, data 19.381) 
Epoch 7 Iter 3400, train entropy gap -19.2407 bits (loss 0.140, data 19.381) 
Epoch 7 Iter 3600, train entropy gap -19.2487 bits (loss 0.132, data 19.381) 
Epoch 7 Iter 3800, train entropy gap -19.2384 bits (loss 0.142, data 19.381) 
Epoch 7 Iter 4000, train entropy gap -19.2790 bits (loss 0.102, data 19.381) 
Epoch 7 Iter 4200, train entropy gap -19.2407 bits (loss 0.140, data 19.381) 
Epoch 7 Iter 4400, train entropy gap -19.2068 bits (loss 0.174, data 19.381) 
Epoch 7 Iter 4600, train entropy gap -19.2430 bits (loss 0.138, data 19.381) 
Epoch 7 Iter 4800, train entropy gap -19.2347 bits (loss 0.146, data 19.381) 
Epoch 7 Iter 5000, train entropy gap -19.2416 bits (loss 0.139, data 19.381) 
Epoch 7 Iter 5200, train entropy gap -19.2887 bits (loss 0.092, data 19.381) 
Epoch 7 Iter 5400, train entropy gap -19.2392 bits (loss 0.142, data 19.381) 
Epoch 7 Iter 5600, train entropy gap -19.2414 bits (loss 0.139, data 19.381) 
Epoch 7 Iter 5800, train entropy gap -19.2202 bits (loss 0.161, data 19.381) 
Epoch 7 Iter 6000, train entropy gap -19.1863 bits (loss 0.194, data 19.381) 
Epoch 7 Iter 6200, train entropy gap -19.2820 bits (loss 0.099, data 19.381) 
Epoch 7 Iter 6400, train entropy gap -19.2262 bits (loss 0.155, data 19.381) 
Epoch 7 Iter 6600, train entropy gap -19.2431 bits (loss 0.138, data 19.381) 
Epoch 7 Iter 6800, train entropy gap -19.2168 bits (loss 0.164, data 19.381) 
Epoch 7 Iter 7000, train entropy gap -19.2451 bits (loss 0.136, data 19.381) 
Epoch 7 Iter 7200, train entropy gap -19.2051 bits (loss 0.176, data 19.381) 
epoch 7 train loss 0.0989 nats / 0.1426 bits
time since start: 720.3 secs
Epoch 8 Iter 0, train entropy gap -19.2790 bits (loss 0.102, data 19.381) 
Epoch 8 Iter 200, train entropy gap -19.2581 bits (loss 0.123, data 19.381) 
Epoch 8 Iter 400, train entropy gap -19.2682 bits (loss 0.113, data 19.381) 
Epoch 8 Iter 600, train entropy gap -19.3017 bits (loss 0.079, data 19.381) 
Epoch 8 Iter 800, train entropy gap -19.2636 bits (loss 0.117, data 19.381) 
Epoch 8 Iter 1000, train entropy gap -19.2396 bits (loss 0.141, data 19.381) 
Epoch 8 Iter 1200, train entropy gap -19.2107 bits (loss 0.170, data 19.381) 
Epoch 8 Iter 1400, train entropy gap -19.1871 bits (loss 0.194, data 19.381) 
Epoch 8 Iter 1600, train entropy gap -19.2592 bits (loss 0.122, data 19.381) 
Epoch 8 Iter 1800, train entropy gap -19.2746 bits (loss 0.106, data 19.381) 
Epoch 8 Iter 2000, train entropy gap -19.2569 bits (loss 0.124, data 19.381) 
Epoch 8 Iter 2200, train entropy gap -19.2795 bits (loss 0.101, data 19.381) 
Epoch 8 Iter 2400, train entropy gap -19.2219 bits (loss 0.159, data 19.381) 
Epoch 8 Iter 2600, train entropy gap -19.2085 bits (loss 0.172, data 19.381) 
Epoch 8 Iter 2800, train entropy gap -19.2429 bits (loss 0.138, data 19.381) 
Epoch 8 Iter 3000, train entropy gap -19.2845 bits (loss 0.096, data 19.381) 
Epoch 8 Iter 3200, train entropy gap -19.2499 bits (loss 0.131, data 19.381) 
Epoch 8 Iter 3400, train entropy gap -19.2472 bits (loss 0.134, data 19.381) 
Epoch 8 Iter 3600, train entropy gap -19.2647 bits (loss 0.116, data 19.381) 
Epoch 8 Iter 3800, train entropy gap -19.2029 bits (loss 0.178, data 19.381) 
Epoch 8 Iter 4000, train entropy gap -19.2508 bits (loss 0.130, data 19.381) 
Epoch 8 Iter 4200, train entropy gap -19.2853 bits (loss 0.096, data 19.381) 
Epoch 8 Iter 4400, train entropy gap -19.2999 bits (loss 0.081, data 19.381) 
Epoch 8 Iter 4600, train entropy gap -19.2627 bits (loss 0.118, data 19.381) 
Epoch 8 Iter 4800, train entropy gap -19.2945 bits (loss 0.086, data 19.381) 
Epoch 8 Iter 5000, train entropy gap -19.2615 bits (loss 0.119, data 19.381) 
Epoch 8 Iter 5200, train entropy gap -19.2755 bits (loss 0.105, data 19.381) 
Epoch 8 Iter 5400, train entropy gap -19.2167 bits (loss 0.164, data 19.381) 
Epoch 8 Iter 5600, train entropy gap -19.2560 bits (loss 0.125, data 19.381) 
Epoch 8 Iter 5800, train entropy gap -19.2568 bits (loss 0.124, data 19.381) 
Epoch 8 Iter 6000, train entropy gap -19.2669 bits (loss 0.114, data 19.381) 
Epoch 8 Iter 6200, train entropy gap -19.2790 bits (loss 0.102, data 19.381) 
Epoch 8 Iter 6400, train entropy gap -19.2495 bits (loss 0.131, data 19.381) 
Epoch 8 Iter 6600, train entropy gap -19.2779 bits (loss 0.103, data 19.381) 
Epoch 8 Iter 6800, train entropy gap -19.2210 bits (loss 0.160, data 19.381) 
Epoch 8 Iter 7000, train entropy gap -19.2571 bits (loss 0.124, data 19.381) 
Epoch 8 Iter 7200, train entropy gap -19.2349 bits (loss 0.146, data 19.381) 
epoch 8 train loss 0.0911 nats / 0.1315 bits
time since start: 810.2 secs
Epoch 9 Iter 0, train entropy gap -19.2706 bits (loss 0.110, data 19.381) 
Epoch 9 Iter 200, train entropy gap -19.2478 bits (loss 0.133, data 19.381) 
Epoch 9 Iter 400, train entropy gap -19.2793 bits (loss 0.102, data 19.381) 
Epoch 9 Iter 600, train entropy gap -19.2917 bits (loss 0.089, data 19.381) 
Epoch 9 Iter 800, train entropy gap -19.2526 bits (loss 0.128, data 19.381) 
Epoch 9 Iter 1000, train entropy gap -19.2653 bits (loss 0.116, data 19.381) 
Epoch 9 Iter 1200, train entropy gap -19.2669 bits (loss 0.114, data 19.381) 
Epoch 9 Iter 1400, train entropy gap -19.2286 bits (loss 0.152, data 19.381) 
Epoch 9 Iter 1600, train entropy gap -19.2585 bits (loss 0.122, data 19.381) 
Epoch 9 Iter 1800, train entropy gap -19.2630 bits (loss 0.118, data 19.381) 
Epoch 9 Iter 2000, train entropy gap -19.2514 bits (loss 0.129, data 19.381) 
Epoch 9 Iter 2200, train entropy gap -19.2560 bits (loss 0.125, data 19.381) 
Epoch 9 Iter 2400, train entropy gap -19.2719 bits (loss 0.109, data 19.381) 
Epoch 9 Iter 2600, train entropy gap -19.3096 bits (loss 0.071, data 19.381) 
Epoch 9 Iter 2800, train entropy gap -19.2819 bits (loss 0.099, data 19.381) 
Epoch 9 Iter 3000, train entropy gap -19.2609 bits (loss 0.120, data 19.381) 
Epoch 9 Iter 3200, train entropy gap -19.2807 bits (loss 0.100, data 19.381) 
Epoch 9 Iter 3400, train entropy gap -19.2473 bits (loss 0.134, data 19.381) 
Epoch 9 Iter 3600, train entropy gap -19.2759 bits (loss 0.105, data 19.381) 
Epoch 9 Iter 3800, train entropy gap -19.2370 bits (loss 0.144, data 19.381) 
Epoch 9 Iter 4000, train entropy gap -19.2140 bits (loss 0.167, data 19.381) 
Epoch 9 Iter 4200, train entropy gap -19.2538 bits (loss 0.127, data 19.381) 
Epoch 9 Iter 4400, train entropy gap -19.2673 bits (loss 0.113, data 19.381) 
Epoch 9 Iter 4600, train entropy gap -19.2550 bits (loss 0.126, data 19.381) 
Epoch 9 Iter 4800, train entropy gap -19.2145 bits (loss 0.166, data 19.381) 
Epoch 9 Iter 5000, train entropy gap -19.2515 bits (loss 0.129, data 19.381) 
Epoch 9 Iter 5200, train entropy gap -19.2651 bits (loss 0.116, data 19.381) 
Epoch 9 Iter 5400, train entropy gap -19.2696 bits (loss 0.111, data 19.381) 
Epoch 9 Iter 5600, train entropy gap -19.2847 bits (loss 0.096, data 19.381) 
Epoch 9 Iter 5800, train entropy gap -19.2415 bits (loss 0.139, data 19.381) 
Epoch 9 Iter 6000, train entropy gap -19.2500 bits (loss 0.131, data 19.381) 
Epoch 9 Iter 6200, train entropy gap -19.2350 bits (loss 0.146, data 19.381) 
Epoch 9 Iter 6400, train entropy gap -19.2276 bits (loss 0.153, data 19.381) 
Epoch 9 Iter 6600, train entropy gap -19.2711 bits (loss 0.110, data 19.381) 
Epoch 9 Iter 6800, train entropy gap -19.2525 bits (loss 0.128, data 19.381) 
Epoch 9 Iter 7000, train entropy gap -19.2933 bits (loss 0.088, data 19.381) 
Epoch 9 Iter 7200, train entropy gap -19.2935 bits (loss 0.087, data 19.381) 
epoch 9 train loss 0.0857 nats / 0.1236 bits
time since start: 900.5 secs
Epoch 10 Iter 0, train entropy gap -19.2445 bits (loss 0.136, data 19.381) 
Epoch 10 Iter 200, train entropy gap -19.2725 bits (loss 0.108, data 19.381) 
Epoch 10 Iter 400, train entropy gap -19.2516 bits (loss 0.129, data 19.381) 
Epoch 10 Iter 600, train entropy gap -19.2765 bits (loss 0.104, data 19.381) 
Epoch 10 Iter 800, train entropy gap -19.2515 bits (loss 0.129, data 19.381) 
Epoch 10 Iter 1000, train entropy gap -19.2391 bits (loss 0.142, data 19.381) 
Epoch 10 Iter 1200, train entropy gap -19.2754 bits (loss 0.105, data 19.381) 
Epoch 10 Iter 1400, train entropy gap -19.2850 bits (loss 0.096, data 19.381) 
Epoch 10 Iter 1600, train entropy gap -19.2725 bits (loss 0.108, data 19.381) 
Epoch 10 Iter 1800, train entropy gap -19.2815 bits (loss 0.099, data 19.381) 
Epoch 10 Iter 2000, train entropy gap -19.2870 bits (loss 0.094, data 19.381) 
Epoch 10 Iter 2200, train entropy gap -19.2288 bits (loss 0.152, data 19.381) 
Epoch 10 Iter 2400, train entropy gap -19.2494 bits (loss 0.131, data 19.381) 
Epoch 10 Iter 2600, train entropy gap -19.3386 bits (loss 0.042, data 19.381) 
Epoch 10 Iter 2800, train entropy gap -19.2567 bits (loss 0.124, data 19.381) 
Epoch 10 Iter 3000, train entropy gap -19.3041 bits (loss 0.077, data 19.381) 
Epoch 10 Iter 3200, train entropy gap -19.3395 bits (loss 0.041, data 19.381) 
Epoch 10 Iter 3400, train entropy gap -19.2494 bits (loss 0.131, data 19.381) 
Epoch 10 Iter 3600, train entropy gap -19.2631 bits (loss 0.118, data 19.381) 
Epoch 10 Iter 3800, train entropy gap -19.2544 bits (loss 0.126, data 19.381) 
Epoch 10 Iter 4000, train entropy gap -19.2319 bits (loss 0.149, data 19.381) 
Epoch 10 Iter 4200, train entropy gap -19.2829 bits (loss 0.098, data 19.381) 
Epoch 10 Iter 4400, train entropy gap -19.2737 bits (loss 0.107, data 19.381) 
Epoch 10 Iter 4600, train entropy gap -19.3130 bits (loss 0.068, data 19.381) 
Epoch 10 Iter 4800, train entropy gap -19.2575 bits (loss 0.123, data 19.381) 
Epoch 10 Iter 5000, train entropy gap -19.2221 bits (loss 0.159, data 19.381) 
Epoch 10 Iter 5200, train entropy gap -19.2305 bits (loss 0.150, data 19.381) 
Epoch 10 Iter 5400, train entropy gap -19.2176 bits (loss 0.163, data 19.381) 
Epoch 10 Iter 5600, train entropy gap -19.2670 bits (loss 0.114, data 19.381) 
Epoch 10 Iter 5800, train entropy gap -19.2626 bits (loss 0.118, data 19.381) 
Epoch 10 Iter 6000, train entropy gap -19.2612 bits (loss 0.120, data 19.381) 
Epoch 10 Iter 6200, train entropy gap -19.2659 bits (loss 0.115, data 19.381) 
Epoch 10 Iter 6400, train entropy gap -19.2526 bits (loss 0.128, data 19.381) 
Epoch 10 Iter 6600, train entropy gap -19.2781 bits (loss 0.103, data 19.381) 
Epoch 10 Iter 6800, train entropy gap -19.2958 bits (loss 0.085, data 19.381) 
Epoch 10 Iter 7000, train entropy gap -19.1960 bits (loss 0.185, data 19.381) 
Epoch 10 Iter 7200, train entropy gap -19.1974 bits (loss 0.183, data 19.381) 
epoch 10 train loss 0.0813 nats / 0.1173 bits
time since start: 990.8 secs
Epoch 11 Iter 0, train entropy gap -19.2536 bits (loss 0.127, data 19.381) 
Epoch 11 Iter 200, train entropy gap -19.2458 bits (loss 0.135, data 19.381) 
Epoch 11 Iter 400, train entropy gap -19.2596 bits (loss 0.121, data 19.381) 
Epoch 11 Iter 600, train entropy gap -19.2576 bits (loss 0.123, data 19.381) 
Epoch 11 Iter 800, train entropy gap -19.2326 bits (loss 0.148, data 19.381) 
Epoch 11 Iter 1000, train entropy gap -19.2672 bits (loss 0.114, data 19.381) 
Epoch 11 Iter 1200, train entropy gap -19.3094 bits (loss 0.071, data 19.381) 
Epoch 11 Iter 1400, train entropy gap -19.3128 bits (loss 0.068, data 19.381) 
Epoch 11 Iter 1600, train entropy gap -19.2869 bits (loss 0.094, data 19.381) 
Epoch 11 Iter 1800, train entropy gap -19.2452 bits (loss 0.136, data 19.381) 
Epoch 11 Iter 2000, train entropy gap -19.2594 bits (loss 0.121, data 19.381) 
Epoch 11 Iter 2200, train entropy gap -19.2592 bits (loss 0.122, data 19.381) 
Epoch 11 Iter 2400, train entropy gap -19.2969 bits (loss 0.084, data 19.381) 
Epoch 11 Iter 2600, train entropy gap -19.3045 bits (loss 0.076, data 19.381) 
Epoch 11 Iter 2800, train entropy gap -19.2905 bits (loss 0.090, data 19.381) 
Epoch 11 Iter 3000, train entropy gap -19.2883 bits (loss 0.092, data 19.381) 
Epoch 11 Iter 3200, train entropy gap -19.2836 bits (loss 0.097, data 19.381) 
Epoch 11 Iter 3400, train entropy gap -19.2610 bits (loss 0.120, data 19.381) 
Epoch 11 Iter 3600, train entropy gap -19.2428 bits (loss 0.138, data 19.381) 
Epoch 11 Iter 3800, train entropy gap -19.2695 bits (loss 0.111, data 19.381) 
Epoch 11 Iter 4000, train entropy gap -19.2958 bits (loss 0.085, data 19.381) 
Epoch 11 Iter 4200, train entropy gap -19.2685 bits (loss 0.112, data 19.381) 
Epoch 11 Iter 4400, train entropy gap -19.2760 bits (loss 0.105, data 19.381) 
Epoch 11 Iter 4600, train entropy gap -19.2629 bits (loss 0.118, data 19.381) 
Epoch 11 Iter 4800, train entropy gap -19.2726 bits (loss 0.108, data 19.381) 
Epoch 11 Iter 5000, train entropy gap -19.2634 bits (loss 0.117, data 19.381) 
Epoch 11 Iter 5200, train entropy gap -19.2349 bits (loss 0.146, data 19.381) 
Epoch 11 Iter 5400, train entropy gap -19.2941 bits (loss 0.087, data 19.381) 
Epoch 11 Iter 5600, train entropy gap -19.2963 bits (loss 0.085, data 19.381) 
Epoch 11 Iter 5800, train entropy gap -19.2232 bits (loss 0.158, data 19.381) 
Epoch 11 Iter 6000, train entropy gap -19.2543 bits (loss 0.127, data 19.381) 
Epoch 11 Iter 6200, train entropy gap -19.2726 bits (loss 0.108, data 19.381) 
Epoch 11 Iter 6400, train entropy gap -19.1950 bits (loss 0.186, data 19.381) 
Epoch 11 Iter 6600, train entropy gap -19.3113 bits (loss 0.070, data 19.381) 
Epoch 11 Iter 6800, train entropy gap -19.2960 bits (loss 0.085, data 19.381) 
Epoch 11 Iter 7000, train entropy gap -19.3238 bits (loss 0.057, data 19.381) 
Epoch 11 Iter 7200, train entropy gap -19.2405 bits (loss 0.140, data 19.381) 
epoch 11 train loss 0.0778 nats / 0.1122 bits
time since start: 1080.6 secs
Epoch 12 Iter 0, train entropy gap -19.2431 bits (loss 0.138, data 19.381) 
Epoch 12 Iter 200, train entropy gap -19.2760 bits (loss 0.105, data 19.381) 
Epoch 12 Iter 400, train entropy gap -19.3087 bits (loss 0.072, data 19.381) 
Epoch 12 Iter 600, train entropy gap -19.2656 bits (loss 0.115, data 19.381) 
Epoch 12 Iter 800, train entropy gap -19.2543 bits (loss 0.126, data 19.381) 
Epoch 12 Iter 1000, train entropy gap -19.3175 bits (loss 0.063, data 19.381) 
Epoch 12 Iter 1200, train entropy gap -19.2945 bits (loss 0.086, data 19.381) 
Epoch 12 Iter 1400, train entropy gap -19.2607 bits (loss 0.120, data 19.381) 
Epoch 12 Iter 1600, train entropy gap -19.2990 bits (loss 0.082, data 19.381) 
Epoch 12 Iter 1800, train entropy gap -19.2854 bits (loss 0.095, data 19.381) 
Epoch 12 Iter 2000, train entropy gap -19.2717 bits (loss 0.109, data 19.381) 
Epoch 12 Iter 2200, train entropy gap -19.3137 bits (loss 0.067, data 19.381) 
Epoch 12 Iter 2400, train entropy gap -19.2919 bits (loss 0.089, data 19.381) 
Epoch 12 Iter 2600, train entropy gap -19.2633 bits (loss 0.117, data 19.381) 
Epoch 12 Iter 2800, train entropy gap -19.2669 bits (loss 0.114, data 19.381) 
Epoch 12 Iter 3000, train entropy gap -19.2555 bits (loss 0.125, data 19.381) 
Epoch 12 Iter 3200, train entropy gap -19.2453 bits (loss 0.136, data 19.381) 
Epoch 12 Iter 3400, train entropy gap -19.2726 bits (loss 0.108, data 19.381) 
Epoch 12 Iter 3600, train entropy gap -19.2585 bits (loss 0.122, data 19.381) 
Epoch 12 Iter 3800, train entropy gap -19.2731 bits (loss 0.108, data 19.381) 
Epoch 12 Iter 4000, train entropy gap -19.3207 bits (loss 0.060, data 19.381) 
Epoch 12 Iter 4200, train entropy gap -19.3105 bits (loss 0.070, data 19.381) 
Epoch 12 Iter 4400, train entropy gap -19.2720 bits (loss 0.109, data 19.381) 
Epoch 12 Iter 4600, train entropy gap -19.2947 bits (loss 0.086, data 19.381) 
Epoch 12 Iter 4800, train entropy gap -19.2645 bits (loss 0.116, data 19.381) 
Epoch 12 Iter 5000, train entropy gap -19.2469 bits (loss 0.134, data 19.381) 
Epoch 12 Iter 5200, train entropy gap -19.1786 bits (loss 0.202, data 19.381) 
Epoch 12 Iter 5400, train entropy gap -19.2613 bits (loss 0.119, data 19.381) 
Epoch 12 Iter 5600, train entropy gap -19.2345 bits (loss 0.146, data 19.381) 
Epoch 12 Iter 5800, train entropy gap -19.2332 bits (loss 0.148, data 19.381) 
Epoch 12 Iter 6000, train entropy gap -19.2455 bits (loss 0.135, data 19.381) 
Epoch 12 Iter 6200, train entropy gap -19.3099 bits (loss 0.071, data 19.381) 
Epoch 12 Iter 6400, train entropy gap -19.2631 bits (loss 0.118, data 19.381) 
Epoch 12 Iter 6600, train entropy gap -19.2489 bits (loss 0.132, data 19.381) 
Epoch 12 Iter 6800, train entropy gap -19.2763 bits (loss 0.105, data 19.381) 
Epoch 12 Iter 7000, train entropy gap -19.2728 bits (loss 0.108, data 19.381) 
Epoch 12 Iter 7200, train entropy gap -19.2801 bits (loss 0.101, data 19.381) 
epoch 12 train loss 0.0746 nats / 0.1077 bits
time since start: 1170.0 secs
Epoch 13 Iter 0, train entropy gap -19.2958 bits (loss 0.085, data 19.381) 
Epoch 13 Iter 200, train entropy gap -19.2941 bits (loss 0.087, data 19.381) 
Epoch 13 Iter 400, train entropy gap -19.3335 bits (loss 0.047, data 19.381) 
Epoch 13 Iter 600, train entropy gap -19.2582 bits (loss 0.123, data 19.381) 
Epoch 13 Iter 800, train entropy gap -19.2870 bits (loss 0.094, data 19.381) 
Epoch 13 Iter 1000, train entropy gap -19.2785 bits (loss 0.102, data 19.381) 
Epoch 13 Iter 1200, train entropy gap -19.3037 bits (loss 0.077, data 19.381) 
Epoch 13 Iter 1400, train entropy gap -19.2741 bits (loss 0.107, data 19.381) 
Epoch 13 Iter 1600, train entropy gap -19.2671 bits (loss 0.114, data 19.381) 
Epoch 13 Iter 1800, train entropy gap -19.2770 bits (loss 0.104, data 19.381) 
Epoch 13 Iter 2000, train entropy gap -19.2625 bits (loss 0.118, data 19.381) 
Epoch 13 Iter 2200, train entropy gap -19.2298 bits (loss 0.151, data 19.381) 
Epoch 13 Iter 2400, train entropy gap -19.3077 bits (loss 0.073, data 19.381) 
Epoch 13 Iter 2600, train entropy gap -19.3027 bits (loss 0.078, data 19.381) 
Epoch 13 Iter 2800, train entropy gap -19.2899 bits (loss 0.091, data 19.381) 
Epoch 13 Iter 3000, train entropy gap -19.2625 bits (loss 0.118, data 19.381) 
Epoch 13 Iter 3200, train entropy gap -19.2587 bits (loss 0.122, data 19.381) 
Epoch 13 Iter 3400, train entropy gap -19.2888 bits (loss 0.092, data 19.381) 
Epoch 13 Iter 3600, train entropy gap -19.3263 bits (loss 0.054, data 19.381) 
Epoch 13 Iter 3800, train entropy gap -19.3194 bits (loss 0.061, data 19.381) 
Epoch 13 Iter 4000, train entropy gap -19.3080 bits (loss 0.073, data 19.381) 
Epoch 13 Iter 4200, train entropy gap -19.2546 bits (loss 0.126, data 19.381) 
Epoch 13 Iter 4400, train entropy gap -19.2847 bits (loss 0.096, data 19.381) 
Epoch 13 Iter 4600, train entropy gap -19.3465 bits (loss 0.034, data 19.381) 
Epoch 13 Iter 4800, train entropy gap -19.2962 bits (loss 0.085, data 19.381) 
Epoch 13 Iter 5000, train entropy gap -19.3169 bits (loss 0.064, data 19.381) 
Epoch 13 Iter 5200, train entropy gap -19.2951 bits (loss 0.086, data 19.381) 
Epoch 13 Iter 5400, train entropy gap -19.2584 bits (loss 0.122, data 19.381) 
Epoch 13 Iter 5600, train entropy gap -19.3293 bits (loss 0.052, data 19.381) 
Epoch 13 Iter 5800, train entropy gap -19.2660 bits (loss 0.115, data 19.381) 
Epoch 13 Iter 6000, train entropy gap -19.3133 bits (loss 0.067, data 19.381) 
Epoch 13 Iter 6200, train entropy gap -19.2775 bits (loss 0.103, data 19.381) 
Epoch 13 Iter 6400, train entropy gap -19.3098 bits (loss 0.071, data 19.381) 
Epoch 13 Iter 6600, train entropy gap -19.2834 bits (loss 0.097, data 19.381) 
Epoch 13 Iter 6800, train entropy gap -19.1945 bits (loss 0.186, data 19.381) 
Epoch 13 Iter 7000, train entropy gap -19.2805 bits (loss 0.100, data 19.381) 
Epoch 13 Iter 7200, train entropy gap -19.2585 bits (loss 0.122, data 19.381) 
epoch 13 train loss 0.0722 nats / 0.1042 bits
time since start: 1259.3 secs
Epoch 14 Iter 0, train entropy gap -19.2826 bits (loss 0.098, data 19.381) 
Epoch 14 Iter 200, train entropy gap -19.2460 bits (loss 0.135, data 19.381) 
Epoch 14 Iter 400, train entropy gap -19.2352 bits (loss 0.146, data 19.381) 
Epoch 14 Iter 600, train entropy gap -19.3009 bits (loss 0.080, data 19.381) 
Epoch 14 Iter 800, train entropy gap -19.3016 bits (loss 0.079, data 19.381) 
Epoch 14 Iter 1000, train entropy gap -19.2938 bits (loss 0.087, data 19.381) 
Epoch 14 Iter 1200, train entropy gap -19.3006 bits (loss 0.080, data 19.381) 
Epoch 14 Iter 1400, train entropy gap -19.3241 bits (loss 0.057, data 19.381) 
Epoch 14 Iter 1600, train entropy gap -19.2889 bits (loss 0.092, data 19.381) 
Epoch 14 Iter 1800, train entropy gap -19.2569 bits (loss 0.124, data 19.381) 
Epoch 14 Iter 2000, train entropy gap -19.2842 bits (loss 0.097, data 19.381) 
Epoch 14 Iter 2200, train entropy gap -19.3176 bits (loss 0.063, data 19.381) 
Epoch 14 Iter 2400, train entropy gap -19.2836 bits (loss 0.097, data 19.381) 
Epoch 14 Iter 2600, train entropy gap -19.2747 bits (loss 0.106, data 19.381) 
Epoch 14 Iter 2800, train entropy gap -19.2390 bits (loss 0.142, data 19.381) 
Epoch 14 Iter 3000, train entropy gap -19.2950 bits (loss 0.086, data 19.381) 
Epoch 14 Iter 3200, train entropy gap -19.2332 bits (loss 0.148, data 19.381) 
Epoch 14 Iter 3400, train entropy gap -19.2897 bits (loss 0.091, data 19.381) 
Epoch 14 Iter 3600, train entropy gap -19.3035 bits (loss 0.077, data 19.381) 
Epoch 14 Iter 3800, train entropy gap -19.2622 bits (loss 0.119, data 19.381) 
Epoch 14 Iter 4000, train entropy gap -19.3119 bits (loss 0.069, data 19.381) 
Epoch 14 Iter 4200, train entropy gap -19.2910 bits (loss 0.090, data 19.381) 
Epoch 14 Iter 4400, train entropy gap -19.2557 bits (loss 0.125, data 19.381) 
Epoch 14 Iter 4600, train entropy gap -19.2162 bits (loss 0.165, data 19.381) 
Epoch 14 Iter 4800, train entropy gap -19.2658 bits (loss 0.115, data 19.381) 
Epoch 14 Iter 5000, train entropy gap -19.2645 bits (loss 0.116, data 19.381) 
Epoch 14 Iter 5200, train entropy gap -19.3225 bits (loss 0.058, data 19.381) 
Epoch 14 Iter 5400, train entropy gap -19.2765 bits (loss 0.104, data 19.381) 
Epoch 14 Iter 5600, train entropy gap -19.2908 bits (loss 0.090, data 19.381) 
Epoch 14 Iter 5800, train entropy gap -19.2575 bits (loss 0.123, data 19.381) 
Epoch 14 Iter 6000, train entropy gap -19.2947 bits (loss 0.086, data 19.381) 
Epoch 14 Iter 6200, train entropy gap -19.2524 bits (loss 0.128, data 19.381) 
Epoch 14 Iter 6400, train entropy gap -19.3053 bits (loss 0.076, data 19.381) 
Epoch 14 Iter 6600, train entropy gap -19.3000 bits (loss 0.081, data 19.381) 
Epoch 14 Iter 6800, train entropy gap -19.2917 bits (loss 0.089, data 19.381) 
Epoch 14 Iter 7000, train entropy gap -19.2616 bits (loss 0.119, data 19.381) 
Epoch 14 Iter 7200, train entropy gap -19.2511 bits (loss 0.130, data 19.381) 
epoch 14 train loss 0.0705 nats / 0.1017 bits
time since start: 1349.5 secs
Epoch 15 Iter 0, train entropy gap -19.2422 bits (loss 0.139, data 19.381) 
Epoch 15 Iter 200, train entropy gap -19.2792 bits (loss 0.102, data 19.381) 
Epoch 15 Iter 400, train entropy gap -19.3118 bits (loss 0.069, data 19.381) 
Epoch 15 Iter 600, train entropy gap -19.3212 bits (loss 0.060, data 19.381) 
Epoch 15 Iter 800, train entropy gap -19.2765 bits (loss 0.104, data 19.381) 
Epoch 15 Iter 1000, train entropy gap -19.2987 bits (loss 0.082, data 19.381) 
Epoch 15 Iter 1200, train entropy gap -19.2573 bits (loss 0.123, data 19.381) 
Epoch 15 Iter 1400, train entropy gap -19.3139 bits (loss 0.067, data 19.381) 
Epoch 15 Iter 1600, train entropy gap -19.2820 bits (loss 0.099, data 19.381) 
Epoch 15 Iter 1800, train entropy gap -19.2696 bits (loss 0.111, data 19.381) 
Epoch 15 Iter 2000, train entropy gap -19.3223 bits (loss 0.058, data 19.381) 
Epoch 15 Iter 2200, train entropy gap -19.3020 bits (loss 0.079, data 19.381) 
Epoch 15 Iter 2400, train entropy gap -19.3124 bits (loss 0.068, data 19.381) 
Epoch 15 Iter 2600, train entropy gap -19.3318 bits (loss 0.049, data 19.381) 
Epoch 15 Iter 2800, train entropy gap -19.3318 bits (loss 0.049, data 19.381) 
Epoch 15 Iter 3000, train entropy gap -19.2920 bits (loss 0.089, data 19.381) 
Epoch 15 Iter 3200, train entropy gap -19.2951 bits (loss 0.086, data 19.381) 
Epoch 15 Iter 3400, train entropy gap -19.2795 bits (loss 0.101, data 19.381) 
Epoch 15 Iter 3600, train entropy gap -19.3106 bits (loss 0.070, data 19.381) 
Epoch 15 Iter 3800, train entropy gap -19.2501 bits (loss 0.131, data 19.381) 
Epoch 15 Iter 4000, train entropy gap -19.3039 bits (loss 0.077, data 19.381) 
Epoch 15 Iter 4200, train entropy gap -19.2823 bits (loss 0.099, data 19.381) 
Epoch 15 Iter 4400, train entropy gap -19.2814 bits (loss 0.099, data 19.381) 
Epoch 15 Iter 4600, train entropy gap -19.2364 bits (loss 0.144, data 19.381) 
Epoch 15 Iter 4800, train entropy gap -19.3061 bits (loss 0.075, data 19.381) 
Epoch 15 Iter 5000, train entropy gap -19.2572 bits (loss 0.124, data 19.381) 
Epoch 15 Iter 5200, train entropy gap -19.3214 bits (loss 0.059, data 19.381) 
Epoch 15 Iter 5400, train entropy gap -19.2891 bits (loss 0.092, data 19.381) 
Epoch 15 Iter 5600, train entropy gap -19.2751 bits (loss 0.106, data 19.381) 
Epoch 15 Iter 5800, train entropy gap -19.2624 bits (loss 0.118, data 19.381) 
Epoch 15 Iter 6000, train entropy gap -19.2442 bits (loss 0.137, data 19.381) 
Epoch 15 Iter 6200, train entropy gap -19.2597 bits (loss 0.121, data 19.381) 
Epoch 15 Iter 6400, train entropy gap -19.3252 bits (loss 0.056, data 19.381) 
Epoch 15 Iter 6600, train entropy gap -19.2280 bits (loss 0.153, data 19.381) 
Epoch 15 Iter 6800, train entropy gap -19.2910 bits (loss 0.090, data 19.381) 
Epoch 15 Iter 7000, train entropy gap -19.3073 bits (loss 0.074, data 19.381) 
Epoch 15 Iter 7200, train entropy gap -19.2828 bits (loss 0.098, data 19.381) 
epoch 15 train loss 0.0692 nats / 0.0998 bits
time since start: 1438.8 secs
Epoch 16 Iter 0, train entropy gap -19.2780 bits (loss 0.103, data 19.381) 
Epoch 16 Iter 200, train entropy gap -19.3235 bits (loss 0.057, data 19.381) 
Epoch 16 Iter 400, train entropy gap -19.2849 bits (loss 0.096, data 19.381) 
Epoch 16 Iter 600, train entropy gap -19.2850 bits (loss 0.096, data 19.381) 
Epoch 16 Iter 800, train entropy gap -19.2888 bits (loss 0.092, data 19.381) 
Epoch 16 Iter 1000, train entropy gap -19.3060 bits (loss 0.075, data 19.381) 
Epoch 16 Iter 1200, train entropy gap -19.2937 bits (loss 0.087, data 19.381) 
Epoch 16 Iter 1400, train entropy gap -19.2806 bits (loss 0.100, data 19.381) 
Epoch 16 Iter 1600, train entropy gap -19.3220 bits (loss 0.059, data 19.381) 
Epoch 16 Iter 1800, train entropy gap -19.2822 bits (loss 0.099, data 19.381) 
Epoch 16 Iter 2000, train entropy gap -19.3137 bits (loss 0.067, data 19.381) 
Epoch 16 Iter 2200, train entropy gap -19.3411 bits (loss 0.040, data 19.381) 
Epoch 16 Iter 2400, train entropy gap -19.2760 bits (loss 0.105, data 19.381) 
Epoch 16 Iter 2600, train entropy gap -19.2896 bits (loss 0.091, data 19.381) 
Epoch 16 Iter 2800, train entropy gap -19.3097 bits (loss 0.071, data 19.381) 
Epoch 16 Iter 3000, train entropy gap -19.2622 bits (loss 0.119, data 19.381) 
Epoch 16 Iter 3200, train entropy gap -19.2869 bits (loss 0.094, data 19.381) 
Epoch 16 Iter 3400, train entropy gap -19.3195 bits (loss 0.061, data 19.381) 
Epoch 16 Iter 3600, train entropy gap -19.2727 bits (loss 0.108, data 19.381) 
Epoch 16 Iter 3800, train entropy gap -19.2885 bits (loss 0.092, data 19.381) 
Epoch 16 Iter 4000, train entropy gap -19.2801 bits (loss 0.101, data 19.381) 
Epoch 16 Iter 4200, train entropy gap -19.2931 bits (loss 0.088, data 19.381) 
Epoch 16 Iter 4400, train entropy gap -19.2418 bits (loss 0.139, data 19.381) 
Epoch 16 Iter 4600, train entropy gap -19.2745 bits (loss 0.106, data 19.381) 
Epoch 16 Iter 4800, train entropy gap -19.3043 bits (loss 0.077, data 19.381) 
Epoch 16 Iter 5000, train entropy gap -19.2851 bits (loss 0.096, data 19.381) 
Epoch 16 Iter 5200, train entropy gap -19.2248 bits (loss 0.156, data 19.381) 
Epoch 16 Iter 5400, train entropy gap -19.3005 bits (loss 0.080, data 19.381) 
Epoch 16 Iter 5600, train entropy gap -19.2797 bits (loss 0.101, data 19.381) 
Epoch 16 Iter 5800, train entropy gap -19.2801 bits (loss 0.101, data 19.381) 
Epoch 16 Iter 6000, train entropy gap -19.2737 bits (loss 0.107, data 19.381) 
Epoch 16 Iter 6200, train entropy gap -19.3165 bits (loss 0.064, data 19.381) 
Epoch 16 Iter 6400, train entropy gap -19.2129 bits (loss 0.168, data 19.381) 
Epoch 16 Iter 6600, train entropy gap -19.2692 bits (loss 0.112, data 19.381) 
Epoch 16 Iter 6800, train entropy gap -19.2854 bits (loss 0.095, data 19.381) 
Epoch 16 Iter 7000, train entropy gap -19.2885 bits (loss 0.092, data 19.381) 
Epoch 16 Iter 7200, train entropy gap -19.2617 bits (loss 0.119, data 19.381) 
epoch 16 train loss 0.0684 nats / 0.0986 bits
time since start: 1528.7 secs
Epoch 17 Iter 0, train entropy gap -19.2929 bits (loss 0.088, data 19.381) 
Epoch 17 Iter 200, train entropy gap -19.2903 bits (loss 0.091, data 19.381) 
Epoch 17 Iter 400, train entropy gap -19.2600 bits (loss 0.121, data 19.381) 
Epoch 17 Iter 600, train entropy gap -19.2683 bits (loss 0.113, data 19.381) 
Epoch 17 Iter 800, train entropy gap -19.2451 bits (loss 0.136, data 19.381) 
Epoch 17 Iter 1000, train entropy gap -19.2811 bits (loss 0.100, data 19.381) 
Epoch 17 Iter 1200, train entropy gap -19.2692 bits (loss 0.112, data 19.381) 
Epoch 17 Iter 1400, train entropy gap -19.2976 bits (loss 0.083, data 19.381) 
Epoch 17 Iter 1600, train entropy gap -19.2926 bits (loss 0.088, data 19.381) 
Epoch 17 Iter 1800, train entropy gap -19.2979 bits (loss 0.083, data 19.381) 
Epoch 17 Iter 2000, train entropy gap -19.3302 bits (loss 0.051, data 19.381) 
Epoch 17 Iter 2200, train entropy gap -19.3131 bits (loss 0.068, data 19.381) 
Epoch 17 Iter 2400, train entropy gap -19.2941 bits (loss 0.087, data 19.381) 
Epoch 17 Iter 2600, train entropy gap -19.2816 bits (loss 0.099, data 19.381) 
Epoch 17 Iter 2800, train entropy gap -19.2991 bits (loss 0.082, data 19.381) 
Epoch 17 Iter 3000, train entropy gap -19.2509 bits (loss 0.130, data 19.381) 
Epoch 17 Iter 3200, train entropy gap -19.2809 bits (loss 0.100, data 19.381) 
Epoch 17 Iter 3400, train entropy gap -19.3510 bits (loss 0.030, data 19.381) 
Epoch 17 Iter 3600, train entropy gap -19.2856 bits (loss 0.095, data 19.381) 
Epoch 17 Iter 3800, train entropy gap -19.2620 bits (loss 0.119, data 19.381) 
Epoch 17 Iter 4000, train entropy gap -19.2713 bits (loss 0.110, data 19.381) 
Epoch 17 Iter 4200, train entropy gap -19.2786 bits (loss 0.102, data 19.381) 
Epoch 17 Iter 4400, train entropy gap -19.3090 bits (loss 0.072, data 19.381) 
Epoch 17 Iter 4600, train entropy gap -19.2976 bits (loss 0.083, data 19.381) 
Epoch 17 Iter 4800, train entropy gap -19.2541 bits (loss 0.127, data 19.381) 
Epoch 17 Iter 5000, train entropy gap -19.2173 bits (loss 0.164, data 19.381) 
Epoch 17 Iter 5200, train entropy gap -19.2827 bits (loss 0.098, data 19.381) 
Epoch 17 Iter 5400, train entropy gap -19.3143 bits (loss 0.067, data 19.381) 
Epoch 17 Iter 5600, train entropy gap -19.2122 bits (loss 0.169, data 19.381) 
Epoch 17 Iter 5800, train entropy gap -19.3069 bits (loss 0.074, data 19.381) 
Epoch 17 Iter 6000, train entropy gap -19.3164 bits (loss 0.064, data 19.381) 
Epoch 17 Iter 6200, train entropy gap -19.2821 bits (loss 0.099, data 19.381) 
Epoch 17 Iter 6400, train entropy gap -19.2871 bits (loss 0.094, data 19.381) 
Epoch 17 Iter 6600, train entropy gap -19.2933 bits (loss 0.088, data 19.381) 
Epoch 17 Iter 6800, train entropy gap -19.2651 bits (loss 0.116, data 19.381) 
Epoch 17 Iter 7000, train entropy gap -19.2720 bits (loss 0.109, data 19.381) 
Epoch 17 Iter 7200, train entropy gap -19.2792 bits (loss 0.102, data 19.381) 
epoch 17 train loss 0.0677 nats / 0.0977 bits
time since start: 1618.6 secs
Epoch 18 Iter 0, train entropy gap -19.2945 bits (loss 0.086, data 19.381) 
Epoch 18 Iter 200, train entropy gap -19.2980 bits (loss 0.083, data 19.381) 
Epoch 18 Iter 400, train entropy gap -19.3013 bits (loss 0.080, data 19.381) 
Epoch 18 Iter 600, train entropy gap -19.2514 bits (loss 0.129, data 19.381) 
Epoch 18 Iter 800, train entropy gap -19.2698 bits (loss 0.111, data 19.381) 
Epoch 18 Iter 1000, train entropy gap -19.2878 bits (loss 0.093, data 19.381) 
Epoch 18 Iter 1200, train entropy gap -19.2780 bits (loss 0.103, data 19.381) 
Epoch 18 Iter 1400, train entropy gap -19.3009 bits (loss 0.080, data 19.381) 
Epoch 18 Iter 1600, train entropy gap -19.3215 bits (loss 0.059, data 19.381) 
Epoch 18 Iter 1800, train entropy gap -19.3089 bits (loss 0.072, data 19.381) 
Epoch 18 Iter 2000, train entropy gap -19.2637 bits (loss 0.117, data 19.381) 
Epoch 18 Iter 2200, train entropy gap -19.2412 bits (loss 0.140, data 19.381) 
Epoch 18 Iter 2400, train entropy gap -19.2906 bits (loss 0.090, data 19.381) 
Epoch 18 Iter 2600, train entropy gap -19.2609 bits (loss 0.120, data 19.381) 
Epoch 18 Iter 2800, train entropy gap -19.2921 bits (loss 0.089, data 19.381) 
Epoch 18 Iter 3000, train entropy gap -19.2725 bits (loss 0.108, data 19.381) 
Epoch 18 Iter 3200, train entropy gap -19.3300 bits (loss 0.051, data 19.381) 
Epoch 18 Iter 3400, train entropy gap -19.2974 bits (loss 0.083, data 19.381) 
Epoch 18 Iter 3600, train entropy gap -19.2825 bits (loss 0.098, data 19.381) 
Epoch 18 Iter 3800, train entropy gap -19.2572 bits (loss 0.124, data 19.381) 
Epoch 18 Iter 4000, train entropy gap -19.2679 bits (loss 0.113, data 19.381) 
Epoch 18 Iter 4200, train entropy gap -19.2395 bits (loss 0.141, data 19.381) 
Epoch 18 Iter 4400, train entropy gap -19.2822 bits (loss 0.099, data 19.381) 
Epoch 18 Iter 4600, train entropy gap -19.2659 bits (loss 0.115, data 19.381) 
Epoch 18 Iter 4800, train entropy gap -19.2765 bits (loss 0.104, data 19.381) 
Epoch 18 Iter 5000, train entropy gap -19.3108 bits (loss 0.070, data 19.381) 
Epoch 18 Iter 5200, train entropy gap -19.2871 bits (loss 0.094, data 19.381) 
Epoch 18 Iter 5400, train entropy gap -19.2437 bits (loss 0.137, data 19.381) 
Epoch 18 Iter 5600, train entropy gap -19.3042 bits (loss 0.077, data 19.381) 
Epoch 18 Iter 5800, train entropy gap -19.2445 bits (loss 0.136, data 19.381) 
Epoch 18 Iter 6000, train entropy gap -19.2788 bits (loss 0.102, data 19.381) 
Epoch 18 Iter 6200, train entropy gap -19.3348 bits (loss 0.046, data 19.381) 
Epoch 18 Iter 6400, train entropy gap -19.2432 bits (loss 0.138, data 19.381) 
Epoch 18 Iter 6600, train entropy gap -19.3124 bits (loss 0.068, data 19.381) 
Epoch 18 Iter 6800, train entropy gap -19.2688 bits (loss 0.112, data 19.381) 
Epoch 18 Iter 7000, train entropy gap -19.3078 bits (loss 0.073, data 19.381) 
Epoch 18 Iter 7200, train entropy gap -19.3251 bits (loss 0.056, data 19.381) 
epoch 18 train loss 0.0674 nats / 0.0973 bits
time since start: 1708.7 secs
Epoch 19 Iter 0, train entropy gap -19.2634 bits (loss 0.117, data 19.381) 
Epoch 19 Iter 200, train entropy gap -19.2567 bits (loss 0.124, data 19.381) 
Epoch 19 Iter 400, train entropy gap -19.2685 bits (loss 0.112, data 19.381) 
Epoch 19 Iter 600, train entropy gap -19.2974 bits (loss 0.083, data 19.381) 
Epoch 19 Iter 800, train entropy gap -19.2572 bits (loss 0.124, data 19.381) 
Epoch 19 Iter 1000, train entropy gap -19.3250 bits (loss 0.056, data 19.381) 
Epoch 19 Iter 1200, train entropy gap -19.3006 bits (loss 0.080, data 19.381) 
Epoch 19 Iter 1400, train entropy gap -19.2331 bits (loss 0.148, data 19.381) 
Epoch 19 Iter 1600, train entropy gap -19.2408 bits (loss 0.140, data 19.381) 
Epoch 19 Iter 1800, train entropy gap -19.3131 bits (loss 0.068, data 19.381) 
Epoch 19 Iter 2000, train entropy gap -19.3371 bits (loss 0.044, data 19.381) 
Epoch 19 Iter 2200, train entropy gap -19.2964 bits (loss 0.084, data 19.381) 
Epoch 19 Iter 2400, train entropy gap -19.3000 bits (loss 0.081, data 19.381) 
Epoch 19 Iter 2600, train entropy gap -19.2752 bits (loss 0.106, data 19.381) 
Epoch 19 Iter 2800, train entropy gap -19.2958 bits (loss 0.085, data 19.381) 
Epoch 19 Iter 3000, train entropy gap -19.2848 bits (loss 0.096, data 19.381) 
Epoch 19 Iter 3200, train entropy gap -19.2603 bits (loss 0.121, data 19.381) 
Epoch 19 Iter 3400, train entropy gap -19.3246 bits (loss 0.056, data 19.381) 
Epoch 19 Iter 3600, train entropy gap -19.2621 bits (loss 0.119, data 19.381) 
Epoch 19 Iter 3800, train entropy gap -19.2946 bits (loss 0.086, data 19.381) 
Epoch 19 Iter 4000, train entropy gap -19.2916 bits (loss 0.089, data 19.381) 
Epoch 19 Iter 4200, train entropy gap -19.2646 bits (loss 0.116, data 19.381) 
Epoch 19 Iter 4400, train entropy gap -19.2897 bits (loss 0.091, data 19.381) 
Epoch 19 Iter 4600, train entropy gap -19.2630 bits (loss 0.118, data 19.381) 
Epoch 19 Iter 4800, train entropy gap -19.3253 bits (loss 0.056, data 19.381) 
Epoch 19 Iter 5000, train entropy gap -19.2789 bits (loss 0.102, data 19.381) 
Epoch 19 Iter 5200, train entropy gap -19.3057 bits (loss 0.075, data 19.381) 
Epoch 19 Iter 5400, train entropy gap -19.3065 bits (loss 0.074, data 19.381) 
Epoch 19 Iter 5600, train entropy gap -19.3244 bits (loss 0.056, data 19.381) 
Epoch 19 Iter 5800, train entropy gap -19.2776 bits (loss 0.103, data 19.381) 
Epoch 19 Iter 6000, train entropy gap -19.2953 bits (loss 0.086, data 19.381) 
Epoch 19 Iter 6200, train entropy gap -19.2746 bits (loss 0.106, data 19.381) 
Epoch 19 Iter 6400, train entropy gap -19.2268 bits (loss 0.154, data 19.381) 
Epoch 19 Iter 6600, train entropy gap -19.3189 bits (loss 0.062, data 19.381) 
Epoch 19 Iter 6800, train entropy gap -19.2344 bits (loss 0.146, data 19.381) 
Epoch 19 Iter 7000, train entropy gap -19.2357 bits (loss 0.145, data 19.381) 
Epoch 19 Iter 7200, train entropy gap -19.2491 bits (loss 0.132, data 19.381) 
epoch 19 train loss 0.0675 nats / 0.0974 bits
time since start: 1798.0 secs
Training done; evaluating likelihood on full data:
Epoch None Iter 0, test loss 0.3780 nats / 0.5453 bits
Epoch None Iter 500, test loss 0.0145 nats / 0.0210 bits
Epoch None Iter 1000, test loss 0.0116 nats / 0.0168 bits
Epoch None Iter 1500, test loss 0.0117 nats / 0.0169 bits
Epoch None Iter 2000, test loss 0.1826 nats / 0.2634 bits
Epoch None Iter 2500, test loss 0.0068 nats / 0.0098 bits
Epoch None Iter 3000, test loss 0.0203 nats / 0.0293 bits
Epoch None Iter 3500, test loss 0.0344 nats / 0.0497 bits
Epoch None Iter 4000, test loss 0.0017 nats / 0.0024 bits
Epoch None Iter 4500, test loss 0.5409 nats / 0.7803 bits
Epoch None Iter 5000, test loss 0.0272 nats / 0.0392 bits
Epoch None Iter 5500, test loss 0.0122 nats / 0.0175 bits
Epoch None Iter 6000, test loss 0.0019 nats / 0.0028 bits
Epoch None Iter 6500, test loss 0.0051 nats / 0.0074 bits
Epoch None Iter 7000, test loss 0.0768 nats / 0.1107 bits
Saved to:
models/dmv-1.6MB-model0.103-data19.381-transformer-blocks4-model64-ff256-heads4-use_flash_attnTrue-posEmb-gelu-20epochs-seed0.pt
