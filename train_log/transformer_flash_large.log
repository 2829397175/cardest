Device cuda
Loading csv... done, took 6.4s
Parsing... done, took 5.1s
Entropy of DMV([Column(Record Type, distribution_size=8), Column(Registration Class, distribution_size=72), Column(State, distribution_size=79), Column(County, distribution_size=64), Column(Body Type, distribution_size=59), Column(Fuel Type, distribution_size=10), Column(Reg Valid Date, distribution_size=2884), Column(Color, distribution_size=222), Column(Scofflaw Indicator, distribution_size=3), Column(Suspension Indicator, distribution_size=3), Column(Revocation Indicator, distribution_size=3)]): 19.3808 bits
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7389597 entries, 0 to 7389596
Data columns (total 11 columns):
 #   Column                Dtype         
---  ------                -----         
 0   Record Type           object        
 1   Registration Class    object        
 2   State                 object        
 3   County                object        
 4   Body Type             object        
 5   Fuel Type             object        
 6   Reg Valid Date        datetime64[ns]
 7   Color                 object        
 8   Scofflaw Indicator    object        
 9   Suspension Indicator  object        
 10  Revocation Indicator  object        
dtypes: datetime64[ns](1), object(10)
memory usage: 620.2+ MB
None
MASK_SCHEME 0
ordering [ 0  1  2  3  4  5  6  7  8  9 10]
using orig mask
 tensor([[ True, False, False, False, False, False, False, False, False, False,
         False],
        [ True,  True, False, False, False, False, False, False, False, False,
         False],
        [ True,  True,  True, False, False, False, False, False, False, False,
         False],
        [ True,  True,  True,  True, False, False, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True, False, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True]])
Number of model parameters: 2983936 (~= 11.4MB)
Transformer(
  (blocks): Sequential(
    (0): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=256, out_features=768, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (1): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=256, out_features=768, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (2): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=256, out_features=768, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (3): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=256, out_features=768, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (norm): LayerNorm()
  (embeddings): ModuleList(
    (0): Embedding(8, 256)
    (1): Embedding(72, 256)
    (2): Embedding(79, 256)
    (3): Embedding(64, 256)
    (4): Embedding(59, 256)
    (5): Embedding(10, 256)
    (6): Embedding(2884, 256)
    (7): Embedding(222, 256)
    (8): Embedding(3, 256)
    (9): Embedding(3, 256)
    (10): Embedding(3, 256)
  )
  (pos_embeddings): Embedding(11, 256)
)
Discretizing table... done, took 5.1s
Epoch 0 Iter 0, train entropy gap 36.7659 bits (loss 56.147, data 19.381) 
Epoch 0 Iter 200, train entropy gap 30.6607 bits (loss 50.042, data 19.381) 
Epoch 0 Iter 400, train entropy gap 17.2752 bits (loss 36.656, data 19.381) 
Epoch 0 Iter 600, train entropy gap 8.3137 bits (loss 27.694, data 19.381) 
Epoch 0 Iter 800, train entropy gap 1.3767 bits (loss 20.758, data 19.381) 
Epoch 0 Iter 1000, train entropy gap -3.1193 bits (loss 16.262, data 19.381) 
Epoch 0 Iter 1200, train entropy gap -6.6830 bits (loss 12.698, data 19.381) 
Epoch 0 Iter 1400, train entropy gap -9.3504 bits (loss 10.030, data 19.381) 
Epoch 0 Iter 1600, train entropy gap -11.3620 bits (loss 8.019, data 19.381) 
Epoch 0 Iter 1800, train entropy gap -13.5232 bits (loss 5.858, data 19.381) 
Epoch 0 Iter 2000, train entropy gap -15.1776 bits (loss 4.203, data 19.381) 
Epoch 0 Iter 2200, train entropy gap -16.6364 bits (loss 2.744, data 19.381) 
Epoch 0 Iter 2400, train entropy gap -17.6548 bits (loss 1.726, data 19.381) 
Epoch 0 Iter 2600, train entropy gap -18.3884 bits (loss 0.992, data 19.381) 
Epoch 0 Iter 2800, train entropy gap -18.7502 bits (loss 0.631, data 19.381) 
Epoch 0 Iter 3000, train entropy gap -18.9037 bits (loss 0.477, data 19.381) 
Epoch 0 Iter 3200, train entropy gap -19.0455 bits (loss 0.335, data 19.381) 
Epoch 0 Iter 3400, train entropy gap -19.1650 bits (loss 0.216, data 19.381) 
Epoch 0 Iter 3600, train entropy gap -19.1397 bits (loss 0.241, data 19.381) 
Epoch 0 Iter 3800, train entropy gap -19.1538 bits (loss 0.227, data 19.381) 
Epoch 0 Iter 4000, train entropy gap -19.2101 bits (loss 0.171, data 19.381) 
Epoch 0 Iter 4200, train entropy gap -19.2393 bits (loss 0.142, data 19.381) 
Epoch 0 Iter 4400, train entropy gap -19.2598 bits (loss 0.121, data 19.381) 
Epoch 0 Iter 4600, train entropy gap -19.2527 bits (loss 0.128, data 19.381) 
Epoch 0 Iter 4800, train entropy gap -19.3051 bits (loss 0.076, data 19.381) 
Epoch 0 Iter 5000, train entropy gap -19.2534 bits (loss 0.127, data 19.381) 
Epoch 0 Iter 5200, train entropy gap -19.2876 bits (loss 0.093, data 19.381) 
Epoch 0 Iter 5400, train entropy gap -19.2761 bits (loss 0.105, data 19.381) 
Epoch 0 Iter 5600, train entropy gap -19.3073 bits (loss 0.074, data 19.381) 
Epoch 0 Iter 5800, train entropy gap -19.2647 bits (loss 0.116, data 19.381) 
Epoch 0 Iter 6000, train entropy gap -19.3062 bits (loss 0.075, data 19.381) 
Epoch 0 Iter 6200, train entropy gap -19.2777 bits (loss 0.103, data 19.381) 
Epoch 0 Iter 6400, train entropy gap -19.3135 bits (loss 0.067, data 19.381) 
Epoch 0 Iter 6600, train entropy gap -19.3146 bits (loss 0.066, data 19.381) 
Epoch 0 Iter 6800, train entropy gap -19.3242 bits (loss 0.057, data 19.381) 
Epoch 0 Iter 7000, train entropy gap -19.3118 bits (loss 0.069, data 19.381) 
Epoch 0 Iter 7200, train entropy gap -19.3346 bits (loss 0.046, data 19.381) 
epoch 0 train loss 4.4165 nats / 6.3716 bits
time since start: 98.0 secs
Epoch 1 Iter 0, train entropy gap -19.3233 bits (loss 0.057, data 19.381) 
Epoch 1 Iter 200, train entropy gap -19.3280 bits (loss 0.053, data 19.381) 
Epoch 1 Iter 400, train entropy gap -19.3252 bits (loss 0.056, data 19.381) 
Epoch 1 Iter 600, train entropy gap -19.3384 bits (loss 0.042, data 19.381) 
Epoch 1 Iter 800, train entropy gap -19.3095 bits (loss 0.071, data 19.381) 
Epoch 1 Iter 1000, train entropy gap -19.3132 bits (loss 0.068, data 19.381) 
Epoch 1 Iter 1200, train entropy gap -19.3432 bits (loss 0.038, data 19.381) 
Epoch 1 Iter 1400, train entropy gap -19.3330 bits (loss 0.048, data 19.381) 
Epoch 1 Iter 1600, train entropy gap -19.3382 bits (loss 0.043, data 19.381) 
Epoch 1 Iter 1800, train entropy gap -19.3354 bits (loss 0.045, data 19.381) 
Epoch 1 Iter 2000, train entropy gap -19.3386 bits (loss 0.042, data 19.381) 
Epoch 1 Iter 2200, train entropy gap -19.3600 bits (loss 0.021, data 19.381) 
Epoch 1 Iter 2400, train entropy gap -19.3468 bits (loss 0.034, data 19.381) 
Epoch 1 Iter 2600, train entropy gap -19.3135 bits (loss 0.067, data 19.381) 
Epoch 1 Iter 2800, train entropy gap -19.3494 bits (loss 0.031, data 19.381) 
Epoch 1 Iter 3000, train entropy gap -19.3148 bits (loss 0.066, data 19.381) 
Epoch 1 Iter 3200, train entropy gap -19.3586 bits (loss 0.022, data 19.381) 
Epoch 1 Iter 3400, train entropy gap -19.3462 bits (loss 0.035, data 19.381) 
Epoch 1 Iter 3600, train entropy gap -19.3568 bits (loss 0.024, data 19.381) 
Epoch 1 Iter 3800, train entropy gap -19.3513 bits (loss 0.030, data 19.381) 
Epoch 1 Iter 4000, train entropy gap -19.3473 bits (loss 0.034, data 19.381) 
Epoch 1 Iter 4200, train entropy gap -19.3410 bits (loss 0.040, data 19.381) 
Epoch 1 Iter 4400, train entropy gap -19.3627 bits (loss 0.018, data 19.381) 
Epoch 1 Iter 4600, train entropy gap -19.3235 bits (loss 0.057, data 19.381) 
Epoch 1 Iter 4800, train entropy gap -19.3564 bits (loss 0.024, data 19.381) 
Epoch 1 Iter 5000, train entropy gap -19.3299 bits (loss 0.051, data 19.381) 
Epoch 1 Iter 5200, train entropy gap -19.3286 bits (loss 0.052, data 19.381) 
Epoch 1 Iter 5400, train entropy gap -19.3425 bits (loss 0.038, data 19.381) 
Epoch 1 Iter 5600, train entropy gap -19.3262 bits (loss 0.055, data 19.381) 
Epoch 1 Iter 5800, train entropy gap -19.3478 bits (loss 0.033, data 19.381) 
Epoch 1 Iter 6000, train entropy gap -19.3259 bits (loss 0.055, data 19.381) 
Epoch 1 Iter 6200, train entropy gap -19.3543 bits (loss 0.027, data 19.381) 
Epoch 1 Iter 6400, train entropy gap -19.3534 bits (loss 0.027, data 19.381) 
Epoch 1 Iter 6600, train entropy gap -19.3605 bits (loss 0.020, data 19.381) 
Epoch 1 Iter 6800, train entropy gap -19.3362 bits (loss 0.045, data 19.381) 
Epoch 1 Iter 7000, train entropy gap -19.3550 bits (loss 0.026, data 19.381) 
Epoch 1 Iter 7200, train entropy gap -19.3480 bits (loss 0.033, data 19.381) 
epoch 1 train loss 0.0300 nats / 0.0433 bits
time since start: 195.2 secs
Epoch 2 Iter 0, train entropy gap -19.3355 bits (loss 0.045, data 19.381) 
Epoch 2 Iter 200, train entropy gap -19.3505 bits (loss 0.030, data 19.381) 
Epoch 2 Iter 400, train entropy gap -19.3545 bits (loss 0.026, data 19.381) 
Epoch 2 Iter 600, train entropy gap -19.3535 bits (loss 0.027, data 19.381) 
Epoch 2 Iter 800, train entropy gap -19.3374 bits (loss 0.043, data 19.381) 
Epoch 2 Iter 1000, train entropy gap -19.3551 bits (loss 0.026, data 19.381) 
Epoch 2 Iter 1200, train entropy gap -19.3553 bits (loss 0.026, data 19.381) 
Epoch 2 Iter 1400, train entropy gap -19.3471 bits (loss 0.034, data 19.381) 
Epoch 2 Iter 1600, train entropy gap -19.3514 bits (loss 0.029, data 19.381) 
Epoch 2 Iter 1800, train entropy gap -19.3423 bits (loss 0.039, data 19.381) 
Epoch 2 Iter 2000, train entropy gap -19.3455 bits (loss 0.035, data 19.381) 
Epoch 2 Iter 2200, train entropy gap -19.3364 bits (loss 0.044, data 19.381) 
Epoch 2 Iter 2400, train entropy gap -19.3256 bits (loss 0.055, data 19.381) 
Epoch 2 Iter 2600, train entropy gap -19.3402 bits (loss 0.041, data 19.381) 
Epoch 2 Iter 2800, train entropy gap -19.3326 bits (loss 0.048, data 19.381) 
Epoch 2 Iter 3000, train entropy gap -19.3551 bits (loss 0.026, data 19.381) 
Epoch 2 Iter 3200, train entropy gap -19.3325 bits (loss 0.048, data 19.381) 
Epoch 2 Iter 3400, train entropy gap -19.3358 bits (loss 0.045, data 19.381) 
Epoch 2 Iter 3600, train entropy gap -19.3349 bits (loss 0.046, data 19.381) 
Epoch 2 Iter 3800, train entropy gap -19.3362 bits (loss 0.045, data 19.381) 
Epoch 2 Iter 4000, train entropy gap -19.3581 bits (loss 0.023, data 19.381) 
Epoch 2 Iter 4200, train entropy gap -19.3192 bits (loss 0.062, data 19.381) 
Epoch 2 Iter 4400, train entropy gap -19.3570 bits (loss 0.024, data 19.381) 
Epoch 2 Iter 4600, train entropy gap -19.3058 bits (loss 0.075, data 19.381) 
Epoch 2 Iter 4800, train entropy gap -19.3534 bits (loss 0.027, data 19.381) 
Epoch 2 Iter 5000, train entropy gap -19.3134 bits (loss 0.067, data 19.381) 
Epoch 2 Iter 5200, train entropy gap -19.2847 bits (loss 0.096, data 19.381) 
Epoch 2 Iter 5400, train entropy gap -19.3408 bits (loss 0.040, data 19.381) 
Epoch 2 Iter 5600, train entropy gap -19.3092 bits (loss 0.072, data 19.381) 
Epoch 2 Iter 5800, train entropy gap -19.3261 bits (loss 0.055, data 19.381) 
Epoch 2 Iter 6000, train entropy gap -19.3395 bits (loss 0.041, data 19.381) 
Epoch 2 Iter 6200, train entropy gap -19.3114 bits (loss 0.069, data 19.381) 
Epoch 2 Iter 6400, train entropy gap -19.3443 bits (loss 0.037, data 19.381) 
Epoch 2 Iter 6600, train entropy gap -19.3156 bits (loss 0.065, data 19.381) 
Epoch 2 Iter 6800, train entropy gap -19.3588 bits (loss 0.022, data 19.381) 
Epoch 2 Iter 7000, train entropy gap -19.3568 bits (loss 0.024, data 19.381) 
Epoch 2 Iter 7200, train entropy gap -19.3374 bits (loss 0.043, data 19.381) 
epoch 2 train loss 0.0312 nats / 0.0450 bits
time since start: 292.5 secs
Epoch 3 Iter 0, train entropy gap -19.3540 bits (loss 0.027, data 19.381) 
Epoch 3 Iter 200, train entropy gap -19.3538 bits (loss 0.027, data 19.381) 
Epoch 3 Iter 400, train entropy gap -19.3412 bits (loss 0.040, data 19.381) 
Epoch 3 Iter 600, train entropy gap -19.3433 bits (loss 0.037, data 19.381) 
Epoch 3 Iter 800, train entropy gap -19.3264 bits (loss 0.054, data 19.381) 
Epoch 3 Iter 1000, train entropy gap -19.3363 bits (loss 0.044, data 19.381) 
Epoch 3 Iter 1200, train entropy gap -19.3462 bits (loss 0.035, data 19.381) 
Epoch 3 Iter 1400, train entropy gap -19.3245 bits (loss 0.056, data 19.381) 
Epoch 3 Iter 1600, train entropy gap -19.3437 bits (loss 0.037, data 19.381) 
Epoch 3 Iter 1800, train entropy gap -19.3225 bits (loss 0.058, data 19.381) 
Epoch 3 Iter 2000, train entropy gap -19.3189 bits (loss 0.062, data 19.381) 
Epoch 3 Iter 2200, train entropy gap -19.3075 bits (loss 0.073, data 19.381) 
Epoch 3 Iter 2400, train entropy gap -19.3484 bits (loss 0.032, data 19.381) 
Epoch 3 Iter 2600, train entropy gap -19.3375 bits (loss 0.043, data 19.381) 
Epoch 3 Iter 2800, train entropy gap -19.3363 bits (loss 0.045, data 19.381) 
Epoch 3 Iter 3000, train entropy gap -19.3239 bits (loss 0.057, data 19.381) 
Epoch 3 Iter 3200, train entropy gap -19.3231 bits (loss 0.058, data 19.381) 
Epoch 3 Iter 3400, train entropy gap -19.3114 bits (loss 0.069, data 19.381) 
Epoch 3 Iter 3600, train entropy gap -19.3104 bits (loss 0.070, data 19.381) 
Epoch 3 Iter 3800, train entropy gap -19.3339 bits (loss 0.047, data 19.381) 
Epoch 3 Iter 4000, train entropy gap -19.3228 bits (loss 0.058, data 19.381) 
Epoch 3 Iter 4200, train entropy gap -19.3224 bits (loss 0.058, data 19.381) 
Epoch 3 Iter 4400, train entropy gap -19.3386 bits (loss 0.042, data 19.381) 
Epoch 3 Iter 4600, train entropy gap -19.3449 bits (loss 0.036, data 19.381) 
Epoch 3 Iter 4800, train entropy gap -19.3044 bits (loss 0.076, data 19.381) 
Epoch 3 Iter 5000, train entropy gap -19.2993 bits (loss 0.082, data 19.381) 
Epoch 3 Iter 5200, train entropy gap -19.3448 bits (loss 0.036, data 19.381) 
Epoch 3 Iter 5400, train entropy gap -19.3377 bits (loss 0.043, data 19.381) 
Epoch 3 Iter 5600, train entropy gap -19.3507 bits (loss 0.030, data 19.381) 
Epoch 3 Iter 5800, train entropy gap -19.3246 bits (loss 0.056, data 19.381) 
Epoch 3 Iter 6000, train entropy gap -19.3325 bits (loss 0.048, data 19.381) 
Epoch 3 Iter 6200, train entropy gap -19.3399 bits (loss 0.041, data 19.381) 
Epoch 3 Iter 6400, train entropy gap -19.3031 bits (loss 0.078, data 19.381) 
Epoch 3 Iter 6600, train entropy gap -19.3285 bits (loss 0.052, data 19.381) 
Epoch 3 Iter 6800, train entropy gap -19.3335 bits (loss 0.047, data 19.381) 
Epoch 3 Iter 7000, train entropy gap -19.3377 bits (loss 0.043, data 19.381) 
Epoch 3 Iter 7200, train entropy gap -19.3129 bits (loss 0.068, data 19.381) 
epoch 3 train loss 0.0334 nats / 0.0482 bits
time since start: 389.9 secs
Epoch 4 Iter 0, train entropy gap -19.3101 bits (loss 0.071, data 19.381) 
Epoch 4 Iter 200, train entropy gap -19.3338 bits (loss 0.047, data 19.381) 
Epoch 4 Iter 400, train entropy gap -19.3328 bits (loss 0.048, data 19.381) 
Epoch 4 Iter 600, train entropy gap -19.3650 bits (loss 0.016, data 19.381) 
Epoch 4 Iter 800, train entropy gap -19.3310 bits (loss 0.050, data 19.381) 
Epoch 4 Iter 1000, train entropy gap -19.3019 bits (loss 0.079, data 19.381) 
Epoch 4 Iter 1200, train entropy gap -19.3198 bits (loss 0.061, data 19.381) 
Epoch 4 Iter 1400, train entropy gap -19.3445 bits (loss 0.036, data 19.381) 
Epoch 4 Iter 1600, train entropy gap -19.3245 bits (loss 0.056, data 19.381) 
Epoch 4 Iter 1800, train entropy gap -19.2904 bits (loss 0.090, data 19.381) 
Epoch 4 Iter 2000, train entropy gap -19.3610 bits (loss 0.020, data 19.381) 
Epoch 4 Iter 2200, train entropy gap -19.3375 bits (loss 0.043, data 19.381) 
Epoch 4 Iter 2400, train entropy gap -19.3194 bits (loss 0.061, data 19.381) 
Epoch 4 Iter 2600, train entropy gap -19.3481 bits (loss 0.033, data 19.381) 
Epoch 4 Iter 2800, train entropy gap -19.3077 bits (loss 0.073, data 19.381) 
Epoch 4 Iter 3000, train entropy gap -19.3151 bits (loss 0.066, data 19.381) 
Epoch 4 Iter 3200, train entropy gap -19.3504 bits (loss 0.030, data 19.381) 
Epoch 4 Iter 3400, train entropy gap -19.3109 bits (loss 0.070, data 19.381) 
Epoch 4 Iter 3600, train entropy gap -19.3444 bits (loss 0.036, data 19.381) 
Epoch 4 Iter 3800, train entropy gap -19.3123 bits (loss 0.069, data 19.381) 
Epoch 4 Iter 4000, train entropy gap -19.3393 bits (loss 0.042, data 19.381) 
Epoch 4 Iter 4200, train entropy gap -19.3538 bits (loss 0.027, data 19.381) 
Epoch 4 Iter 4400, train entropy gap -19.3313 bits (loss 0.050, data 19.381) 
Epoch 4 Iter 4600, train entropy gap -19.3453 bits (loss 0.036, data 19.381) 
Epoch 4 Iter 4800, train entropy gap -19.3223 bits (loss 0.058, data 19.381) 
Epoch 4 Iter 5000, train entropy gap -19.3184 bits (loss 0.062, data 19.381) 
Epoch 4 Iter 5200, train entropy gap -19.3110 bits (loss 0.070, data 19.381) 
Epoch 4 Iter 5400, train entropy gap -19.3554 bits (loss 0.025, data 19.381) 
Epoch 4 Iter 5600, train entropy gap -19.3266 bits (loss 0.054, data 19.381) 
Epoch 4 Iter 5800, train entropy gap -19.2971 bits (loss 0.084, data 19.381) 
Epoch 4 Iter 6000, train entropy gap -19.3584 bits (loss 0.022, data 19.381) 
Epoch 4 Iter 6200, train entropy gap -19.3401 bits (loss 0.041, data 19.381) 
Epoch 4 Iter 6400, train entropy gap -19.3105 bits (loss 0.070, data 19.381) 
Epoch 4 Iter 6600, train entropy gap -19.3065 bits (loss 0.074, data 19.381) 
Epoch 4 Iter 6800, train entropy gap -19.3263 bits (loss 0.055, data 19.381) 
Epoch 4 Iter 7000, train entropy gap -19.3417 bits (loss 0.039, data 19.381) 
Epoch 4 Iter 7200, train entropy gap -19.2825 bits (loss 0.098, data 19.381) 
epoch 4 train loss 0.0338 nats / 0.0488 bits
time since start: 487.3 secs
Epoch 5 Iter 0, train entropy gap -19.3410 bits (loss 0.040, data 19.381) 
Epoch 5 Iter 200, train entropy gap -19.3215 bits (loss 0.059, data 19.381) 
Epoch 5 Iter 400, train entropy gap -19.3553 bits (loss 0.026, data 19.381) 
Epoch 5 Iter 600, train entropy gap -19.2984 bits (loss 0.082, data 19.381) 
Epoch 5 Iter 800, train entropy gap -19.3243 bits (loss 0.057, data 19.381) 
Epoch 5 Iter 1000, train entropy gap -19.2983 bits (loss 0.083, data 19.381) 
Epoch 5 Iter 1200, train entropy gap -19.3160 bits (loss 0.065, data 19.381) 
Epoch 5 Iter 1400, train entropy gap -19.3547 bits (loss 0.026, data 19.381) 
Epoch 5 Iter 1600, train entropy gap -19.3597 bits (loss 0.021, data 19.381) 
Epoch 5 Iter 1800, train entropy gap -19.3171 bits (loss 0.064, data 19.381) 
Epoch 5 Iter 2000, train entropy gap -19.3067 bits (loss 0.074, data 19.381) 
Epoch 5 Iter 2200, train entropy gap -19.3521 bits (loss 0.029, data 19.381) 
Epoch 5 Iter 2400, train entropy gap -19.3328 bits (loss 0.048, data 19.381) 
Epoch 5 Iter 2600, train entropy gap -19.3617 bits (loss 0.019, data 19.381) 
Epoch 5 Iter 2800, train entropy gap -19.3326 bits (loss 0.048, data 19.381) 
Epoch 5 Iter 3000, train entropy gap -19.3276 bits (loss 0.053, data 19.381) 
Epoch 5 Iter 3200, train entropy gap -19.3306 bits (loss 0.050, data 19.381) 
Epoch 5 Iter 3400, train entropy gap -19.3228 bits (loss 0.058, data 19.381) 
Epoch 5 Iter 3600, train entropy gap -19.3037 bits (loss 0.077, data 19.381) 
Epoch 5 Iter 3800, train entropy gap -19.3471 bits (loss 0.034, data 19.381) 
Epoch 5 Iter 4000, train entropy gap -19.3555 bits (loss 0.025, data 19.381) 
Epoch 5 Iter 4200, train entropy gap -19.3492 bits (loss 0.032, data 19.381) 
Epoch 5 Iter 4400, train entropy gap -19.3257 bits (loss 0.055, data 19.381) 
Epoch 5 Iter 4600, train entropy gap -19.3278 bits (loss 0.053, data 19.381) 
Epoch 5 Iter 4800, train entropy gap -19.3387 bits (loss 0.042, data 19.381) 
Epoch 5 Iter 5000, train entropy gap -19.3472 bits (loss 0.034, data 19.381) 
Epoch 5 Iter 5200, train entropy gap -19.2993 bits (loss 0.082, data 19.381) 
Epoch 5 Iter 5400, train entropy gap -19.3472 bits (loss 0.034, data 19.381) 
Epoch 5 Iter 5600, train entropy gap -19.3425 bits (loss 0.038, data 19.381) 
Epoch 5 Iter 5800, train entropy gap -19.3169 bits (loss 0.064, data 19.381) 
Epoch 5 Iter 6000, train entropy gap -19.3005 bits (loss 0.080, data 19.381) 
Epoch 5 Iter 6200, train entropy gap -19.3223 bits (loss 0.059, data 19.381) 
Epoch 5 Iter 6400, train entropy gap -19.2913 bits (loss 0.089, data 19.381) 
Epoch 5 Iter 6600, train entropy gap -19.3281 bits (loss 0.053, data 19.381) 
Epoch 5 Iter 6800, train entropy gap -19.3467 bits (loss 0.034, data 19.381) 
Epoch 5 Iter 7000, train entropy gap -19.3573 bits (loss 0.024, data 19.381) 
Epoch 5 Iter 7200, train entropy gap -19.3045 bits (loss 0.076, data 19.381) 
epoch 5 train loss 0.0342 nats / 0.0494 bits
time since start: 584.6 secs
Epoch 6 Iter 0, train entropy gap -19.3204 bits (loss 0.060, data 19.381) 
Epoch 6 Iter 200, train entropy gap -19.2993 bits (loss 0.082, data 19.381) 
Epoch 6 Iter 400, train entropy gap -19.3361 bits (loss 0.045, data 19.381) 
Epoch 6 Iter 600, train entropy gap -19.3135 bits (loss 0.067, data 19.381) 
Epoch 6 Iter 800, train entropy gap -19.3275 bits (loss 0.053, data 19.381) 
Epoch 6 Iter 1000, train entropy gap -19.3544 bits (loss 0.026, data 19.381) 
Epoch 6 Iter 1200, train entropy gap -19.2577 bits (loss 0.123, data 19.381) 
Epoch 6 Iter 1400, train entropy gap -19.3420 bits (loss 0.039, data 19.381) 
Epoch 6 Iter 1600, train entropy gap -19.3416 bits (loss 0.039, data 19.381) 
Epoch 6 Iter 1800, train entropy gap -19.2790 bits (loss 0.102, data 19.381) 
Epoch 6 Iter 2000, train entropy gap -19.3376 bits (loss 0.043, data 19.381) 
Epoch 6 Iter 2200, train entropy gap -19.3310 bits (loss 0.050, data 19.381) 
Epoch 6 Iter 2400, train entropy gap -19.3314 bits (loss 0.049, data 19.381) 
Epoch 6 Iter 2600, train entropy gap -19.3549 bits (loss 0.026, data 19.381) 
Epoch 6 Iter 2800, train entropy gap -19.3283 bits (loss 0.053, data 19.381) 
Epoch 6 Iter 3000, train entropy gap -19.3559 bits (loss 0.025, data 19.381) 
Epoch 6 Iter 3200, train entropy gap -19.3412 bits (loss 0.040, data 19.381) 
Epoch 6 Iter 3400, train entropy gap -19.2912 bits (loss 0.090, data 19.381) 
Epoch 6 Iter 3600, train entropy gap -19.3280 bits (loss 0.053, data 19.381) 
Epoch 6 Iter 3800, train entropy gap -19.3352 bits (loss 0.046, data 19.381) 
Epoch 6 Iter 4000, train entropy gap -19.3463 bits (loss 0.034, data 19.381) 
Epoch 6 Iter 4200, train entropy gap -19.3541 bits (loss 0.027, data 19.381) 
Epoch 6 Iter 4400, train entropy gap -19.3260 bits (loss 0.055, data 19.381) 
Epoch 6 Iter 4600, train entropy gap -19.3416 bits (loss 0.039, data 19.381) 
Epoch 6 Iter 4800, train entropy gap -19.3088 bits (loss 0.072, data 19.381) 
Epoch 6 Iter 5000, train entropy gap -19.3510 bits (loss 0.030, data 19.381) 
Epoch 6 Iter 5200, train entropy gap -19.3293 bits (loss 0.052, data 19.381) 
Epoch 6 Iter 5400, train entropy gap -19.3290 bits (loss 0.052, data 19.381) 
Epoch 6 Iter 5600, train entropy gap -19.3388 bits (loss 0.042, data 19.381) 
Epoch 6 Iter 5800, train entropy gap -19.3229 bits (loss 0.058, data 19.381) 
Epoch 6 Iter 6000, train entropy gap -19.3105 bits (loss 0.070, data 19.381) 
Epoch 6 Iter 6200, train entropy gap -19.3137 bits (loss 0.067, data 19.381) 
Epoch 6 Iter 6400, train entropy gap -19.3221 bits (loss 0.059, data 19.381) 
Epoch 6 Iter 6600, train entropy gap -19.3053 bits (loss 0.076, data 19.381) 
Epoch 6 Iter 6800, train entropy gap -19.3133 bits (loss 0.068, data 19.381) 
Epoch 6 Iter 7000, train entropy gap -19.3196 bits (loss 0.061, data 19.381) 
Epoch 6 Iter 7200, train entropy gap -19.3090 bits (loss 0.072, data 19.381) 
epoch 6 train loss 0.0348 nats / 0.0502 bits
time since start: 681.9 secs
Epoch 7 Iter 0, train entropy gap -19.3339 bits (loss 0.047, data 19.381) 
Epoch 7 Iter 200, train entropy gap -19.3251 bits (loss 0.056, data 19.381) 
Epoch 7 Iter 400, train entropy gap -19.3403 bits (loss 0.040, data 19.381) 
Epoch 7 Iter 600, train entropy gap -19.3267 bits (loss 0.054, data 19.381) 
Epoch 7 Iter 800, train entropy gap -19.3378 bits (loss 0.043, data 19.381) 
Epoch 7 Iter 1000, train entropy gap -19.3318 bits (loss 0.049, data 19.381) 
Epoch 7 Iter 1200, train entropy gap -19.3182 bits (loss 0.063, data 19.381) 
Epoch 7 Iter 1400, train entropy gap -19.3267 bits (loss 0.054, data 19.381) 
Epoch 7 Iter 1600, train entropy gap -19.3076 bits (loss 0.073, data 19.381) 
Epoch 7 Iter 1800, train entropy gap -19.3412 bits (loss 0.040, data 19.381) 
Epoch 7 Iter 2000, train entropy gap -19.3201 bits (loss 0.061, data 19.381) 
Epoch 7 Iter 2200, train entropy gap -19.3269 bits (loss 0.054, data 19.381) 
Epoch 7 Iter 2400, train entropy gap -19.3340 bits (loss 0.047, data 19.381) 
Epoch 7 Iter 2600, train entropy gap -19.3514 bits (loss 0.029, data 19.381) 
Epoch 7 Iter 2800, train entropy gap -19.3447 bits (loss 0.036, data 19.381) 
Epoch 7 Iter 3000, train entropy gap -19.3438 bits (loss 0.037, data 19.381) 
Epoch 7 Iter 3200, train entropy gap -19.3589 bits (loss 0.022, data 19.381) 
Epoch 7 Iter 3400, train entropy gap -19.3484 bits (loss 0.032, data 19.381) 
Epoch 7 Iter 3600, train entropy gap -19.3182 bits (loss 0.063, data 19.381) 
Epoch 7 Iter 3800, train entropy gap -19.2769 bits (loss 0.104, data 19.381) 
Epoch 7 Iter 4000, train entropy gap -19.3518 bits (loss 0.029, data 19.381) 
Epoch 7 Iter 4200, train entropy gap -19.3316 bits (loss 0.049, data 19.381) 
Epoch 7 Iter 4400, train entropy gap -19.3356 bits (loss 0.045, data 19.381) 
Epoch 7 Iter 4600, train entropy gap -19.3448 bits (loss 0.036, data 19.381) 
Epoch 7 Iter 4800, train entropy gap -19.2993 bits (loss 0.082, data 19.381) 
Epoch 7 Iter 5000, train entropy gap -19.2739 bits (loss 0.107, data 19.381) 
Epoch 7 Iter 5200, train entropy gap -19.3458 bits (loss 0.035, data 19.381) 
Epoch 7 Iter 5400, train entropy gap -19.3349 bits (loss 0.046, data 19.381) 
Epoch 7 Iter 5600, train entropy gap -19.3390 bits (loss 0.042, data 19.381) 
Epoch 7 Iter 5800, train entropy gap -19.3072 bits (loss 0.074, data 19.381) 
Epoch 7 Iter 6000, train entropy gap -19.3315 bits (loss 0.049, data 19.381) 
Epoch 7 Iter 6200, train entropy gap -19.3308 bits (loss 0.050, data 19.381) 
Epoch 7 Iter 6400, train entropy gap -19.3334 bits (loss 0.047, data 19.381) 
Epoch 7 Iter 6600, train entropy gap -19.3339 bits (loss 0.047, data 19.381) 
Epoch 7 Iter 6800, train entropy gap -19.3445 bits (loss 0.036, data 19.381) 
Epoch 7 Iter 7000, train entropy gap -19.3061 bits (loss 0.075, data 19.381) 
Epoch 7 Iter 7200, train entropy gap -19.3445 bits (loss 0.036, data 19.381) 
epoch 7 train loss 0.0353 nats / 0.0510 bits
time since start: 779.2 secs
Epoch 8 Iter 0, train entropy gap -19.2903 bits (loss 0.091, data 19.381) 
Epoch 8 Iter 200, train entropy gap -19.3464 bits (loss 0.034, data 19.381) 
Epoch 8 Iter 400, train entropy gap -19.3595 bits (loss 0.021, data 19.381) 
Epoch 8 Iter 600, train entropy gap -19.3355 bits (loss 0.045, data 19.381) 
Epoch 8 Iter 800, train entropy gap -19.3232 bits (loss 0.058, data 19.381) 
Epoch 8 Iter 1000, train entropy gap -19.3405 bits (loss 0.040, data 19.381) 
Epoch 8 Iter 1200, train entropy gap -19.3440 bits (loss 0.037, data 19.381) 
Epoch 8 Iter 1400, train entropy gap -19.3302 bits (loss 0.051, data 19.381) 
Epoch 8 Iter 1600, train entropy gap -19.3361 bits (loss 0.045, data 19.381) 
Epoch 8 Iter 1800, train entropy gap -19.3194 bits (loss 0.061, data 19.381) 
Epoch 8 Iter 2000, train entropy gap -19.3220 bits (loss 0.059, data 19.381) 
Epoch 8 Iter 2200, train entropy gap -19.3048 bits (loss 0.076, data 19.381) 
Epoch 8 Iter 2400, train entropy gap -19.3287 bits (loss 0.052, data 19.381) 
Epoch 8 Iter 2600, train entropy gap -19.3402 bits (loss 0.041, data 19.381) 
Epoch 8 Iter 2800, train entropy gap -19.3607 bits (loss 0.020, data 19.381) 
Epoch 8 Iter 3000, train entropy gap -19.3346 bits (loss 0.046, data 19.381) 
Epoch 8 Iter 3200, train entropy gap -19.3501 bits (loss 0.031, data 19.381) 
Epoch 8 Iter 3400, train entropy gap -19.3447 bits (loss 0.036, data 19.381) 
Epoch 8 Iter 3600, train entropy gap -19.3614 bits (loss 0.019, data 19.381) 
Epoch 8 Iter 3800, train entropy gap -19.3531 bits (loss 0.028, data 19.381) 
Epoch 8 Iter 4000, train entropy gap -19.3481 bits (loss 0.033, data 19.381) 
Epoch 8 Iter 4200, train entropy gap -19.3265 bits (loss 0.054, data 19.381) 
Epoch 8 Iter 4400, train entropy gap -19.3469 bits (loss 0.034, data 19.381) 
Epoch 8 Iter 4600, train entropy gap -19.3362 bits (loss 0.045, data 19.381) 
Epoch 8 Iter 4800, train entropy gap -19.3062 bits (loss 0.075, data 19.381) 
Epoch 8 Iter 5000, train entropy gap -19.3588 bits (loss 0.022, data 19.381) 
Epoch 8 Iter 5200, train entropy gap -19.3149 bits (loss 0.066, data 19.381) 
Epoch 8 Iter 5400, train entropy gap -19.3629 bits (loss 0.018, data 19.381) 
Epoch 8 Iter 5600, train entropy gap -19.3224 bits (loss 0.058, data 19.381) 
Epoch 8 Iter 5800, train entropy gap -19.3266 bits (loss 0.054, data 19.381) 
Epoch 8 Iter 6000, train entropy gap -19.2873 bits (loss 0.094, data 19.381) 
Epoch 8 Iter 6200, train entropy gap -19.3399 bits (loss 0.041, data 19.381) 
Epoch 8 Iter 6400, train entropy gap -19.3033 bits (loss 0.078, data 19.381) 
Epoch 8 Iter 6600, train entropy gap -19.3236 bits (loss 0.057, data 19.381) 
Epoch 8 Iter 6800, train entropy gap -19.3475 bits (loss 0.033, data 19.381) 
Epoch 8 Iter 7000, train entropy gap -19.3477 bits (loss 0.033, data 19.381) 
Epoch 8 Iter 7200, train entropy gap -19.2848 bits (loss 0.096, data 19.381) 
epoch 8 train loss 0.0359 nats / 0.0518 bits
time since start: 876.5 secs
Epoch 9 Iter 0, train entropy gap -19.3158 bits (loss 0.065, data 19.381) 
Epoch 9 Iter 200, train entropy gap -19.3559 bits (loss 0.025, data 19.381) 
Epoch 9 Iter 400, train entropy gap -19.3417 bits (loss 0.039, data 19.381) 
Epoch 9 Iter 600, train entropy gap -19.3317 bits (loss 0.049, data 19.381) 
Epoch 9 Iter 800, train entropy gap -19.2984 bits (loss 0.082, data 19.381) 
Epoch 9 Iter 1000, train entropy gap -19.3043 bits (loss 0.077, data 19.381) 
Epoch 9 Iter 1200, train entropy gap -19.3042 bits (loss 0.077, data 19.381) 
Epoch 9 Iter 1400, train entropy gap -19.3301 bits (loss 0.051, data 19.381) 
Epoch 9 Iter 1600, train entropy gap -19.3401 bits (loss 0.041, data 19.381) 
Epoch 9 Iter 1800, train entropy gap -19.3452 bits (loss 0.036, data 19.381) 
Epoch 9 Iter 2000, train entropy gap -19.3480 bits (loss 0.033, data 19.381) 
Epoch 9 Iter 2200, train entropy gap -19.3250 bits (loss 0.056, data 19.381) 
Epoch 9 Iter 2400, train entropy gap -19.3084 bits (loss 0.072, data 19.381) 
Epoch 9 Iter 2600, train entropy gap -19.2872 bits (loss 0.094, data 19.381) 
Epoch 9 Iter 2800, train entropy gap -19.3228 bits (loss 0.058, data 19.381) 
Epoch 9 Iter 3000, train entropy gap -19.3453 bits (loss 0.036, data 19.381) 
Epoch 9 Iter 3200, train entropy gap -19.3155 bits (loss 0.065, data 19.381) 
Epoch 9 Iter 3400, train entropy gap -19.3169 bits (loss 0.064, data 19.381) 
Epoch 9 Iter 3600, train entropy gap -19.3312 bits (loss 0.050, data 19.381) 
Epoch 9 Iter 3800, train entropy gap -19.2914 bits (loss 0.089, data 19.381) 
Epoch 9 Iter 4000, train entropy gap -19.3408 bits (loss 0.040, data 19.381) 
Epoch 9 Iter 4200, train entropy gap -19.3445 bits (loss 0.036, data 19.381) 
Epoch 9 Iter 4400, train entropy gap -19.3326 bits (loss 0.048, data 19.381) 
Epoch 9 Iter 4600, train entropy gap -19.3465 bits (loss 0.034, data 19.381) 
Epoch 9 Iter 4800, train entropy gap -19.3273 bits (loss 0.053, data 19.381) 
Epoch 9 Iter 5000, train entropy gap -19.3154 bits (loss 0.065, data 19.381) 
Epoch 9 Iter 5200, train entropy gap -19.3084 bits (loss 0.072, data 19.381) 
Epoch 9 Iter 5400, train entropy gap -19.3375 bits (loss 0.043, data 19.381) 
Epoch 9 Iter 5600, train entropy gap -19.3237 bits (loss 0.057, data 19.381) 
Epoch 9 Iter 5800, train entropy gap -19.3270 bits (loss 0.054, data 19.381) 
Epoch 9 Iter 6000, train entropy gap -19.3337 bits (loss 0.047, data 19.381) 
Epoch 9 Iter 6200, train entropy gap -19.3255 bits (loss 0.055, data 19.381) 
Epoch 9 Iter 6400, train entropy gap -19.2865 bits (loss 0.094, data 19.381) 
Epoch 9 Iter 6600, train entropy gap -19.3104 bits (loss 0.070, data 19.381) 
Epoch 9 Iter 6800, train entropy gap -19.3226 bits (loss 0.058, data 19.381) 
Epoch 9 Iter 7000, train entropy gap -19.3352 bits (loss 0.046, data 19.381) 
Epoch 9 Iter 7200, train entropy gap -19.3287 bits (loss 0.052, data 19.381) 
epoch 9 train loss 0.0368 nats / 0.0531 bits
time since start: 973.7 secs
Epoch 10 Iter 0, train entropy gap -19.3381 bits (loss 0.043, data 19.381) 
Epoch 10 Iter 200, train entropy gap -19.2988 bits (loss 0.082, data 19.381) 
Epoch 10 Iter 400, train entropy gap -19.3307 bits (loss 0.050, data 19.381) 
Epoch 10 Iter 600, train entropy gap -19.3547 bits (loss 0.026, data 19.381) 
Epoch 10 Iter 800, train entropy gap -19.3421 bits (loss 0.039, data 19.381) 
Epoch 10 Iter 1000, train entropy gap -19.3321 bits (loss 0.049, data 19.381) 
Epoch 10 Iter 1200, train entropy gap -19.3291 bits (loss 0.052, data 19.381) 
Epoch 10 Iter 1400, train entropy gap -19.3404 bits (loss 0.040, data 19.381) 
Epoch 10 Iter 1600, train entropy gap -19.3280 bits (loss 0.053, data 19.381) 
Epoch 10 Iter 1800, train entropy gap -19.3337 bits (loss 0.047, data 19.381) 
Epoch 10 Iter 2000, train entropy gap -19.3237 bits (loss 0.057, data 19.381) 
Epoch 10 Iter 2200, train entropy gap -19.3445 bits (loss 0.036, data 19.381) 
Epoch 10 Iter 2400, train entropy gap -19.3154 bits (loss 0.065, data 19.381) 
Epoch 10 Iter 2600, train entropy gap -19.2999 bits (loss 0.081, data 19.381) 
Epoch 10 Iter 2800, train entropy gap -19.3407 bits (loss 0.040, data 19.381) 
Epoch 10 Iter 3000, train entropy gap -19.3351 bits (loss 0.046, data 19.381) 
Epoch 10 Iter 3200, train entropy gap -19.2798 bits (loss 0.101, data 19.381) 
Epoch 10 Iter 3400, train entropy gap -19.2635 bits (loss 0.117, data 19.381) 
Epoch 10 Iter 3600, train entropy gap -19.3143 bits (loss 0.067, data 19.381) 
Epoch 10 Iter 3800, train entropy gap -19.3261 bits (loss 0.055, data 19.381) 
Epoch 10 Iter 4000, train entropy gap -19.3464 bits (loss 0.034, data 19.381) 
Epoch 10 Iter 4200, train entropy gap -19.3400 bits (loss 0.041, data 19.381) 
Epoch 10 Iter 4400, train entropy gap -19.3337 bits (loss 0.047, data 19.381) 
Epoch 10 Iter 4600, train entropy gap -19.3327 bits (loss 0.048, data 19.381) 
Epoch 10 Iter 4800, train entropy gap -19.3508 bits (loss 0.030, data 19.381) 
Epoch 10 Iter 5000, train entropy gap -19.3530 bits (loss 0.028, data 19.381) 
Epoch 10 Iter 5200, train entropy gap -19.3196 bits (loss 0.061, data 19.381) 
Epoch 10 Iter 5400, train entropy gap -19.3377 bits (loss 0.043, data 19.381) 
Epoch 10 Iter 5600, train entropy gap -19.3588 bits (loss 0.022, data 19.381) 
Epoch 10 Iter 5800, train entropy gap -19.3595 bits (loss 0.021, data 19.381) 
Epoch 10 Iter 6000, train entropy gap -19.3132 bits (loss 0.068, data 19.381) 
Epoch 10 Iter 6200, train entropy gap -19.3260 bits (loss 0.055, data 19.381) 
Epoch 10 Iter 6400, train entropy gap -19.3425 bits (loss 0.038, data 19.381) 
Epoch 10 Iter 6600, train entropy gap -19.3231 bits (loss 0.058, data 19.381) 
Epoch 10 Iter 6800, train entropy gap -19.2767 bits (loss 0.104, data 19.381) 
Epoch 10 Iter 7000, train entropy gap -19.3278 bits (loss 0.053, data 19.381) 
Epoch 10 Iter 7200, train entropy gap -19.3349 bits (loss 0.046, data 19.381) 
epoch 10 train loss 0.0373 nats / 0.0537 bits
time since start: 1071.1 secs
Epoch 11 Iter 0, train entropy gap -19.3160 bits (loss 0.065, data 19.381) 
Epoch 11 Iter 200, train entropy gap -19.3518 bits (loss 0.029, data 19.381) 
Epoch 11 Iter 400, train entropy gap -19.3214 bits (loss 0.059, data 19.381) 
Epoch 11 Iter 600, train entropy gap -19.3299 bits (loss 0.051, data 19.381) 
Epoch 11 Iter 800, train entropy gap -19.3242 bits (loss 0.057, data 19.381) 
Epoch 11 Iter 1000, train entropy gap -19.3448 bits (loss 0.036, data 19.381) 
Epoch 11 Iter 1200, train entropy gap -19.3036 bits (loss 0.077, data 19.381) 
Epoch 11 Iter 1400, train entropy gap -19.2700 bits (loss 0.111, data 19.381) 
Epoch 11 Iter 1600, train entropy gap -19.3563 bits (loss 0.025, data 19.381) 
Epoch 11 Iter 1800, train entropy gap -19.3267 bits (loss 0.054, data 19.381) 
Epoch 11 Iter 2000, train entropy gap -19.3192 bits (loss 0.062, data 19.381) 
Epoch 11 Iter 2200, train entropy gap -19.3250 bits (loss 0.056, data 19.381) 
Epoch 11 Iter 2400, train entropy gap -19.3413 bits (loss 0.040, data 19.381) 
Epoch 11 Iter 2600, train entropy gap -19.3518 bits (loss 0.029, data 19.381) 
Epoch 11 Iter 2800, train entropy gap -19.2944 bits (loss 0.086, data 19.381) 
Epoch 11 Iter 3000, train entropy gap -19.3365 bits (loss 0.044, data 19.381) 
Epoch 11 Iter 3200, train entropy gap -19.3504 bits (loss 0.030, data 19.381) 
Epoch 11 Iter 3400, train entropy gap -19.3323 bits (loss 0.049, data 19.381) 
Epoch 11 Iter 3600, train entropy gap -19.3321 bits (loss 0.049, data 19.381) 
Epoch 11 Iter 3800, train entropy gap -19.3161 bits (loss 0.065, data 19.381) 
Epoch 11 Iter 4000, train entropy gap -19.3286 bits (loss 0.052, data 19.381) 
Epoch 11 Iter 4200, train entropy gap -19.3189 bits (loss 0.062, data 19.381) 
Epoch 11 Iter 4400, train entropy gap -19.3071 bits (loss 0.074, data 19.381) 
Epoch 11 Iter 4600, train entropy gap -19.3439 bits (loss 0.037, data 19.381) 
Epoch 11 Iter 4800, train entropy gap -19.3419 bits (loss 0.039, data 19.381) 
Epoch 11 Iter 5000, train entropy gap -19.3582 bits (loss 0.023, data 19.381) 
Epoch 11 Iter 5200, train entropy gap -19.3038 bits (loss 0.077, data 19.381) 
Epoch 11 Iter 5400, train entropy gap -19.3272 bits (loss 0.054, data 19.381) 
Epoch 11 Iter 5600, train entropy gap -19.3279 bits (loss 0.053, data 19.381) 
Epoch 11 Iter 5800, train entropy gap -19.2867 bits (loss 0.094, data 19.381) 
Epoch 11 Iter 6000, train entropy gap -19.3128 bits (loss 0.068, data 19.381) 
Epoch 11 Iter 6200, train entropy gap -19.3490 bits (loss 0.032, data 19.381) 
Epoch 11 Iter 6400, train entropy gap -19.3297 bits (loss 0.051, data 19.381) 
Epoch 11 Iter 6600, train entropy gap -19.2877 bits (loss 0.093, data 19.381) 
Epoch 11 Iter 6800, train entropy gap -19.2680 bits (loss 0.113, data 19.381) 
Epoch 11 Iter 7000, train entropy gap -19.3322 bits (loss 0.049, data 19.381) 
Epoch 11 Iter 7200, train entropy gap -19.3222 bits (loss 0.059, data 19.381) 
epoch 11 train loss 0.0381 nats / 0.0550 bits
time since start: 1168.2 secs
Epoch 12 Iter 0, train entropy gap -19.3329 bits (loss 0.048, data 19.381) 
Epoch 12 Iter 200, train entropy gap -19.3281 bits (loss 0.053, data 19.381) 
Epoch 12 Iter 400, train entropy gap -19.3256 bits (loss 0.055, data 19.381) 
Epoch 12 Iter 600, train entropy gap -19.3437 bits (loss 0.037, data 19.381) 
Epoch 12 Iter 800, train entropy gap -19.3210 bits (loss 0.060, data 19.381) 
Epoch 12 Iter 1000, train entropy gap -19.3353 bits (loss 0.046, data 19.381) 
Epoch 12 Iter 1200, train entropy gap -19.3524 bits (loss 0.028, data 19.381) 
Epoch 12 Iter 1400, train entropy gap -19.3142 bits (loss 0.067, data 19.381) 
Epoch 12 Iter 1600, train entropy gap -19.3193 bits (loss 0.061, data 19.381) 
Epoch 12 Iter 1800, train entropy gap -19.3456 bits (loss 0.035, data 19.381) 
Epoch 12 Iter 2000, train entropy gap -19.3446 bits (loss 0.036, data 19.381) 
Epoch 12 Iter 2200, train entropy gap -19.3304 bits (loss 0.050, data 19.381) 
Epoch 12 Iter 2400, train entropy gap -19.3435 bits (loss 0.037, data 19.381) 
Epoch 12 Iter 2600, train entropy gap -19.3579 bits (loss 0.023, data 19.381) 
Epoch 12 Iter 2800, train entropy gap -19.3339 bits (loss 0.047, data 19.381) 
Epoch 12 Iter 3000, train entropy gap -19.3361 bits (loss 0.045, data 19.381) 
Epoch 12 Iter 3200, train entropy gap -19.3161 bits (loss 0.065, data 19.381) 
Epoch 12 Iter 3400, train entropy gap -19.3185 bits (loss 0.062, data 19.381) 
Epoch 12 Iter 3600, train entropy gap -19.3456 bits (loss 0.035, data 19.381) 
Epoch 12 Iter 3800, train entropy gap -19.3053 bits (loss 0.076, data 19.381) 
Epoch 12 Iter 4000, train entropy gap -19.3129 bits (loss 0.068, data 19.381) 
Epoch 12 Iter 4200, train entropy gap -19.3038 bits (loss 0.077, data 19.381) 
Epoch 12 Iter 4400, train entropy gap -19.3200 bits (loss 0.061, data 19.381) 
Epoch 12 Iter 4600, train entropy gap -19.3266 bits (loss 0.054, data 19.381) 
Epoch 12 Iter 4800, train entropy gap -19.3285 bits (loss 0.052, data 19.381) 
Epoch 12 Iter 5000, train entropy gap -19.3103 bits (loss 0.070, data 19.381) 
Epoch 12 Iter 5200, train entropy gap -19.3310 bits (loss 0.050, data 19.381) 
Epoch 12 Iter 5400, train entropy gap -19.3532 bits (loss 0.028, data 19.381) 
Epoch 12 Iter 5600, train entropy gap -19.3208 bits (loss 0.060, data 19.381) 
Epoch 12 Iter 5800, train entropy gap -19.3224 bits (loss 0.058, data 19.381) 
Epoch 12 Iter 6000, train entropy gap -19.3304 bits (loss 0.050, data 19.381) 
Epoch 12 Iter 6200, train entropy gap -19.3276 bits (loss 0.053, data 19.381) 
Epoch 12 Iter 6400, train entropy gap -19.3180 bits (loss 0.063, data 19.381) 
Epoch 12 Iter 6600, train entropy gap -19.3402 bits (loss 0.041, data 19.381) 
Epoch 12 Iter 6800, train entropy gap -19.3270 bits (loss 0.054, data 19.381) 
Epoch 12 Iter 7000, train entropy gap -19.3466 bits (loss 0.034, data 19.381) 
Epoch 12 Iter 7200, train entropy gap -19.2992 bits (loss 0.082, data 19.381) 
epoch 12 train loss 0.0390 nats / 0.0563 bits
time since start: 1265.4 secs
Epoch 13 Iter 0, train entropy gap -19.3318 bits (loss 0.049, data 19.381) 
Epoch 13 Iter 200, train entropy gap -19.3110 bits (loss 0.070, data 19.381) 
Epoch 13 Iter 400, train entropy gap -19.3215 bits (loss 0.059, data 19.381) 
Epoch 13 Iter 600, train entropy gap -19.3547 bits (loss 0.026, data 19.381) 
Epoch 13 Iter 800, train entropy gap -19.3402 bits (loss 0.041, data 19.381) 
Epoch 13 Iter 1000, train entropy gap -19.3292 bits (loss 0.052, data 19.381) 
Epoch 13 Iter 1200, train entropy gap -19.3253 bits (loss 0.055, data 19.381) 
Epoch 13 Iter 1400, train entropy gap -19.3243 bits (loss 0.057, data 19.381) 
Epoch 13 Iter 1600, train entropy gap -19.3288 bits (loss 0.052, data 19.381) 
Epoch 13 Iter 1800, train entropy gap -19.2980 bits (loss 0.083, data 19.381) 
Epoch 13 Iter 2000, train entropy gap -19.3388 bits (loss 0.042, data 19.381) 
Epoch 13 Iter 2200, train entropy gap -19.3038 bits (loss 0.077, data 19.381) 
Epoch 13 Iter 2400, train entropy gap -19.3157 bits (loss 0.065, data 19.381) 
Epoch 13 Iter 2600, train entropy gap -19.3111 bits (loss 0.070, data 19.381) 
Epoch 13 Iter 2800, train entropy gap -19.3142 bits (loss 0.067, data 19.381) 
Epoch 13 Iter 3000, train entropy gap -19.3235 bits (loss 0.057, data 19.381) 
Epoch 13 Iter 3200, train entropy gap -19.2931 bits (loss 0.088, data 19.381) 
Epoch 13 Iter 3400, train entropy gap -19.2669 bits (loss 0.114, data 19.381) 
Epoch 13 Iter 3600, train entropy gap -19.3452 bits (loss 0.036, data 19.381) 
Epoch 13 Iter 3800, train entropy gap -19.3348 bits (loss 0.046, data 19.381) 
Epoch 13 Iter 4000, train entropy gap -19.3479 bits (loss 0.033, data 19.381) 
Epoch 13 Iter 4200, train entropy gap -19.3374 bits (loss 0.043, data 19.381) 
Epoch 13 Iter 4400, train entropy gap -19.3179 bits (loss 0.063, data 19.381) 
Epoch 13 Iter 4600, train entropy gap -19.3114 bits (loss 0.069, data 19.381) 
Epoch 13 Iter 4800, train entropy gap -19.3289 bits (loss 0.052, data 19.381) 
Epoch 13 Iter 5000, train entropy gap -19.3176 bits (loss 0.063, data 19.381) 
Epoch 13 Iter 5200, train entropy gap -19.3377 bits (loss 0.043, data 19.381) 
Epoch 13 Iter 5400, train entropy gap -19.3517 bits (loss 0.029, data 19.381) 
Epoch 13 Iter 5600, train entropy gap -19.3437 bits (loss 0.037, data 19.381) 
Epoch 13 Iter 5800, train entropy gap -19.3322 bits (loss 0.049, data 19.381) 
Epoch 13 Iter 6000, train entropy gap -19.3482 bits (loss 0.033, data 19.381) 
Epoch 13 Iter 6200, train entropy gap -19.3136 bits (loss 0.067, data 19.381) 
Epoch 13 Iter 6400, train entropy gap -19.2979 bits (loss 0.083, data 19.381) 
Epoch 13 Iter 6600, train entropy gap -19.3463 bits (loss 0.034, data 19.381) 
Epoch 13 Iter 6800, train entropy gap -19.2861 bits (loss 0.095, data 19.381) 
Epoch 13 Iter 7000, train entropy gap -19.3424 bits (loss 0.038, data 19.381) 
Epoch 13 Iter 7200, train entropy gap -19.3185 bits (loss 0.062, data 19.381) 
epoch 13 train loss 0.0391 nats / 0.0565 bits
time since start: 1362.6 secs
Epoch 14 Iter 0, train entropy gap -19.3386 bits (loss 0.042, data 19.381) 
Epoch 14 Iter 200, train entropy gap -19.3214 bits (loss 0.059, data 19.381) 
Epoch 14 Iter 400, train entropy gap -19.3282 bits (loss 0.053, data 19.381) 
Epoch 14 Iter 600, train entropy gap -19.3199 bits (loss 0.061, data 19.381) 
Epoch 14 Iter 800, train entropy gap -19.3332 bits (loss 0.048, data 19.381) 
Epoch 14 Iter 1000, train entropy gap -19.3212 bits (loss 0.060, data 19.381) 
Epoch 14 Iter 1200, train entropy gap -19.3231 bits (loss 0.058, data 19.381) 
Epoch 14 Iter 1400, train entropy gap -19.2969 bits (loss 0.084, data 19.381) 
Epoch 14 Iter 1600, train entropy gap -19.2973 bits (loss 0.084, data 19.381) 
Epoch 14 Iter 1800, train entropy gap -19.3176 bits (loss 0.063, data 19.381) 
Epoch 14 Iter 2000, train entropy gap -19.3542 bits (loss 0.027, data 19.381) 
Epoch 14 Iter 2200, train entropy gap -19.3486 bits (loss 0.032, data 19.381) 
Epoch 14 Iter 2400, train entropy gap -19.3428 bits (loss 0.038, data 19.381) 
Epoch 14 Iter 2600, train entropy gap -19.3375 bits (loss 0.043, data 19.381) 
Epoch 14 Iter 2800, train entropy gap -19.3331 bits (loss 0.048, data 19.381) 
Epoch 14 Iter 3000, train entropy gap -19.3162 bits (loss 0.065, data 19.381) 
Epoch 14 Iter 3200, train entropy gap -19.2851 bits (loss 0.096, data 19.381) 
Epoch 14 Iter 3400, train entropy gap -19.3203 bits (loss 0.061, data 19.381) 
Epoch 14 Iter 3600, train entropy gap -19.3284 bits (loss 0.052, data 19.381) 
Epoch 14 Iter 3800, train entropy gap -19.3196 bits (loss 0.061, data 19.381) 
Epoch 14 Iter 4000, train entropy gap -19.3485 bits (loss 0.032, data 19.381) 
Epoch 14 Iter 4200, train entropy gap -19.3647 bits (loss 0.016, data 19.381) 
Epoch 14 Iter 4400, train entropy gap -19.3371 bits (loss 0.044, data 19.381) 
Epoch 14 Iter 4600, train entropy gap -19.3221 bits (loss 0.059, data 19.381) 
Epoch 14 Iter 4800, train entropy gap -19.2986 bits (loss 0.082, data 19.381) 
Epoch 14 Iter 5000, train entropy gap -19.2983 bits (loss 0.083, data 19.381) 
Epoch 14 Iter 5200, train entropy gap -19.3193 bits (loss 0.061, data 19.381) 
Epoch 14 Iter 5400, train entropy gap -19.3391 bits (loss 0.042, data 19.381) 
Epoch 14 Iter 5600, train entropy gap -19.2939 bits (loss 0.087, data 19.381) 
Epoch 14 Iter 5800, train entropy gap -19.3153 bits (loss 0.065, data 19.381) 
Epoch 14 Iter 6000, train entropy gap -19.3325 bits (loss 0.048, data 19.381) 
Epoch 14 Iter 6200, train entropy gap -19.3549 bits (loss 0.026, data 19.381) 
Epoch 14 Iter 6400, train entropy gap -19.3144 bits (loss 0.066, data 19.381) 
Epoch 14 Iter 6600, train entropy gap -19.3621 bits (loss 0.019, data 19.381) 
Epoch 14 Iter 6800, train entropy gap -19.3262 bits (loss 0.055, data 19.381) 
Epoch 14 Iter 7000, train entropy gap -19.3210 bits (loss 0.060, data 19.381) 
Epoch 14 Iter 7200, train entropy gap -19.3021 bits (loss 0.079, data 19.381) 
epoch 14 train loss 0.0395 nats / 0.0570 bits
time since start: 1459.8 secs
Epoch 15 Iter 0, train entropy gap -19.3621 bits (loss 0.019, data 19.381) 
Epoch 15 Iter 200, train entropy gap -19.3446 bits (loss 0.036, data 19.381) 
Epoch 15 Iter 400, train entropy gap -19.3280 bits (loss 0.053, data 19.381) 
Epoch 15 Iter 600, train entropy gap -19.3352 bits (loss 0.046, data 19.381) 
Epoch 15 Iter 800, train entropy gap -19.3144 bits (loss 0.066, data 19.381) 
Epoch 15 Iter 1000, train entropy gap -19.3542 bits (loss 0.027, data 19.381) 
Epoch 15 Iter 1200, train entropy gap -19.2949 bits (loss 0.086, data 19.381) 
Epoch 15 Iter 1400, train entropy gap -19.3221 bits (loss 0.059, data 19.381) 
Epoch 15 Iter 1600, train entropy gap -19.2996 bits (loss 0.081, data 19.381) 
Epoch 15 Iter 1800, train entropy gap -19.3407 bits (loss 0.040, data 19.381) 
Epoch 15 Iter 2000, train entropy gap -19.3209 bits (loss 0.060, data 19.381) 
Epoch 15 Iter 2200, train entropy gap -19.3146 bits (loss 0.066, data 19.381) 
Epoch 15 Iter 2400, train entropy gap -19.3276 bits (loss 0.053, data 19.381) 
Epoch 15 Iter 2600, train entropy gap -19.2791 bits (loss 0.102, data 19.381) 
Epoch 15 Iter 2800, train entropy gap -19.3136 bits (loss 0.067, data 19.381) 
Epoch 15 Iter 3000, train entropy gap -19.3361 bits (loss 0.045, data 19.381) 
Epoch 15 Iter 3200, train entropy gap -19.2989 bits (loss 0.082, data 19.381) 
Epoch 15 Iter 3400, train entropy gap -19.3465 bits (loss 0.034, data 19.381) 
Epoch 15 Iter 3600, train entropy gap -19.3179 bits (loss 0.063, data 19.381) 
Epoch 15 Iter 3800, train entropy gap -19.3076 bits (loss 0.073, data 19.381) 
Epoch 15 Iter 4000, train entropy gap -19.3103 bits (loss 0.071, data 19.381) 
Epoch 15 Iter 4200, train entropy gap -19.3243 bits (loss 0.056, data 19.381) 
Epoch 15 Iter 4400, train entropy gap -19.3151 bits (loss 0.066, data 19.381) 
Epoch 15 Iter 4600, train entropy gap -19.2979 bits (loss 0.083, data 19.381) 
Epoch 15 Iter 4800, train entropy gap -19.3284 bits (loss 0.052, data 19.381) 
Epoch 15 Iter 5000, train entropy gap -19.3242 bits (loss 0.057, data 19.381) 
Epoch 15 Iter 5200, train entropy gap -19.3197 bits (loss 0.061, data 19.381) 
Epoch 15 Iter 5400, train entropy gap -19.3222 bits (loss 0.059, data 19.381) 
Epoch 15 Iter 5600, train entropy gap -19.3246 bits (loss 0.056, data 19.381) 
Epoch 15 Iter 5800, train entropy gap -19.3085 bits (loss 0.072, data 19.381) 
Epoch 15 Iter 6000, train entropy gap -19.3003 bits (loss 0.081, data 19.381) 
Epoch 15 Iter 6200, train entropy gap -19.3414 bits (loss 0.039, data 19.381) 
Epoch 15 Iter 6400, train entropy gap -19.2988 bits (loss 0.082, data 19.381) 
Epoch 15 Iter 6600, train entropy gap -19.3258 bits (loss 0.055, data 19.381) 
Epoch 15 Iter 6800, train entropy gap -19.3045 bits (loss 0.076, data 19.381) 
Epoch 15 Iter 7000, train entropy gap -19.3137 bits (loss 0.067, data 19.381) 
Epoch 15 Iter 7200, train entropy gap -19.3426 bits (loss 0.038, data 19.381) 
epoch 15 train loss 0.0403 nats / 0.0581 bits
time since start: 1557.1 secs
Epoch 16 Iter 0, train entropy gap -19.3363 bits (loss 0.044, data 19.381) 
Epoch 16 Iter 200, train entropy gap -19.3400 bits (loss 0.041, data 19.381) 
Epoch 16 Iter 400, train entropy gap -19.3356 bits (loss 0.045, data 19.381) 
Epoch 16 Iter 600, train entropy gap -19.3147 bits (loss 0.066, data 19.381) 
Epoch 16 Iter 800, train entropy gap -19.3059 bits (loss 0.075, data 19.381) 
Epoch 16 Iter 1000, train entropy gap -19.3111 bits (loss 0.070, data 19.381) 
Epoch 16 Iter 1200, train entropy gap -19.3220 bits (loss 0.059, data 19.381) 
Epoch 16 Iter 1400, train entropy gap -19.3395 bits (loss 0.041, data 19.381) 
Epoch 16 Iter 1600, train entropy gap -19.3132 bits (loss 0.068, data 19.381) 
Epoch 16 Iter 1800, train entropy gap -19.2755 bits (loss 0.105, data 19.381) 
Epoch 16 Iter 2000, train entropy gap -19.2744 bits (loss 0.106, data 19.381) 
Epoch 16 Iter 2200, train entropy gap -19.2858 bits (loss 0.095, data 19.381) 
Epoch 16 Iter 2400, train entropy gap -19.3013 bits (loss 0.079, data 19.381) 
Epoch 16 Iter 2600, train entropy gap -19.3126 bits (loss 0.068, data 19.381) 
Epoch 16 Iter 2800, train entropy gap -19.3084 bits (loss 0.072, data 19.381) 
Epoch 16 Iter 3000, train entropy gap -19.3365 bits (loss 0.044, data 19.381) 
Epoch 16 Iter 3200, train entropy gap -19.3079 bits (loss 0.073, data 19.381) 
Epoch 16 Iter 3400, train entropy gap -19.3261 bits (loss 0.055, data 19.381) 
Epoch 16 Iter 3600, train entropy gap -19.3357 bits (loss 0.045, data 19.381) 
Epoch 16 Iter 3800, train entropy gap -19.3275 bits (loss 0.053, data 19.381) 
Epoch 16 Iter 4000, train entropy gap -19.3224 bits (loss 0.058, data 19.381) 
Epoch 16 Iter 4200, train entropy gap -19.3162 bits (loss 0.065, data 19.381) 
Epoch 16 Iter 4400, train entropy gap -19.3107 bits (loss 0.070, data 19.381) 
Epoch 16 Iter 4600, train entropy gap -19.2959 bits (loss 0.085, data 19.381) 
Epoch 16 Iter 4800, train entropy gap -19.3171 bits (loss 0.064, data 19.381) 
Epoch 16 Iter 5000, train entropy gap -19.3119 bits (loss 0.069, data 19.381) 
Epoch 16 Iter 5200, train entropy gap -19.3046 bits (loss 0.076, data 19.381) 
Epoch 16 Iter 5400, train entropy gap -19.3236 bits (loss 0.057, data 19.381) 
Epoch 16 Iter 5600, train entropy gap -19.3416 bits (loss 0.039, data 19.381) 
Epoch 16 Iter 5800, train entropy gap -19.2870 bits (loss 0.094, data 19.381) 
Epoch 16 Iter 6000, train entropy gap -19.3477 bits (loss 0.033, data 19.381) 
Epoch 16 Iter 6200, train entropy gap -19.2998 bits (loss 0.081, data 19.381) 
Epoch 16 Iter 6400, train entropy gap -19.3084 bits (loss 0.072, data 19.381) 
Epoch 16 Iter 6600, train entropy gap -19.3433 bits (loss 0.038, data 19.381) 
Epoch 16 Iter 6800, train entropy gap -19.3298 bits (loss 0.051, data 19.381) 
Epoch 16 Iter 7000, train entropy gap -19.2905 bits (loss 0.090, data 19.381) 
Epoch 16 Iter 7200, train entropy gap -19.2764 bits (loss 0.104, data 19.381) 
epoch 16 train loss 0.0409 nats / 0.0591 bits
time since start: 1654.4 secs
Epoch 17 Iter 0, train entropy gap -19.3445 bits (loss 0.036, data 19.381) 
Epoch 17 Iter 200, train entropy gap -19.3517 bits (loss 0.029, data 19.381) 
Epoch 17 Iter 400, train entropy gap -19.3179 bits (loss 0.063, data 19.381) 
Epoch 17 Iter 600, train entropy gap -19.3137 bits (loss 0.067, data 19.381) 
Epoch 17 Iter 800, train entropy gap -19.3046 bits (loss 0.076, data 19.381) 
Epoch 17 Iter 1000, train entropy gap -19.3204 bits (loss 0.060, data 19.381) 
Epoch 17 Iter 1200, train entropy gap -19.3133 bits (loss 0.068, data 19.381) 
Epoch 17 Iter 1400, train entropy gap -19.3262 bits (loss 0.055, data 19.381) 
Epoch 17 Iter 1600, train entropy gap -19.3278 bits (loss 0.053, data 19.381) 
Epoch 17 Iter 1800, train entropy gap -19.3064 bits (loss 0.074, data 19.381) 
Epoch 17 Iter 2000, train entropy gap -19.3530 bits (loss 0.028, data 19.381) 
Epoch 17 Iter 2200, train entropy gap -19.3423 bits (loss 0.038, data 19.381) 
Epoch 17 Iter 2400, train entropy gap -19.3397 bits (loss 0.041, data 19.381) 
Epoch 17 Iter 2600, train entropy gap -19.3002 bits (loss 0.081, data 19.381) 
Epoch 17 Iter 2800, train entropy gap -19.3318 bits (loss 0.049, data 19.381) 
Epoch 17 Iter 3000, train entropy gap -19.3135 bits (loss 0.067, data 19.381) 
Epoch 17 Iter 3200, train entropy gap -19.3424 bits (loss 0.038, data 19.381) 
Epoch 17 Iter 3400, train entropy gap -19.3177 bits (loss 0.063, data 19.381) 
Epoch 17 Iter 3600, train entropy gap -19.3258 bits (loss 0.055, data 19.381) 
Epoch 17 Iter 3800, train entropy gap -19.3006 bits (loss 0.080, data 19.381) 
Epoch 17 Iter 4000, train entropy gap -19.3264 bits (loss 0.054, data 19.381) 
Epoch 17 Iter 4200, train entropy gap -19.3210 bits (loss 0.060, data 19.381) 
Epoch 17 Iter 4400, train entropy gap -19.2981 bits (loss 0.083, data 19.381) 
Epoch 17 Iter 4600, train entropy gap -19.3288 bits (loss 0.052, data 19.381) 
Epoch 17 Iter 4800, train entropy gap -19.3235 bits (loss 0.057, data 19.381) 
Epoch 17 Iter 5000, train entropy gap -19.3098 bits (loss 0.071, data 19.381) 
Epoch 17 Iter 5200, train entropy gap -19.3275 bits (loss 0.053, data 19.381) 
Epoch 17 Iter 5400, train entropy gap -19.3611 bits (loss 0.020, data 19.381) 
Epoch 17 Iter 5600, train entropy gap -19.3361 bits (loss 0.045, data 19.381) 
Epoch 17 Iter 5800, train entropy gap -19.3169 bits (loss 0.064, data 19.381) 
Epoch 17 Iter 6000, train entropy gap -19.3208 bits (loss 0.060, data 19.381) 
Epoch 17 Iter 6200, train entropy gap -19.3251 bits (loss 0.056, data 19.381) 
Epoch 17 Iter 6400, train entropy gap -19.3228 bits (loss 0.058, data 19.381) 
Epoch 17 Iter 6600, train entropy gap -19.3044 bits (loss 0.076, data 19.381) 
Epoch 17 Iter 6800, train entropy gap -19.2874 bits (loss 0.093, data 19.381) 
Epoch 17 Iter 7000, train entropy gap -19.2851 bits (loss 0.096, data 19.381) 
Epoch 17 Iter 7200, train entropy gap -19.3403 bits (loss 0.040, data 19.381) 
epoch 17 train loss 0.0413 nats / 0.0596 bits
time since start: 1751.7 secs
Epoch 18 Iter 0, train entropy gap -19.3210 bits (loss 0.060, data 19.381) 
Epoch 18 Iter 200, train entropy gap -19.3352 bits (loss 0.046, data 19.381) 
Epoch 18 Iter 400, train entropy gap -19.3234 bits (loss 0.057, data 19.381) 
Epoch 18 Iter 600, train entropy gap -19.3107 bits (loss 0.070, data 19.381) 
Epoch 18 Iter 800, train entropy gap -19.3332 bits (loss 0.048, data 19.381) 
Epoch 18 Iter 1000, train entropy gap -19.3302 bits (loss 0.051, data 19.381) 
Epoch 18 Iter 1200, train entropy gap -19.3084 bits (loss 0.072, data 19.381) 
Epoch 18 Iter 1400, train entropy gap -19.3313 bits (loss 0.050, data 19.381) 
Epoch 18 Iter 1600, train entropy gap -19.3334 bits (loss 0.047, data 19.381) 
Epoch 18 Iter 1800, train entropy gap -19.3565 bits (loss 0.024, data 19.381) 
Epoch 18 Iter 2000, train entropy gap -19.3217 bits (loss 0.059, data 19.381) 
Epoch 18 Iter 2200, train entropy gap -19.2730 bits (loss 0.108, data 19.381) 
Epoch 18 Iter 2400, train entropy gap -19.2762 bits (loss 0.105, data 19.381) 
Epoch 18 Iter 2600, train entropy gap -19.3242 bits (loss 0.057, data 19.381) 
Epoch 18 Iter 2800, train entropy gap -19.2846 bits (loss 0.096, data 19.381) 
Epoch 18 Iter 3000, train entropy gap -19.3465 bits (loss 0.034, data 19.381) 
Epoch 18 Iter 3200, train entropy gap -19.2868 bits (loss 0.094, data 19.381) 
Epoch 18 Iter 3400, train entropy gap -19.3115 bits (loss 0.069, data 19.381) 
Epoch 18 Iter 3600, train entropy gap -19.2838 bits (loss 0.097, data 19.381) 
Epoch 18 Iter 3800, train entropy gap -19.3449 bits (loss 0.036, data 19.381) 
Epoch 18 Iter 4000, train entropy gap -19.3102 bits (loss 0.071, data 19.381) 
Epoch 18 Iter 4200, train entropy gap -19.3170 bits (loss 0.064, data 19.381) 
Epoch 18 Iter 4400, train entropy gap -19.3343 bits (loss 0.047, data 19.381) 
Epoch 18 Iter 4600, train entropy gap -19.3245 bits (loss 0.056, data 19.381) 
Epoch 18 Iter 4800, train entropy gap -19.3150 bits (loss 0.066, data 19.381) 
Epoch 18 Iter 5000, train entropy gap -19.3213 bits (loss 0.059, data 19.381) 
Epoch 18 Iter 5200, train entropy gap -19.3387 bits (loss 0.042, data 19.381) 
Epoch 18 Iter 5400, train entropy gap -19.3253 bits (loss 0.056, data 19.381) 
Epoch 18 Iter 5600, train entropy gap -19.2729 bits (loss 0.108, data 19.381) 
Epoch 18 Iter 5800, train entropy gap -19.2945 bits (loss 0.086, data 19.381) 
Epoch 18 Iter 6000, train entropy gap -19.2909 bits (loss 0.090, data 19.381) 
Epoch 18 Iter 6200, train entropy gap -19.3099 bits (loss 0.071, data 19.381) 
Epoch 18 Iter 6400, train entropy gap -19.3110 bits (loss 0.070, data 19.381) 
Epoch 18 Iter 6600, train entropy gap -19.3356 bits (loss 0.045, data 19.381) 
Epoch 18 Iter 6800, train entropy gap -19.3177 bits (loss 0.063, data 19.381) 
Epoch 18 Iter 7000, train entropy gap -19.2992 bits (loss 0.082, data 19.381) 
Epoch 18 Iter 7200, train entropy gap -19.3179 bits (loss 0.063, data 19.381) 
epoch 18 train loss 0.0422 nats / 0.0609 bits
time since start: 1849.0 secs
Epoch 19 Iter 0, train entropy gap -19.3324 bits (loss 0.048, data 19.381) 
Epoch 19 Iter 200, train entropy gap -19.3056 bits (loss 0.075, data 19.381) 
Epoch 19 Iter 400, train entropy gap -19.3436 bits (loss 0.037, data 19.381) 
Epoch 19 Iter 600, train entropy gap -19.3165 bits (loss 0.064, data 19.381) 
Epoch 19 Iter 800, train entropy gap -19.3261 bits (loss 0.055, data 19.381) 
Epoch 19 Iter 1000, train entropy gap -19.3423 bits (loss 0.038, data 19.381) 
Epoch 19 Iter 1200, train entropy gap -19.3532 bits (loss 0.028, data 19.381) 
Epoch 19 Iter 1400, train entropy gap -19.3325 bits (loss 0.048, data 19.381) 
Epoch 19 Iter 1600, train entropy gap -19.3385 bits (loss 0.042, data 19.381) 
Epoch 19 Iter 1800, train entropy gap -19.3289 bits (loss 0.052, data 19.381) 
Epoch 19 Iter 2000, train entropy gap -19.3095 bits (loss 0.071, data 19.381) 
Epoch 19 Iter 2200, train entropy gap -19.3323 bits (loss 0.049, data 19.381) 
Epoch 19 Iter 2400, train entropy gap -19.3215 bits (loss 0.059, data 19.381) 
Epoch 19 Iter 2600, train entropy gap -19.2845 bits (loss 0.096, data 19.381) 
Epoch 19 Iter 2800, train entropy gap -19.3329 bits (loss 0.048, data 19.381) 
Epoch 19 Iter 3000, train entropy gap -19.3405 bits (loss 0.040, data 19.381) 
Epoch 19 Iter 3200, train entropy gap -19.3352 bits (loss 0.046, data 19.381) 
Epoch 19 Iter 3400, train entropy gap -19.3150 bits (loss 0.066, data 19.381) 
Epoch 19 Iter 3600, train entropy gap -19.2969 bits (loss 0.084, data 19.381) 
Epoch 19 Iter 3800, train entropy gap -19.3254 bits (loss 0.055, data 19.381) 
Epoch 19 Iter 4000, train entropy gap -19.3199 bits (loss 0.061, data 19.381) 
Epoch 19 Iter 4200, train entropy gap -19.3540 bits (loss 0.027, data 19.381) 
Epoch 19 Iter 4400, train entropy gap -19.3254 bits (loss 0.055, data 19.381) 
Epoch 19 Iter 4600, train entropy gap -19.3218 bits (loss 0.059, data 19.381) 
Epoch 19 Iter 4800, train entropy gap -19.3211 bits (loss 0.060, data 19.381) 
Epoch 19 Iter 5000, train entropy gap -19.3136 bits (loss 0.067, data 19.381) 
Epoch 19 Iter 5200, train entropy gap -19.3002 bits (loss 0.081, data 19.381) 
Epoch 19 Iter 5400, train entropy gap -19.3559 bits (loss 0.025, data 19.381) 
Epoch 19 Iter 5600, train entropy gap -19.3062 bits (loss 0.075, data 19.381) 
Epoch 19 Iter 5800, train entropy gap -19.3073 bits (loss 0.074, data 19.381) 
Epoch 19 Iter 6000, train entropy gap -19.3097 bits (loss 0.071, data 19.381) 
Epoch 19 Iter 6200, train entropy gap -19.2841 bits (loss 0.097, data 19.381) 
Epoch 19 Iter 6400, train entropy gap -19.3142 bits (loss 0.067, data 19.381) 
Epoch 19 Iter 6600, train entropy gap -19.3149 bits (loss 0.066, data 19.381) 
Epoch 19 Iter 6800, train entropy gap -19.3053 bits (loss 0.076, data 19.381) 
Epoch 19 Iter 7000, train entropy gap -19.3246 bits (loss 0.056, data 19.381) 
Epoch 19 Iter 7200, train entropy gap -19.2970 bits (loss 0.084, data 19.381) 
epoch 19 train loss 0.0427 nats / 0.0616 bits
time since start: 1946.3 secs
Training done; evaluating likelihood on full data:
Epoch None Iter 0, test loss 0.2920 nats / 0.4212 bits
Epoch None Iter 500, test loss 0.0041 nats / 0.0059 bits
Epoch None Iter 1000, test loss 0.0099 nats / 0.0143 bits
Epoch None Iter 1500, test loss 0.0121 nats / 0.0175 bits
Epoch None Iter 2000, test loss 0.1770 nats / 0.2554 bits
Epoch None Iter 2500, test loss 0.0046 nats / 0.0066 bits
Epoch None Iter 3000, test loss 0.0094 nats / 0.0136 bits
Epoch None Iter 3500, test loss 0.0101 nats / 0.0146 bits
Epoch None Iter 4000, test loss 0.0010 nats / 0.0015 bits
Epoch None Iter 4500, test loss 0.3167 nats / 0.4570 bits
Epoch None Iter 5000, test loss 0.0084 nats / 0.0122 bits
Epoch None Iter 5500, test loss 0.0100 nats / 0.0144 bits
Epoch None Iter 6000, test loss 0.0018 nats / 0.0026 bits
Epoch None Iter 6500, test loss 0.0045 nats / 0.0065 bits
Epoch None Iter 7000, test loss 0.0367 nats / 0.0529 bits
Saved to:
models/dmv-11.4MB-model0.057-data19.381-transformer-blocks4-model256-ff512-heads32-use_flash_attnTrue-posEmb-gelu-20epochs-seed0.pt
Device cuda
Loading csv... done, took 6.4s
Parsing... done, took 5.1s
Entropy of DMV([Column(Record Type, distribution_size=8), Column(Registration Class, distribution_size=72), Column(State, distribution_size=79), Column(County, distribution_size=64), Column(Body Type, distribution_size=59), Column(Fuel Type, distribution_size=10), Column(Reg Valid Date, distribution_size=2884), Column(Color, distribution_size=222), Column(Scofflaw Indicator, distribution_size=3), Column(Suspension Indicator, distribution_size=3), Column(Revocation Indicator, distribution_size=3)]): 19.3808 bits
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7389597 entries, 0 to 7389596
Data columns (total 11 columns):
 #   Column                Dtype         
---  ------                -----         
 0   Record Type           object        
 1   Registration Class    object        
 2   State                 object        
 3   County                object        
 4   Body Type             object        
 5   Fuel Type             object        
 6   Reg Valid Date        datetime64[ns]
 7   Color                 object        
 8   Scofflaw Indicator    object        
 9   Suspension Indicator  object        
 10  Revocation Indicator  object        
dtypes: datetime64[ns](1), object(10)
memory usage: 620.2+ MB
None
MASK_SCHEME 0
ordering [ 0  1  2  3  4  5  6  7  8  9 10]
using orig mask
 tensor([[ True, False, False, False, False, False, False, False, False, False,
         False],
        [ True,  True, False, False, False, False, False, False, False, False,
         False],
        [ True,  True,  True, False, False, False, False, False, False, False,
         False],
        [ True,  True,  True,  True, False, False, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True, False, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True, False, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True, False, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True, False, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True]])
Number of model parameters: 2983936 (~= 11.4MB)
Transformer(
  (blocks): Sequential(
    (0): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=256, out_features=768, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (1): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=256, out_features=768, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (2): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=256, out_features=768, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (3): Block(
      (mlp): Sequential(
        (0): Conv1d()
        (1): GeLU()
        (2): Conv1d()
      )
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (attn): FlashMHA(
        (Wqkv): Linear(in_features=256, out_features=768, bias=True)
        (inner_attn): FlashAttention()
        (out_proj): Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (norm): LayerNorm()
  (embeddings): ModuleList(
    (0): Embedding(8, 256)
    (1): Embedding(72, 256)
    (2): Embedding(79, 256)
    (3): Embedding(64, 256)
    (4): Embedding(59, 256)
    (5): Embedding(10, 256)
    (6): Embedding(2884, 256)
    (7): Embedding(222, 256)
    (8): Embedding(3, 256)
    (9): Embedding(3, 256)
    (10): Embedding(3, 256)
  )
  (pos_embeddings): Embedding(11, 256)
)
Discretizing table... done, took 4.8s
Epoch 0 Iter 0, train entropy gap 36.4531 bits (loss 55.834, data 19.381) 
Epoch 0 Iter 200, train entropy gap 28.9947 bits (loss 48.376, data 19.381) 
Epoch 0 Iter 400, train entropy gap 14.4403 bits (loss 33.821, data 19.381) 
Epoch 0 Iter 600, train entropy gap 7.4021 bits (loss 26.783, data 19.381) 
Epoch 0 Iter 800, train entropy gap 3.7662 bits (loss 23.147, data 19.381) 
Epoch 0 Iter 1000, train entropy gap 2.4528 bits (loss 21.834, data 19.381) 
Epoch 0 Iter 1200, train entropy gap 1.8316 bits (loss 21.212, data 19.381) 
Epoch 0 Iter 1400, train entropy gap 1.4048 bits (loss 20.786, data 19.381) 
Epoch 0 Iter 1600, train entropy gap 1.3104 bits (loss 20.691, data 19.381) 
Epoch 0 Iter 1800, train entropy gap 1.2596 bits (loss 20.640, data 19.381) 
Epoch 0 Iter 2000, train entropy gap 1.1111 bits (loss 20.492, data 19.381) 
Epoch 0 Iter 2200, train entropy gap 1.0884 bits (loss 20.469, data 19.381) 
Epoch 0 Iter 2400, train entropy gap 1.0569 bits (loss 20.438, data 19.381) 
Epoch 0 Iter 2600, train entropy gap 1.0907 bits (loss 20.472, data 19.381) 
Epoch 0 Iter 2800, train entropy gap 1.1688 bits (loss 20.550, data 19.381) 
Epoch 0 Iter 3000, train entropy gap 1.1974 bits (loss 20.578, data 19.381) 
Epoch 0 Iter 3200, train entropy gap 1.2371 bits (loss 20.618, data 19.381) 
Epoch 0 Iter 3400, train entropy gap 1.0333 bits (loss 20.414, data 19.381) 
Epoch 0 Iter 3600, train entropy gap 1.2309 bits (loss 20.612, data 19.381) 
Epoch 0 Iter 3800, train entropy gap 0.8744 bits (loss 20.255, data 19.381) 
Epoch 0 Iter 4000, train entropy gap 0.9750 bits (loss 20.356, data 19.381) 
Epoch 0 Iter 4200, train entropy gap 0.9436 bits (loss 20.324, data 19.381) 
Epoch 0 Iter 4400, train entropy gap 0.9291 bits (loss 20.310, data 19.381) 
Epoch 0 Iter 4600, train entropy gap 0.7466 bits (loss 20.127, data 19.381) 
Epoch 0 Iter 4800, train entropy gap 0.9753 bits (loss 20.356, data 19.381) 
Epoch 0 Iter 5000, train entropy gap 1.0718 bits (loss 20.453, data 19.381) 
Epoch 0 Iter 5200, train entropy gap 0.9103 bits (loss 20.291, data 19.381) 
Epoch 0 Iter 5400, train entropy gap 0.9809 bits (loss 20.362, data 19.381) 
Epoch 0 Iter 5600, train entropy gap 0.8741 bits (loss 20.255, data 19.381) 
Epoch 0 Iter 5800, train entropy gap 1.1812 bits (loss 20.562, data 19.381) 
Epoch 0 Iter 6000, train entropy gap 1.0200 bits (loss 20.401, data 19.381) 
Epoch 0 Iter 6200, train entropy gap 0.9123 bits (loss 20.293, data 19.381) 
Epoch 0 Iter 6400, train entropy gap 0.7290 bits (loss 20.110, data 19.381) 
Epoch 0 Iter 6600, train entropy gap 0.9856 bits (loss 20.366, data 19.381) 
Epoch 0 Iter 6800, train entropy gap 1.0888 bits (loss 20.470, data 19.381) 
Epoch 0 Iter 7000, train entropy gap 0.9393 bits (loss 20.320, data 19.381) 
Epoch 0 Iter 7200, train entropy gap 0.8884 bits (loss 20.269, data 19.381) 
epoch 0 train loss 15.5247 nats / 22.3975 bits
time since start: 170.8 secs
Epoch 1 Iter 0, train entropy gap 1.0703 bits (loss 20.451, data 19.381) 
Epoch 1 Iter 200, train entropy gap 0.9259 bits (loss 20.307, data 19.381) 
Epoch 1 Iter 400, train entropy gap 0.8618 bits (loss 20.243, data 19.381) 
Epoch 1 Iter 600, train entropy gap 0.8225 bits (loss 20.203, data 19.381) 
Epoch 1 Iter 800, train entropy gap 0.7831 bits (loss 20.164, data 19.381) 
Epoch 1 Iter 1000, train entropy gap 0.8984 bits (loss 20.279, data 19.381) 
Epoch 1 Iter 1200, train entropy gap 0.8493 bits (loss 20.230, data 19.381) 
Epoch 1 Iter 1400, train entropy gap 0.9466 bits (loss 20.327, data 19.381) 
Epoch 1 Iter 1600, train entropy gap 1.0493 bits (loss 20.430, data 19.381) 
Epoch 1 Iter 1800, train entropy gap 0.7087 bits (loss 20.090, data 19.381) 
Epoch 1 Iter 2000, train entropy gap 1.0424 bits (loss 20.423, data 19.381) 
Epoch 1 Iter 2200, train entropy gap 0.8040 bits (loss 20.185, data 19.381) 
Epoch 1 Iter 2400, train entropy gap 0.8773 bits (loss 20.258, data 19.381) 
Epoch 1 Iter 2600, train entropy gap 0.6913 bits (loss 20.072, data 19.381) 
Epoch 1 Iter 2800, train entropy gap 1.1323 bits (loss 20.513, data 19.381) 
Epoch 1 Iter 3000, train entropy gap 0.8808 bits (loss 20.262, data 19.381) 
Epoch 1 Iter 3200, train entropy gap 0.8096 bits (loss 20.190, data 19.381) 
Epoch 1 Iter 3400, train entropy gap 0.7730 bits (loss 20.154, data 19.381) 
Epoch 1 Iter 3600, train entropy gap 0.8227 bits (loss 20.204, data 19.381) 
Epoch 1 Iter 3800, train entropy gap 0.9522 bits (loss 20.333, data 19.381) 
Epoch 1 Iter 4000, train entropy gap 1.0254 bits (loss 20.406, data 19.381) 
Epoch 1 Iter 4200, train entropy gap 0.9832 bits (loss 20.364, data 19.381) 
Epoch 1 Iter 4400, train entropy gap 0.9245 bits (loss 20.305, data 19.381) 
Epoch 1 Iter 4600, train entropy gap 0.9974 bits (loss 20.378, data 19.381) 
Epoch 1 Iter 4800, train entropy gap 0.8644 bits (loss 20.245, data 19.381) 
Epoch 1 Iter 5000, train entropy gap 0.9548 bits (loss 20.336, data 19.381) 
Epoch 1 Iter 5200, train entropy gap 0.6730 bits (loss 20.054, data 19.381) 
Epoch 1 Iter 5400, train entropy gap 0.8788 bits (loss 20.260, data 19.381) 
Epoch 1 Iter 5600, train entropy gap 0.9078 bits (loss 20.289, data 19.381) 
Epoch 1 Iter 5800, train entropy gap 0.8413 bits (loss 20.222, data 19.381) 
Epoch 1 Iter 6000, train entropy gap 0.9418 bits (loss 20.323, data 19.381) 
Epoch 1 Iter 6200, train entropy gap 0.6097 bits (loss 19.991, data 19.381) 
Epoch 1 Iter 6400, train entropy gap 0.7747 bits (loss 20.156, data 19.381) 
Epoch 1 Iter 6600, train entropy gap 0.8421 bits (loss 20.223, data 19.381) 
Epoch 1 Iter 6800, train entropy gap 0.9700 bits (loss 20.351, data 19.381) 
Epoch 1 Iter 7000, train entropy gap 0.8315 bits (loss 20.212, data 19.381) 
Epoch 1 Iter 7200, train entropy gap 1.0272 bits (loss 20.408, data 19.381) 
epoch 1 train loss 14.0740 nats / 20.3045 bits
time since start: 360.7 secs
Epoch 2 Iter 0, train entropy gap 0.9951 bits (loss 20.376, data 19.381) 
Epoch 2 Iter 200, train entropy gap 0.9042 bits (loss 20.285, data 19.381) 
Epoch 2 Iter 400, train entropy gap 1.0241 bits (loss 20.405, data 19.381) 
Epoch 2 Iter 600, train entropy gap 0.8511 bits (loss 20.232, data 19.381) 
Epoch 2 Iter 800, train entropy gap 0.8743 bits (loss 20.255, data 19.381) 
Epoch 2 Iter 1000, train entropy gap 0.8160 bits (loss 20.197, data 19.381) 
Epoch 2 Iter 1200, train entropy gap 0.9050 bits (loss 20.286, data 19.381) 
Epoch 2 Iter 1400, train entropy gap 0.9572 bits (loss 20.338, data 19.381) 
Epoch 2 Iter 1600, train entropy gap 0.9372 bits (loss 20.318, data 19.381) 
Epoch 2 Iter 1800, train entropy gap 0.8437 bits (loss 20.225, data 19.381) 
Epoch 2 Iter 2000, train entropy gap 0.8728 bits (loss 20.254, data 19.381) 
Epoch 2 Iter 2200, train entropy gap 1.0040 bits (loss 20.385, data 19.381) 
Epoch 2 Iter 2400, train entropy gap 1.0152 bits (loss 20.396, data 19.381) 
Epoch 2 Iter 2600, train entropy gap 0.8055 bits (loss 20.186, data 19.381) 
Epoch 2 Iter 2800, train entropy gap 1.1232 bits (loss 20.504, data 19.381) 
Epoch 2 Iter 3000, train entropy gap 0.8360 bits (loss 20.217, data 19.381) 
Epoch 2 Iter 3200, train entropy gap 0.9304 bits (loss 20.311, data 19.381) 
Epoch 2 Iter 3400, train entropy gap 0.9728 bits (loss 20.354, data 19.381) 
Epoch 2 Iter 3600, train entropy gap 0.9873 bits (loss 20.368, data 19.381) 
Epoch 2 Iter 3800, train entropy gap 0.8365 bits (loss 20.217, data 19.381) 
Epoch 2 Iter 4000, train entropy gap 0.9763 bits (loss 20.357, data 19.381) 
Epoch 2 Iter 4200, train entropy gap 0.9502 bits (loss 20.331, data 19.381) 
Epoch 2 Iter 4400, train entropy gap 0.6956 bits (loss 20.076, data 19.381) 
Epoch 2 Iter 4600, train entropy gap 0.8363 bits (loss 20.217, data 19.381) 
Epoch 2 Iter 4800, train entropy gap 0.8918 bits (loss 20.273, data 19.381) 
Epoch 2 Iter 5000, train entropy gap 1.1352 bits (loss 20.516, data 19.381) 
Epoch 2 Iter 5200, train entropy gap 0.8671 bits (loss 20.248, data 19.381) 
Epoch 2 Iter 5400, train entropy gap 0.8384 bits (loss 20.219, data 19.381) 
Epoch 2 Iter 5600, train entropy gap 1.0798 bits (loss 20.461, data 19.381) 
Epoch 2 Iter 5800, train entropy gap 0.7916 bits (loss 20.172, data 19.381) 
Epoch 2 Iter 6000, train entropy gap 1.0586 bits (loss 20.439, data 19.381) 
Epoch 2 Iter 6200, train entropy gap 0.8307 bits (loss 20.212, data 19.381) 
Epoch 2 Iter 6400, train entropy gap 0.8062 bits (loss 20.187, data 19.381) 
Epoch 2 Iter 6600, train entropy gap 0.7213 bits (loss 20.102, data 19.381) 
Epoch 2 Iter 6800, train entropy gap 1.0335 bits (loss 20.414, data 19.381) 
Epoch 2 Iter 7000, train entropy gap 0.8587 bits (loss 20.239, data 19.381) 
Epoch 2 Iter 7200, train entropy gap 0.6770 bits (loss 20.058, data 19.381) 
epoch 2 train loss 14.0555 nats / 20.2778 bits
time since start: 550.5 secs
Epoch 3 Iter 0, train entropy gap 1.1208 bits (loss 20.502, data 19.381) 
Epoch 3 Iter 200, train entropy gap 0.8285 bits (loss 20.209, data 19.381) 
Epoch 3 Iter 400, train entropy gap 0.7871 bits (loss 20.168, data 19.381) 
Epoch 3 Iter 600, train entropy gap 1.0478 bits (loss 20.429, data 19.381) 
Epoch 3 Iter 800, train entropy gap 0.8717 bits (loss 20.253, data 19.381) 
Epoch 3 Iter 1000, train entropy gap 0.9331 bits (loss 20.314, data 19.381) 
Epoch 3 Iter 1200, train entropy gap 0.9188 bits (loss 20.300, data 19.381) 
Epoch 3 Iter 1400, train entropy gap 0.8940 bits (loss 20.275, data 19.381) 
Epoch 3 Iter 1600, train entropy gap 0.8053 bits (loss 20.186, data 19.381) 
Epoch 3 Iter 1800, train entropy gap 0.7806 bits (loss 20.161, data 19.381) 
Epoch 3 Iter 2000, train entropy gap 0.8936 bits (loss 20.274, data 19.381) 
Epoch 3 Iter 2200, train entropy gap 1.0100 bits (loss 20.391, data 19.381) 
Epoch 3 Iter 2400, train entropy gap 0.8654 bits (loss 20.246, data 19.381) 
Epoch 3 Iter 2600, train entropy gap 0.7616 bits (loss 20.142, data 19.381) 
Epoch 3 Iter 2800, train entropy gap 1.0030 bits (loss 20.384, data 19.381) 
Epoch 3 Iter 3000, train entropy gap 0.7718 bits (loss 20.153, data 19.381) 
Epoch 3 Iter 3200, train entropy gap 0.8330 bits (loss 20.214, data 19.381) 
Epoch 3 Iter 3400, train entropy gap 0.8229 bits (loss 20.204, data 19.381) 
Epoch 3 Iter 3600, train entropy gap 0.7787 bits (loss 20.159, data 19.381) 
Epoch 3 Iter 3800, train entropy gap 0.9819 bits (loss 20.363, data 19.381) 
Epoch 3 Iter 4000, train entropy gap 0.7656 bits (loss 20.146, data 19.381) 
Epoch 3 Iter 4200, train entropy gap 0.9081 bits (loss 20.289, data 19.381) 
Epoch 3 Iter 4400, train entropy gap 0.8240 bits (loss 20.205, data 19.381) 
Epoch 3 Iter 4600, train entropy gap 0.8097 bits (loss 20.191, data 19.381) 
Epoch 3 Iter 4800, train entropy gap 0.9183 bits (loss 20.299, data 19.381) 
Epoch 3 Iter 5000, train entropy gap 0.8005 bits (loss 20.181, data 19.381) 
Epoch 3 Iter 5200, train entropy gap 0.9203 bits (loss 20.301, data 19.381) 
Epoch 3 Iter 5400, train entropy gap 0.7699 bits (loss 20.151, data 19.381) 
Epoch 3 Iter 5600, train entropy gap 0.6778 bits (loss 20.059, data 19.381) 
Epoch 3 Iter 5800, train entropy gap 0.9344 bits (loss 20.315, data 19.381) 
Epoch 3 Iter 6000, train entropy gap 0.7841 bits (loss 20.165, data 19.381) 
Epoch 3 Iter 6200, train entropy gap 0.6918 bits (loss 20.073, data 19.381) 
Epoch 3 Iter 6400, train entropy gap 0.6701 bits (loss 20.051, data 19.381) 
Epoch 3 Iter 6600, train entropy gap 0.8005 bits (loss 20.181, data 19.381) 
Epoch 3 Iter 6800, train entropy gap 0.8315 bits (loss 20.212, data 19.381) 
Epoch 3 Iter 7000, train entropy gap 0.8267 bits (loss 20.208, data 19.381) 
Epoch 3 Iter 7200, train entropy gap 0.8491 bits (loss 20.230, data 19.381) 
epoch 3 train loss 14.0416 nats / 20.2577 bits
time since start: 740.8 secs
Epoch 4 Iter 0, train entropy gap 0.8798 bits (loss 20.261, data 19.381) 
Epoch 4 Iter 200, train entropy gap 0.8614 bits (loss 20.242, data 19.381) 
Epoch 4 Iter 400, train entropy gap 1.0061 bits (loss 20.387, data 19.381) 
Epoch 4 Iter 600, train entropy gap 0.9047 bits (loss 20.286, data 19.381) 
Epoch 4 Iter 800, train entropy gap 0.8377 bits (loss 20.219, data 19.381) 
Epoch 4 Iter 1000, train entropy gap 0.7435 bits (loss 20.124, data 19.381) 
Epoch 4 Iter 1200, train entropy gap 0.8649 bits (loss 20.246, data 19.381) 
Epoch 4 Iter 1400, train entropy gap 0.8829 bits (loss 20.264, data 19.381) 
Epoch 4 Iter 1600, train entropy gap 0.9759 bits (loss 20.357, data 19.381) 
Epoch 4 Iter 1800, train entropy gap 1.0175 bits (loss 20.398, data 19.381) 
Epoch 4 Iter 2000, train entropy gap 0.8749 bits (loss 20.256, data 19.381) 
Epoch 4 Iter 2200, train entropy gap 0.7825 bits (loss 20.163, data 19.381) 
Epoch 4 Iter 2400, train entropy gap 1.0872 bits (loss 20.468, data 19.381) 
Epoch 4 Iter 2600, train entropy gap 0.8898 bits (loss 20.271, data 19.381) 
Epoch 4 Iter 2800, train entropy gap 0.8706 bits (loss 20.251, data 19.381) 
Epoch 4 Iter 3000, train entropy gap 0.7556 bits (loss 20.136, data 19.381) 
Epoch 4 Iter 3200, train entropy gap 0.7331 bits (loss 20.114, data 19.381) 
Epoch 4 Iter 3400, train entropy gap 0.8837 bits (loss 20.265, data 19.381) 
Epoch 4 Iter 3600, train entropy gap 0.7656 bits (loss 20.146, data 19.381) 
Epoch 4 Iter 3800, train entropy gap 1.0596 bits (loss 20.440, data 19.381) 
Epoch 4 Iter 4000, train entropy gap 0.8939 bits (loss 20.275, data 19.381) 
Epoch 4 Iter 4200, train entropy gap 0.7988 bits (loss 20.180, data 19.381) 
Epoch 4 Iter 4400, train entropy gap 0.8340 bits (loss 20.215, data 19.381) 
Epoch 4 Iter 4600, train entropy gap 0.8294 bits (loss 20.210, data 19.381) 
Epoch 4 Iter 4800, train entropy gap 0.7728 bits (loss 20.154, data 19.381) 
Epoch 4 Iter 5000, train entropy gap 0.6987 bits (loss 20.080, data 19.381) 
Epoch 4 Iter 5200, train entropy gap 0.9240 bits (loss 20.305, data 19.381) 
Epoch 4 Iter 5400, train entropy gap 0.7122 bits (loss 20.093, data 19.381) 
Epoch 4 Iter 5600, train entropy gap 0.9071 bits (loss 20.288, data 19.381) 
Epoch 4 Iter 5800, train entropy gap 0.8915 bits (loss 20.272, data 19.381) 
Epoch 4 Iter 6000, train entropy gap 0.9403 bits (loss 20.321, data 19.381) 
Epoch 4 Iter 6200, train entropy gap 0.9232 bits (loss 20.304, data 19.381) 
Epoch 4 Iter 6400, train entropy gap 0.6832 bits (loss 20.064, data 19.381) 
Epoch 4 Iter 6600, train entropy gap 0.7113 bits (loss 20.092, data 19.381) 
Epoch 4 Iter 6800, train entropy gap 0.9329 bits (loss 20.314, data 19.381) 
Epoch 4 Iter 7000, train entropy gap 0.7704 bits (loss 20.151, data 19.381) 
Epoch 4 Iter 7200, train entropy gap 0.8433 bits (loss 20.224, data 19.381) 
epoch 4 train loss 14.0233 nats / 20.2313 bits
time since start: 930.1 secs
Epoch 5 Iter 0, train entropy gap 0.6841 bits (loss 20.065, data 19.381) 
Epoch 5 Iter 200, train entropy gap 0.7821 bits (loss 20.163, data 19.381) 
Epoch 5 Iter 400, train entropy gap 0.6601 bits (loss 20.041, data 19.381) 
Epoch 5 Iter 600, train entropy gap 0.8884 bits (loss 20.269, data 19.381) 
Epoch 5 Iter 800, train entropy gap 0.7628 bits (loss 20.144, data 19.381) 
Epoch 5 Iter 1000, train entropy gap 0.8915 bits (loss 20.272, data 19.381) 
Epoch 5 Iter 1200, train entropy gap 0.6683 bits (loss 20.049, data 19.381) 
Epoch 5 Iter 1400, train entropy gap 0.8327 bits (loss 20.214, data 19.381) 
Epoch 5 Iter 1600, train entropy gap 0.5731 bits (loss 19.954, data 19.381) 
Epoch 5 Iter 1800, train entropy gap 0.8409 bits (loss 20.222, data 19.381) 
Epoch 5 Iter 2000, train entropy gap 0.8533 bits (loss 20.234, data 19.381) 
Epoch 5 Iter 2200, train entropy gap 0.7272 bits (loss 20.108, data 19.381) 
Epoch 5 Iter 2400, train entropy gap 0.8809 bits (loss 20.262, data 19.381) 
Epoch 5 Iter 2600, train entropy gap 0.8337 bits (loss 20.215, data 19.381) 
Epoch 5 Iter 2800, train entropy gap 0.6169 bits (loss 19.998, data 19.381) 
Epoch 5 Iter 3000, train entropy gap 0.6533 bits (loss 20.034, data 19.381) 
Epoch 5 Iter 3200, train entropy gap 0.7732 bits (loss 20.154, data 19.381) 
Epoch 5 Iter 3400, train entropy gap 1.0109 bits (loss 20.392, data 19.381) 
Epoch 5 Iter 3600, train entropy gap 0.9690 bits (loss 20.350, data 19.381) 
Epoch 5 Iter 3800, train entropy gap 0.6689 bits (loss 20.050, data 19.381) 
Epoch 5 Iter 4000, train entropy gap 0.6532 bits (loss 20.034, data 19.381) 
Epoch 5 Iter 4200, train entropy gap 0.8212 bits (loss 20.202, data 19.381) 
Epoch 5 Iter 4400, train entropy gap 0.8400 bits (loss 20.221, data 19.381) 
Epoch 5 Iter 4600, train entropy gap 0.9259 bits (loss 20.307, data 19.381) 
Epoch 5 Iter 4800, train entropy gap 0.8089 bits (loss 20.190, data 19.381) 
Epoch 5 Iter 5000, train entropy gap 1.0335 bits (loss 20.414, data 19.381) 
Epoch 5 Iter 5200, train entropy gap 0.7783 bits (loss 20.159, data 19.381) 
Epoch 5 Iter 5400, train entropy gap 0.8027 bits (loss 20.183, data 19.381) 
Epoch 5 Iter 5600, train entropy gap 0.8668 bits (loss 20.248, data 19.381) 
Epoch 5 Iter 5800, train entropy gap 0.8372 bits (loss 20.218, data 19.381) 
Epoch 5 Iter 6000, train entropy gap 0.8091 bits (loss 20.190, data 19.381) 
Epoch 5 Iter 6200, train entropy gap 0.7862 bits (loss 20.167, data 19.381) 
Epoch 5 Iter 6400, train entropy gap 0.9404 bits (loss 20.321, data 19.381) 
Epoch 5 Iter 6600, train entropy gap 1.0743 bits (loss 20.455, data 19.381) 
Epoch 5 Iter 6800, train entropy gap 0.7347 bits (loss 20.116, data 19.381) 
Epoch 5 Iter 7000, train entropy gap 0.7511 bits (loss 20.132, data 19.381) 
Epoch 5 Iter 7200, train entropy gap 0.6769 bits (loss 20.058, data 19.381) 
epoch 5 train loss 14.0127 nats / 20.2160 bits
time since start: 1118.7 secs
Epoch 6 Iter 0, train entropy gap 0.9281 bits (loss 20.309, data 19.381) 
Epoch 6 Iter 200, train entropy gap 0.8575 bits (loss 20.238, data 19.381) 
Epoch 6 Iter 400, train entropy gap 0.6357 bits (loss 20.017, data 19.381) 
Epoch 6 Iter 600, train entropy gap 0.9435 bits (loss 20.324, data 19.381) 
Epoch 6 Iter 800, train entropy gap 0.8316 bits (loss 20.212, data 19.381) 
Epoch 6 Iter 1000, train entropy gap 0.7820 bits (loss 20.163, data 19.381) 
Epoch 6 Iter 1200, train entropy gap 0.9814 bits (loss 20.362, data 19.381) 
Epoch 6 Iter 1400, train entropy gap 0.8525 bits (loss 20.233, data 19.381) 
Epoch 6 Iter 1600, train entropy gap 0.7423 bits (loss 20.123, data 19.381) 
Epoch 6 Iter 1800, train entropy gap 0.7437 bits (loss 20.124, data 19.381) 
Epoch 6 Iter 2000, train entropy gap 0.8362 bits (loss 20.217, data 19.381) 
Epoch 6 Iter 2200, train entropy gap 0.8241 bits (loss 20.205, data 19.381) 
Epoch 6 Iter 2400, train entropy gap 0.7228 bits (loss 20.104, data 19.381) 
Epoch 6 Iter 2600, train entropy gap 0.7982 bits (loss 20.179, data 19.381) 
Epoch 6 Iter 2800, train entropy gap 0.8263 bits (loss 20.207, data 19.381) 
Epoch 6 Iter 3000, train entropy gap 0.7427 bits (loss 20.123, data 19.381) 
Epoch 6 Iter 3200, train entropy gap 0.8233 bits (loss 20.204, data 19.381) 
Epoch 6 Iter 3400, train entropy gap 1.0669 bits (loss 20.448, data 19.381) 
Epoch 6 Iter 3600, train entropy gap 0.7092 bits (loss 20.090, data 19.381) 
Epoch 6 Iter 3800, train entropy gap 1.0154 bits (loss 20.396, data 19.381) 
Epoch 6 Iter 4000, train entropy gap 0.8935 bits (loss 20.274, data 19.381) 
Epoch 6 Iter 4200, train entropy gap 0.7982 bits (loss 20.179, data 19.381) 
Epoch 6 Iter 4400, train entropy gap 0.9971 bits (loss 20.378, data 19.381) 
Epoch 6 Iter 4600, train entropy gap 0.8090 bits (loss 20.190, data 19.381) 
Epoch 6 Iter 4800, train entropy gap 0.9704 bits (loss 20.351, data 19.381) 
Epoch 6 Iter 5000, train entropy gap 0.7534 bits (loss 20.134, data 19.381) 
Epoch 6 Iter 5200, train entropy gap 0.7218 bits (loss 20.103, data 19.381) 
Epoch 6 Iter 5400, train entropy gap 0.7870 bits (loss 20.168, data 19.381) 
Epoch 6 Iter 5600, train entropy gap 0.9700 bits (loss 20.351, data 19.381) 
Epoch 6 Iter 5800, train entropy gap 0.6745 bits (loss 20.055, data 19.381) 
Epoch 6 Iter 6000, train entropy gap 0.6945 bits (loss 20.075, data 19.381) 
Epoch 6 Iter 6200, train entropy gap 0.9785 bits (loss 20.359, data 19.381) 
Epoch 6 Iter 6400, train entropy gap 0.8504 bits (loss 20.231, data 19.381) 
Epoch 6 Iter 6600, train entropy gap 0.8810 bits (loss 20.262, data 19.381) 
Epoch 6 Iter 6800, train entropy gap 0.7691 bits (loss 20.150, data 19.381) 
Epoch 6 Iter 7000, train entropy gap 0.7370 bits (loss 20.118, data 19.381) 
Epoch 6 Iter 7200, train entropy gap 0.8639 bits (loss 20.245, data 19.381) 
epoch 6 train loss 14.0047 nats / 20.2045 bits
time since start: 1307.9 secs
Epoch 7 Iter 0, train entropy gap 0.8169 bits (loss 20.198, data 19.381) 
Epoch 7 Iter 200, train entropy gap 0.7597 bits (loss 20.140, data 19.381) 
Epoch 7 Iter 400, train entropy gap 0.6777 bits (loss 20.058, data 19.381) 
Epoch 7 Iter 600, train entropy gap 0.7119 bits (loss 20.093, data 19.381) 
Epoch 7 Iter 800, train entropy gap 0.8514 bits (loss 20.232, data 19.381) 
Epoch 7 Iter 1000, train entropy gap 0.6647 bits (loss 20.046, data 19.381) 
Epoch 7 Iter 1200, train entropy gap 0.7096 bits (loss 20.090, data 19.381) 
Epoch 7 Iter 1400, train entropy gap 0.7875 bits (loss 20.168, data 19.381) 
Epoch 7 Iter 1600, train entropy gap 0.8467 bits (loss 20.228, data 19.381) 
Epoch 7 Iter 1800, train entropy gap 0.6944 bits (loss 20.075, data 19.381) 
Epoch 7 Iter 2000, train entropy gap 0.8539 bits (loss 20.235, data 19.381) 
Epoch 7 Iter 2200, train entropy gap 0.8436 bits (loss 20.224, data 19.381) 
Epoch 7 Iter 2400, train entropy gap 0.6868 bits (loss 20.068, data 19.381) 
Epoch 7 Iter 2600, train entropy gap 0.8449 bits (loss 20.226, data 19.381) 
Epoch 7 Iter 2800, train entropy gap 0.7807 bits (loss 20.161, data 19.381) 
Epoch 7 Iter 3000, train entropy gap 0.7226 bits (loss 20.103, data 19.381) 
Epoch 7 Iter 3200, train entropy gap 0.6138 bits (loss 19.995, data 19.381) 
Epoch 7 Iter 3400, train entropy gap 0.7070 bits (loss 20.088, data 19.381) 
Epoch 7 Iter 3600, train entropy gap 1.0470 bits (loss 20.428, data 19.381) 
Epoch 7 Iter 3800, train entropy gap 0.8300 bits (loss 20.211, data 19.381) 
Epoch 7 Iter 4000, train entropy gap 0.7809 bits (loss 20.162, data 19.381) 
Epoch 7 Iter 4200, train entropy gap 0.9172 bits (loss 20.298, data 19.381) 
Epoch 7 Iter 4400, train entropy gap 0.8117 bits (loss 20.192, data 19.381) 
Epoch 7 Iter 4600, train entropy gap 0.6933 bits (loss 20.074, data 19.381) 
Epoch 7 Iter 4800, train entropy gap 1.0318 bits (loss 20.413, data 19.381) 
Epoch 7 Iter 5000, train entropy gap 0.9187 bits (loss 20.299, data 19.381) 
Epoch 7 Iter 5200, train entropy gap 0.6329 bits (loss 20.014, data 19.381) 
Epoch 7 Iter 5400, train entropy gap 0.7653 bits (loss 20.146, data 19.381) 
Epoch 7 Iter 5600, train entropy gap 0.8389 bits (loss 20.220, data 19.381) 
Epoch 7 Iter 5800, train entropy gap 1.0036 bits (loss 20.384, data 19.381) 
Epoch 7 Iter 6000, train entropy gap 0.7043 bits (loss 20.085, data 19.381) 
Epoch 7 Iter 6200, train entropy gap 0.8301 bits (loss 20.211, data 19.381) 
Epoch 7 Iter 6400, train entropy gap 0.8195 bits (loss 20.200, data 19.381) 
Epoch 7 Iter 6600, train entropy gap 0.7007 bits (loss 20.081, data 19.381) 
Epoch 7 Iter 6800, train entropy gap 0.8925 bits (loss 20.273, data 19.381) 
Epoch 7 Iter 7000, train entropy gap 0.5979 bits (loss 19.979, data 19.381) 
Epoch 7 Iter 7200, train entropy gap 0.8578 bits (loss 20.239, data 19.381) 
epoch 7 train loss 13.9981 nats / 20.1950 bits
time since start: 1497.2 secs
Epoch 8 Iter 0, train entropy gap 0.9306 bits (loss 20.311, data 19.381) 
Epoch 8 Iter 200, train entropy gap 0.8623 bits (loss 20.243, data 19.381) 
Epoch 8 Iter 400, train entropy gap 0.6905 bits (loss 20.071, data 19.381) 
Epoch 8 Iter 600, train entropy gap 0.8151 bits (loss 20.196, data 19.381) 
Epoch 8 Iter 800, train entropy gap 0.7757 bits (loss 20.156, data 19.381) 
Epoch 8 Iter 1000, train entropy gap 0.7661 bits (loss 20.147, data 19.381) 
Epoch 8 Iter 1200, train entropy gap 0.8238 bits (loss 20.205, data 19.381) 
Epoch 8 Iter 1400, train entropy gap 0.8732 bits (loss 20.254, data 19.381) 
Epoch 8 Iter 1600, train entropy gap 0.8190 bits (loss 20.200, data 19.381) 
Epoch 8 Iter 1800, train entropy gap 0.7719 bits (loss 20.153, data 19.381) 
Epoch 8 Iter 2000, train entropy gap 0.8515 bits (loss 20.232, data 19.381) 
Epoch 8 Iter 2200, train entropy gap 0.7150 bits (loss 20.096, data 19.381) 
Epoch 8 Iter 2400, train entropy gap 0.9857 bits (loss 20.367, data 19.381) 
Epoch 8 Iter 2600, train entropy gap 0.8928 bits (loss 20.274, data 19.381) 
Epoch 8 Iter 2800, train entropy gap 0.7450 bits (loss 20.126, data 19.381) 
Epoch 8 Iter 3000, train entropy gap 0.7962 bits (loss 20.177, data 19.381) 
Epoch 8 Iter 3200, train entropy gap 0.4734 bits (loss 19.854, data 19.381) 
Epoch 8 Iter 3400, train entropy gap 0.5595 bits (loss 19.940, data 19.381) 
Epoch 8 Iter 3600, train entropy gap 0.7770 bits (loss 20.158, data 19.381) 
Epoch 8 Iter 3800, train entropy gap 0.5894 bits (loss 19.970, data 19.381) 
Epoch 8 Iter 4000, train entropy gap 0.8707 bits (loss 20.252, data 19.381) 
Epoch 8 Iter 4200, train entropy gap 0.9253 bits (loss 20.306, data 19.381) 
Epoch 8 Iter 4400, train entropy gap 0.7492 bits (loss 20.130, data 19.381) 
Epoch 8 Iter 4600, train entropy gap 0.8021 bits (loss 20.183, data 19.381) 
Epoch 8 Iter 4800, train entropy gap 0.9337 bits (loss 20.314, data 19.381) 
Epoch 8 Iter 5000, train entropy gap 0.7569 bits (loss 20.138, data 19.381) 
Epoch 8 Iter 5200, train entropy gap 0.8374 bits (loss 20.218, data 19.381) 
Epoch 8 Iter 5400, train entropy gap 0.8568 bits (loss 20.238, data 19.381) 
Epoch 8 Iter 5600, train entropy gap 1.0050 bits (loss 20.386, data 19.381) 
Epoch 8 Iter 5800, train entropy gap 0.8304 bits (loss 20.211, data 19.381) 
Epoch 8 Iter 6000, train entropy gap 1.1345 bits (loss 20.515, data 19.381) 
Epoch 8 Iter 6200, train entropy gap 0.7202 bits (loss 20.101, data 19.381) 
Epoch 8 Iter 6400, train entropy gap 0.6911 bits (loss 20.072, data 19.381) 
Epoch 8 Iter 6600, train entropy gap 0.7877 bits (loss 20.168, data 19.381) 
Epoch 8 Iter 6800, train entropy gap 0.7449 bits (loss 20.126, data 19.381) 
Epoch 8 Iter 7000, train entropy gap 0.7880 bits (loss 20.169, data 19.381) 
Epoch 8 Iter 7200, train entropy gap 0.8921 bits (loss 20.273, data 19.381) 
epoch 8 train loss 13.9925 nats / 20.1869 bits
time since start: 1686.7 secs
Epoch 9 Iter 0, train entropy gap 0.7381 bits (loss 20.119, data 19.381) 
Epoch 9 Iter 200, train entropy gap 0.8877 bits (loss 20.269, data 19.381) 
Epoch 9 Iter 400, train entropy gap 0.6923 bits (loss 20.073, data 19.381) 
Epoch 9 Iter 600, train entropy gap 0.7999 bits (loss 20.181, data 19.381) 
Epoch 9 Iter 800, train entropy gap 0.8226 bits (loss 20.203, data 19.381) 
Epoch 9 Iter 1000, train entropy gap 0.8367 bits (loss 20.217, data 19.381) 
Epoch 9 Iter 1200, train entropy gap 0.7999 bits (loss 20.181, data 19.381) 
Epoch 9 Iter 1400, train entropy gap 0.6826 bits (loss 20.063, data 19.381) 
Epoch 9 Iter 1600, train entropy gap 0.5635 bits (loss 19.944, data 19.381) 
Epoch 9 Iter 1800, train entropy gap 0.7563 bits (loss 20.137, data 19.381) 
Epoch 9 Iter 2000, train entropy gap 0.7879 bits (loss 20.169, data 19.381) 
Epoch 9 Iter 2200, train entropy gap 0.8414 bits (loss 20.222, data 19.381) 
Epoch 9 Iter 2400, train entropy gap 0.8225 bits (loss 20.203, data 19.381) 
Epoch 9 Iter 2600, train entropy gap 0.9114 bits (loss 20.292, data 19.381) 
Epoch 9 Iter 2800, train entropy gap 0.7327 bits (loss 20.113, data 19.381) 
Epoch 9 Iter 3000, train entropy gap 0.7271 bits (loss 20.108, data 19.381) 
Epoch 9 Iter 3200, train entropy gap 0.9931 bits (loss 20.374, data 19.381) 
Epoch 9 Iter 3400, train entropy gap 0.8127 bits (loss 20.193, data 19.381) 
Epoch 9 Iter 3600, train entropy gap 0.6171 bits (loss 19.998, data 19.381) 
Epoch 9 Iter 3800, train entropy gap 0.8896 bits (loss 20.270, data 19.381) 
Epoch 9 Iter 4000, train entropy gap 0.9287 bits (loss 20.309, data 19.381) 
Epoch 9 Iter 4200, train entropy gap 1.0764 bits (loss 20.457, data 19.381) 
Epoch 9 Iter 4400, train entropy gap 0.8452 bits (loss 20.226, data 19.381) 
Epoch 9 Iter 4600, train entropy gap 0.8787 bits (loss 20.259, data 19.381) 
Epoch 9 Iter 4800, train entropy gap 0.8703 bits (loss 20.251, data 19.381) 
Epoch 9 Iter 5000, train entropy gap 0.7704 bits (loss 20.151, data 19.381) 
Epoch 9 Iter 5200, train entropy gap 0.9901 bits (loss 20.371, data 19.381) 
Epoch 9 Iter 5400, train entropy gap 0.9872 bits (loss 20.368, data 19.381) 
Epoch 9 Iter 5600, train entropy gap 0.8785 bits (loss 20.259, data 19.381) 
Epoch 9 Iter 5800, train entropy gap 0.7087 bits (loss 20.090, data 19.381) 
Epoch 9 Iter 6000, train entropy gap 0.7675 bits (loss 20.148, data 19.381) 
Epoch 9 Iter 6200, train entropy gap 0.7778 bits (loss 20.159, data 19.381) 
Epoch 9 Iter 6400, train entropy gap 0.9196 bits (loss 20.300, data 19.381) 
Epoch 9 Iter 6600, train entropy gap 0.8565 bits (loss 20.237, data 19.381) 
Epoch 9 Iter 6800, train entropy gap 0.8994 bits (loss 20.280, data 19.381) 
Epoch 9 Iter 7000, train entropy gap 0.8042 bits (loss 20.185, data 19.381) 
Epoch 9 Iter 7200, train entropy gap 0.7254 bits (loss 20.106, data 19.381) 
epoch 9 train loss 13.9880 nats / 20.1804 bits
time since start: 1876.1 secs
Epoch 10 Iter 0, train entropy gap 0.7806 bits (loss 20.161, data 19.381) 
Epoch 10 Iter 200, train entropy gap 0.7560 bits (loss 20.137, data 19.381) 
Epoch 10 Iter 400, train entropy gap 0.8922 bits (loss 20.273, data 19.381) 
Epoch 10 Iter 600, train entropy gap 0.8159 bits (loss 20.197, data 19.381) 
Epoch 10 Iter 800, train entropy gap 0.8437 bits (loss 20.225, data 19.381) 
Epoch 10 Iter 1000, train entropy gap 0.8155 bits (loss 20.196, data 19.381) 
Epoch 10 Iter 1200, train entropy gap 0.7741 bits (loss 20.155, data 19.381) 
Epoch 10 Iter 1400, train entropy gap 0.6705 bits (loss 20.051, data 19.381) 
Epoch 10 Iter 1600, train entropy gap 0.8222 bits (loss 20.203, data 19.381) 
Epoch 10 Iter 1800, train entropy gap 0.9128 bits (loss 20.294, data 19.381) 
Epoch 10 Iter 2000, train entropy gap 0.8322 bits (loss 20.213, data 19.381) 
Epoch 10 Iter 2200, train entropy gap 0.8226 bits (loss 20.203, data 19.381) 
Epoch 10 Iter 2400, train entropy gap 0.7506 bits (loss 20.131, data 19.381) 
Epoch 10 Iter 2600, train entropy gap 0.7900 bits (loss 20.171, data 19.381) 
Epoch 10 Iter 2800, train entropy gap 0.6866 bits (loss 20.067, data 19.381) 
Epoch 10 Iter 3000, train entropy gap 1.0022 bits (loss 20.383, data 19.381) 
Epoch 10 Iter 3200, train entropy gap 0.9516 bits (loss 20.332, data 19.381) 
Epoch 10 Iter 3400, train entropy gap 1.1213 bits (loss 20.502, data 19.381) 
Epoch 10 Iter 3600, train entropy gap 1.0326 bits (loss 20.413, data 19.381) 
Epoch 10 Iter 3800, train entropy gap 0.7694 bits (loss 20.150, data 19.381) 
Epoch 10 Iter 4000, train entropy gap 0.7745 bits (loss 20.155, data 19.381) 
Epoch 10 Iter 4200, train entropy gap 0.7877 bits (loss 20.169, data 19.381) 
Epoch 10 Iter 4400, train entropy gap 0.9344 bits (loss 20.315, data 19.381) 
Epoch 10 Iter 4600, train entropy gap 0.9759 bits (loss 20.357, data 19.381) 
Epoch 10 Iter 4800, train entropy gap 0.7666 bits (loss 20.147, data 19.381) 
Epoch 10 Iter 5000, train entropy gap 0.7663 bits (loss 20.147, data 19.381) 
Epoch 10 Iter 5200, train entropy gap 0.6907 bits (loss 20.072, data 19.381) 
Epoch 10 Iter 5400, train entropy gap 0.8752 bits (loss 20.256, data 19.381) 
Epoch 10 Iter 5600, train entropy gap 0.7443 bits (loss 20.125, data 19.381) 
Epoch 10 Iter 5800, train entropy gap 0.7524 bits (loss 20.133, data 19.381) 
Epoch 10 Iter 6000, train entropy gap 0.7169 bits (loss 20.098, data 19.381) 
Epoch 10 Iter 6200, train entropy gap 0.6993 bits (loss 20.080, data 19.381) 
Epoch 10 Iter 6400, train entropy gap 0.8677 bits (loss 20.248, data 19.381) 
Epoch 10 Iter 6600, train entropy gap 1.0356 bits (loss 20.416, data 19.381) 
Epoch 10 Iter 6800, train entropy gap 0.9088 bits (loss 20.290, data 19.381) 
Epoch 10 Iter 7000, train entropy gap 0.8004 bits (loss 20.181, data 19.381) 
Epoch 10 Iter 7200, train entropy gap 0.7554 bits (loss 20.136, data 19.381) 
epoch 10 train loss 13.9838 nats / 20.1744 bits
time since start: 2066.4 secs
Epoch 11 Iter 0, train entropy gap 0.7837 bits (loss 20.165, data 19.381) 
Epoch 11 Iter 200, train entropy gap 0.8361 bits (loss 20.217, data 19.381) 
Epoch 11 Iter 400, train entropy gap 0.7811 bits (loss 20.162, data 19.381) 
Epoch 11 Iter 600, train entropy gap 0.7966 bits (loss 20.177, data 19.381) 
Epoch 11 Iter 800, train entropy gap 0.5928 bits (loss 19.974, data 19.381) 
Epoch 11 Iter 1000, train entropy gap 0.5375 bits (loss 19.918, data 19.381) 
Epoch 11 Iter 1200, train entropy gap 0.6199 bits (loss 20.001, data 19.381) 
Epoch 11 Iter 1400, train entropy gap 0.7626 bits (loss 20.143, data 19.381) 
Epoch 11 Iter 1600, train entropy gap 0.6274 bits (loss 20.008, data 19.381) 
Epoch 11 Iter 1800, train entropy gap 0.8692 bits (loss 20.250, data 19.381) 
Epoch 11 Iter 2000, train entropy gap 0.9517 bits (loss 20.332, data 19.381) 
Epoch 11 Iter 2200, train entropy gap 0.7302 bits (loss 20.111, data 19.381) 
Epoch 11 Iter 2400, train entropy gap 0.7141 bits (loss 20.095, data 19.381) 
Epoch 11 Iter 2600, train entropy gap 0.8124 bits (loss 20.193, data 19.381) 
Epoch 11 Iter 2800, train entropy gap 0.7423 bits (loss 20.123, data 19.381) 
Epoch 11 Iter 3000, train entropy gap 1.0089 bits (loss 20.390, data 19.381) 
Epoch 11 Iter 3200, train entropy gap 0.8356 bits (loss 20.216, data 19.381) 
Epoch 11 Iter 3400, train entropy gap 0.8763 bits (loss 20.257, data 19.381) 
Epoch 11 Iter 3600, train entropy gap 0.7706 bits (loss 20.151, data 19.381) 
Epoch 11 Iter 3800, train entropy gap 0.8043 bits (loss 20.185, data 19.381) 
Epoch 11 Iter 4000, train entropy gap 0.9371 bits (loss 20.318, data 19.381) 
Epoch 11 Iter 4200, train entropy gap 0.8509 bits (loss 20.232, data 19.381) 
Epoch 11 Iter 4400, train entropy gap 0.7159 bits (loss 20.097, data 19.381) 
Epoch 11 Iter 4600, train entropy gap 0.7882 bits (loss 20.169, data 19.381) 
Epoch 11 Iter 4800, train entropy gap 0.7282 bits (loss 20.109, data 19.381) 
Epoch 11 Iter 5000, train entropy gap 0.6788 bits (loss 20.060, data 19.381) 
Epoch 11 Iter 5200, train entropy gap 0.7871 bits (loss 20.168, data 19.381) 
Epoch 11 Iter 5400, train entropy gap 0.7858 bits (loss 20.167, data 19.381) 
Epoch 11 Iter 5600, train entropy gap 1.0182 bits (loss 20.399, data 19.381) 
Epoch 11 Iter 5800, train entropy gap 0.8586 bits (loss 20.239, data 19.381) 
Epoch 11 Iter 6000, train entropy gap 0.8162 bits (loss 20.197, data 19.381) 
Epoch 11 Iter 6200, train entropy gap 0.9143 bits (loss 20.295, data 19.381) 
Epoch 11 Iter 6400, train entropy gap 0.7198 bits (loss 20.101, data 19.381) 
Epoch 11 Iter 6600, train entropy gap 0.8668 bits (loss 20.248, data 19.381) 
Epoch 11 Iter 6800, train entropy gap 0.8555 bits (loss 20.236, data 19.381) 
Epoch 11 Iter 7000, train entropy gap 0.6726 bits (loss 20.053, data 19.381) 
Epoch 11 Iter 7200, train entropy gap 0.9968 bits (loss 20.378, data 19.381) 
epoch 11 train loss 13.9842 nats / 20.1749 bits
time since start: 2255.2 secs
Epoch 12 Iter 0, train entropy gap 0.5973 bits (loss 19.978, data 19.381) 
Epoch 12 Iter 200, train entropy gap 0.7874 bits (loss 20.168, data 19.381) 
Epoch 12 Iter 400, train entropy gap 0.7723 bits (loss 20.153, data 19.381) 
Epoch 12 Iter 600, train entropy gap 0.6573 bits (loss 20.038, data 19.381) 
Epoch 12 Iter 800, train entropy gap 0.8697 bits (loss 20.251, data 19.381) 
Epoch 12 Iter 1000, train entropy gap 0.8665 bits (loss 20.247, data 19.381) 
Epoch 12 Iter 1200, train entropy gap 0.6826 bits (loss 20.063, data 19.381) 
Epoch 12 Iter 1400, train entropy gap 0.5296 bits (loss 19.910, data 19.381) 
Epoch 12 Iter 1600, train entropy gap 1.0396 bits (loss 20.420, data 19.381) 
Epoch 12 Iter 1800, train entropy gap 0.7357 bits (loss 20.116, data 19.381) 
Epoch 12 Iter 2000, train entropy gap 0.8192 bits (loss 20.200, data 19.381) 
Epoch 12 Iter 2200, train entropy gap 0.7933 bits (loss 20.174, data 19.381) 
Epoch 12 Iter 2400, train entropy gap 0.9800 bits (loss 20.361, data 19.381) 
Epoch 12 Iter 2600, train entropy gap 0.8223 bits (loss 20.203, data 19.381) 
Epoch 12 Iter 2800, train entropy gap 0.5015 bits (loss 19.882, data 19.381) 
Epoch 12 Iter 3000, train entropy gap 0.5979 bits (loss 19.979, data 19.381) 
Epoch 12 Iter 3200, train entropy gap 0.8511 bits (loss 20.232, data 19.381) 
Epoch 12 Iter 3400, train entropy gap 0.9379 bits (loss 20.319, data 19.381) 
Epoch 12 Iter 3600, train entropy gap 0.8129 bits (loss 20.194, data 19.381) 
Epoch 12 Iter 3800, train entropy gap 0.8938 bits (loss 20.275, data 19.381) 
Epoch 12 Iter 4000, train entropy gap 0.7987 bits (loss 20.180, data 19.381) 
Epoch 12 Iter 4200, train entropy gap 0.6809 bits (loss 20.062, data 19.381) 
Epoch 12 Iter 4400, train entropy gap 0.6679 bits (loss 20.049, data 19.381) 
Epoch 12 Iter 4600, train entropy gap 0.8725 bits (loss 20.253, data 19.381) 
Epoch 12 Iter 4800, train entropy gap 0.7198 bits (loss 20.101, data 19.381) 
Epoch 12 Iter 5000, train entropy gap 0.6785 bits (loss 20.059, data 19.381) 
Epoch 12 Iter 5200, train entropy gap 0.7569 bits (loss 20.138, data 19.381) 
Epoch 12 Iter 5400, train entropy gap 0.7554 bits (loss 20.136, data 19.381) 
Epoch 12 Iter 5600, train entropy gap 0.6358 bits (loss 20.017, data 19.381) 
Epoch 12 Iter 5800, train entropy gap 0.8214 bits (loss 20.202, data 19.381) 
Epoch 12 Iter 6000, train entropy gap 0.5477 bits (loss 19.928, data 19.381) 
Epoch 12 Iter 6200, train entropy gap 0.7317 bits (loss 20.113, data 19.381) 
Epoch 12 Iter 6400, train entropy gap 0.7984 bits (loss 20.179, data 19.381) 
Epoch 12 Iter 6600, train entropy gap 0.6483 bits (loss 20.029, data 19.381) 
Epoch 12 Iter 6800, train entropy gap 0.4520 bits (loss 19.833, data 19.381) 
Epoch 12 Iter 7000, train entropy gap 0.8461 bits (loss 20.227, data 19.381) 
Epoch 12 Iter 7200, train entropy gap 0.7372 bits (loss 20.118, data 19.381) 
epoch 12 train loss 13.9774 nats / 20.1651 bits
time since start: 2444.5 secs
Epoch 13 Iter 0, train entropy gap 0.8402 bits (loss 20.221, data 19.381) 
Epoch 13 Iter 200, train entropy gap 0.7738 bits (loss 20.155, data 19.381) 
Epoch 13 Iter 400, train entropy gap 0.7716 bits (loss 20.152, data 19.381) 
Epoch 13 Iter 600, train entropy gap 0.5744 bits (loss 19.955, data 19.381) 
Epoch 13 Iter 800, train entropy gap 0.7758 bits (loss 20.157, data 19.381) 
Epoch 13 Iter 1000, train entropy gap 0.6744 bits (loss 20.055, data 19.381) 
Epoch 13 Iter 1200, train entropy gap 0.7575 bits (loss 20.138, data 19.381) 
Epoch 13 Iter 1400, train entropy gap 0.7783 bits (loss 20.159, data 19.381) 
Epoch 13 Iter 1600, train entropy gap 0.7886 bits (loss 20.169, data 19.381) 
Epoch 13 Iter 1800, train entropy gap 0.7914 bits (loss 20.172, data 19.381) 
Epoch 13 Iter 2000, train entropy gap 0.5925 bits (loss 19.973, data 19.381) 
Epoch 13 Iter 2200, train entropy gap 0.6123 bits (loss 19.993, data 19.381) 
Epoch 13 Iter 2400, train entropy gap 0.7576 bits (loss 20.138, data 19.381) 
Epoch 13 Iter 2600, train entropy gap 0.8398 bits (loss 20.221, data 19.381) 
Epoch 13 Iter 2800, train entropy gap 0.8120 bits (loss 20.193, data 19.381) 
Epoch 13 Iter 3000, train entropy gap 0.8652 bits (loss 20.246, data 19.381) 
Epoch 13 Iter 3200, train entropy gap 0.5611 bits (loss 19.942, data 19.381) 
Epoch 13 Iter 3400, train entropy gap 0.8289 bits (loss 20.210, data 19.381) 
Epoch 13 Iter 3600, train entropy gap 0.6591 bits (loss 20.040, data 19.381) 
Epoch 13 Iter 3800, train entropy gap 0.7034 bits (loss 20.084, data 19.381) 
Epoch 13 Iter 4000, train entropy gap 0.5638 bits (loss 19.945, data 19.381) 
Epoch 13 Iter 4200, train entropy gap 0.6375 bits (loss 20.018, data 19.381) 
Epoch 13 Iter 4400, train entropy gap 0.8711 bits (loss 20.252, data 19.381) 
Epoch 13 Iter 4600, train entropy gap 0.7747 bits (loss 20.156, data 19.381) 
Epoch 13 Iter 4800, train entropy gap 0.7229 bits (loss 20.104, data 19.381) 
Epoch 13 Iter 5000, train entropy gap 0.8167 bits (loss 20.198, data 19.381) 
Epoch 13 Iter 5200, train entropy gap 0.9027 bits (loss 20.284, data 19.381) 
Epoch 13 Iter 5400, train entropy gap 0.8283 bits (loss 20.209, data 19.381) 
Epoch 13 Iter 5600, train entropy gap 0.6075 bits (loss 19.988, data 19.381) 
Epoch 13 Iter 5800, train entropy gap 0.9519 bits (loss 20.333, data 19.381) 
Epoch 13 Iter 6000, train entropy gap 0.8740 bits (loss 20.255, data 19.381) 
Epoch 13 Iter 6200, train entropy gap 0.7355 bits (loss 20.116, data 19.381) 
Epoch 13 Iter 6400, train entropy gap 0.9518 bits (loss 20.333, data 19.381) 
Epoch 13 Iter 6600, train entropy gap 0.7012 bits (loss 20.082, data 19.381) 
Epoch 13 Iter 6800, train entropy gap 0.7017 bits (loss 20.083, data 19.381) 
Epoch 13 Iter 7000, train entropy gap 0.4660 bits (loss 19.847, data 19.381) 
Epoch 13 Iter 7200, train entropy gap 0.8250 bits (loss 20.206, data 19.381) 
epoch 13 train loss 13.9741 nats / 20.1604 bits
time since start: 2634.1 secs
Epoch 14 Iter 0, train entropy gap 0.7082 bits (loss 20.089, data 19.381) 
Epoch 14 Iter 200, train entropy gap 0.7520 bits (loss 20.133, data 19.381) 
Epoch 14 Iter 400, train entropy gap 0.7088 bits (loss 20.090, data 19.381) 
Epoch 14 Iter 600, train entropy gap 0.6759 bits (loss 20.057, data 19.381) 
Epoch 14 Iter 800, train entropy gap 0.8837 bits (loss 20.265, data 19.381) 
Epoch 14 Iter 1000, train entropy gap 0.7135 bits (loss 20.094, data 19.381) 
Epoch 14 Iter 1200, train entropy gap 0.7682 bits (loss 20.149, data 19.381) 
Epoch 14 Iter 1400, train entropy gap 0.7975 bits (loss 20.178, data 19.381) 
Epoch 14 Iter 1600, train entropy gap 0.8269 bits (loss 20.208, data 19.381) 
Epoch 14 Iter 1800, train entropy gap 0.6852 bits (loss 20.066, data 19.381) 
Epoch 14 Iter 2000, train entropy gap 0.5746 bits (loss 19.955, data 19.381) 
Epoch 14 Iter 2200, train entropy gap 0.7410 bits (loss 20.122, data 19.381) 
Epoch 14 Iter 2400, train entropy gap 0.7596 bits (loss 20.140, data 19.381) 
Epoch 14 Iter 2600, train entropy gap 0.7584 bits (loss 20.139, data 19.381) 
Epoch 14 Iter 2800, train entropy gap 0.5747 bits (loss 19.956, data 19.381) 
Epoch 14 Iter 3000, train entropy gap 0.6856 bits (loss 20.066, data 19.381) 
Epoch 14 Iter 3200, train entropy gap 0.7579 bits (loss 20.139, data 19.381) 
Epoch 14 Iter 3400, train entropy gap 0.8854 bits (loss 20.266, data 19.381) 
Epoch 14 Iter 3600, train entropy gap 0.7354 bits (loss 20.116, data 19.381) 
Epoch 14 Iter 3800, train entropy gap 0.8184 bits (loss 20.199, data 19.381) 
Epoch 14 Iter 4000, train entropy gap 0.8801 bits (loss 20.261, data 19.381) 
Epoch 14 Iter 4200, train entropy gap 0.7893 bits (loss 20.170, data 19.381) 
Epoch 14 Iter 4400, train entropy gap 0.7965 bits (loss 20.177, data 19.381) 
Epoch 14 Iter 4600, train entropy gap 0.8260 bits (loss 20.207, data 19.381) 
Epoch 14 Iter 4800, train entropy gap 0.7457 bits (loss 20.127, data 19.381) 
Epoch 14 Iter 5000, train entropy gap 0.9623 bits (loss 20.343, data 19.381) 
Epoch 14 Iter 5200, train entropy gap 0.7018 bits (loss 20.083, data 19.381) 
Epoch 14 Iter 5400, train entropy gap 0.7919 bits (loss 20.173, data 19.381) 
Epoch 14 Iter 5600, train entropy gap 0.8772 bits (loss 20.258, data 19.381) 
Epoch 14 Iter 5800, train entropy gap 0.7546 bits (loss 20.135, data 19.381) 
Epoch 14 Iter 6000, train entropy gap 0.9007 bits (loss 20.281, data 19.381) 
Epoch 14 Iter 6200, train entropy gap 0.6954 bits (loss 20.076, data 19.381) 
Epoch 14 Iter 6400, train entropy gap 0.9455 bits (loss 20.326, data 19.381) 
Epoch 14 Iter 6600, train entropy gap 0.9182 bits (loss 20.299, data 19.381) 
Epoch 14 Iter 6800, train entropy gap 0.8597 bits (loss 20.240, data 19.381) 
Epoch 14 Iter 7000, train entropy gap 0.7258 bits (loss 20.107, data 19.381) 
Epoch 14 Iter 7200, train entropy gap 0.7271 bits (loss 20.108, data 19.381) 
epoch 14 train loss 13.9714 nats / 20.1565 bits
time since start: 2823.9 secs
Epoch 15 Iter 0, train entropy gap 0.7536 bits (loss 20.134, data 19.381) 
Epoch 15 Iter 200, train entropy gap 0.7889 bits (loss 20.170, data 19.381) 
Epoch 15 Iter 400, train entropy gap 1.0423 bits (loss 20.423, data 19.381) 
Epoch 15 Iter 600, train entropy gap 0.9305 bits (loss 20.311, data 19.381) 
Epoch 15 Iter 800, train entropy gap 0.8906 bits (loss 20.271, data 19.381) 
Epoch 15 Iter 1000, train entropy gap 0.6341 bits (loss 20.015, data 19.381) 
Epoch 15 Iter 1200, train entropy gap 0.8494 bits (loss 20.230, data 19.381) 
Epoch 15 Iter 1400, train entropy gap 0.7881 bits (loss 20.169, data 19.381) 
Epoch 15 Iter 1600, train entropy gap 0.8236 bits (loss 20.204, data 19.381) 
Epoch 15 Iter 1800, train entropy gap 0.7871 bits (loss 20.168, data 19.381) 
Epoch 15 Iter 2000, train entropy gap 0.8342 bits (loss 20.215, data 19.381) 
Epoch 15 Iter 2200, train entropy gap 0.5908 bits (loss 19.972, data 19.381) 
Epoch 15 Iter 2400, train entropy gap 0.8965 bits (loss 20.277, data 19.381) 
Epoch 15 Iter 2600, train entropy gap 0.8803 bits (loss 20.261, data 19.381) 
Epoch 15 Iter 2800, train entropy gap 0.8152 bits (loss 20.196, data 19.381) 
Epoch 15 Iter 3000, train entropy gap 0.9073 bits (loss 20.288, data 19.381) 
Epoch 15 Iter 3200, train entropy gap 0.7241 bits (loss 20.105, data 19.381) 
Epoch 15 Iter 3400, train entropy gap 0.7903 bits (loss 20.171, data 19.381) 
Epoch 15 Iter 3600, train entropy gap 0.6744 bits (loss 20.055, data 19.381) 
Epoch 15 Iter 3800, train entropy gap 0.6532 bits (loss 20.034, data 19.381) 
Epoch 15 Iter 4000, train entropy gap 0.4908 bits (loss 19.872, data 19.381) 
Epoch 15 Iter 4200, train entropy gap 0.8218 bits (loss 20.203, data 19.381) 
Epoch 15 Iter 4400, train entropy gap 0.7897 bits (loss 20.171, data 19.381) 
Epoch 15 Iter 4600, train entropy gap 0.9517 bits (loss 20.333, data 19.381) 
Epoch 15 Iter 4800, train entropy gap 0.5927 bits (loss 19.973, data 19.381) 
Epoch 15 Iter 5000, train entropy gap 0.7431 bits (loss 20.124, data 19.381) 
Epoch 15 Iter 5200, train entropy gap 0.7882 bits (loss 20.169, data 19.381) 
Epoch 15 Iter 5400, train entropy gap 0.9260 bits (loss 20.307, data 19.381) 
Epoch 15 Iter 5600, train entropy gap 0.8198 bits (loss 20.201, data 19.381) 
Epoch 15 Iter 5800, train entropy gap 0.8360 bits (loss 20.217, data 19.381) 
Epoch 15 Iter 6000, train entropy gap 0.8578 bits (loss 20.239, data 19.381) 
Epoch 15 Iter 6200, train entropy gap 0.8158 bits (loss 20.197, data 19.381) 
Epoch 15 Iter 6400, train entropy gap 0.7409 bits (loss 20.122, data 19.381) 
Epoch 15 Iter 6600, train entropy gap 0.9269 bits (loss 20.308, data 19.381) 
Epoch 15 Iter 6800, train entropy gap 0.7202 bits (loss 20.101, data 19.381) 
Epoch 15 Iter 7000, train entropy gap 0.7315 bits (loss 20.112, data 19.381) 
Epoch 15 Iter 7200, train entropy gap 0.6975 bits (loss 20.078, data 19.381) 
epoch 15 train loss 13.9689 nats / 20.1529 bits
time since start: 3007.5 secs
Epoch 16 Iter 0, train entropy gap 0.7745 bits (loss 20.155, data 19.381) 
Epoch 16 Iter 200, train entropy gap 0.5507 bits (loss 19.932, data 19.381) 
Epoch 16 Iter 400, train entropy gap 0.8566 bits (loss 20.237, data 19.381) 
Epoch 16 Iter 600, train entropy gap 0.8628 bits (loss 20.244, data 19.381) 
Epoch 16 Iter 800, train entropy gap 0.6819 bits (loss 20.063, data 19.381) 
Epoch 16 Iter 1000, train entropy gap 0.6529 bits (loss 20.034, data 19.381) 
Epoch 16 Iter 1200, train entropy gap 0.6471 bits (loss 20.028, data 19.381) 
Epoch 16 Iter 1400, train entropy gap 0.7461 bits (loss 20.127, data 19.381) 
Epoch 16 Iter 1600, train entropy gap 0.4801 bits (loss 19.861, data 19.381) 
Epoch 16 Iter 1800, train entropy gap 0.9062 bits (loss 20.287, data 19.381) 
Epoch 16 Iter 2000, train entropy gap 0.7534 bits (loss 20.134, data 19.381) 
Epoch 16 Iter 2200, train entropy gap 0.7758 bits (loss 20.157, data 19.381) 
Epoch 16 Iter 2400, train entropy gap 0.8998 bits (loss 20.281, data 19.381) 
Epoch 16 Iter 2600, train entropy gap 0.7921 bits (loss 20.173, data 19.381) 
Epoch 16 Iter 2800, train entropy gap 1.0571 bits (loss 20.438, data 19.381) 
Epoch 16 Iter 3000, train entropy gap 0.7676 bits (loss 20.148, data 19.381) 
Epoch 16 Iter 3200, train entropy gap 0.7894 bits (loss 20.170, data 19.381) 
Epoch 16 Iter 3400, train entropy gap 0.6650 bits (loss 20.046, data 19.381) 
Epoch 16 Iter 3600, train entropy gap 0.8622 bits (loss 20.243, data 19.381) 
Epoch 16 Iter 3800, train entropy gap 0.7847 bits (loss 20.166, data 19.381) 
Epoch 16 Iter 4000, train entropy gap 0.8451 bits (loss 20.226, data 19.381) 
Epoch 16 Iter 4200, train entropy gap 0.6884 bits (loss 20.069, data 19.381) 
Epoch 16 Iter 4400, train entropy gap 0.7562 bits (loss 20.137, data 19.381) 
Epoch 16 Iter 4600, train entropy gap 0.8647 bits (loss 20.246, data 19.381) 
Epoch 16 Iter 4800, train entropy gap 0.7521 bits (loss 20.133, data 19.381) 
Epoch 16 Iter 5000, train entropy gap 0.7101 bits (loss 20.091, data 19.381) 
Epoch 16 Iter 5200, train entropy gap 0.6883 bits (loss 20.069, data 19.381) 
Epoch 16 Iter 5400, train entropy gap 0.8054 bits (loss 20.186, data 19.381) 
Epoch 16 Iter 5600, train entropy gap 0.6777 bits (loss 20.058, data 19.381) 
Epoch 16 Iter 5800, train entropy gap 0.9090 bits (loss 20.290, data 19.381) 
Epoch 16 Iter 6000, train entropy gap 0.7956 bits (loss 20.176, data 19.381) 
Epoch 16 Iter 6200, train entropy gap 0.7547 bits (loss 20.136, data 19.381) 
Epoch 16 Iter 6400, train entropy gap 0.9211 bits (loss 20.302, data 19.381) 
Epoch 16 Iter 6600, train entropy gap 0.6801 bits (loss 20.061, data 19.381) 
Epoch 16 Iter 6800, train entropy gap 0.7062 bits (loss 20.087, data 19.381) 
Epoch 16 Iter 7000, train entropy gap 0.5384 bits (loss 19.919, data 19.381) 
Epoch 16 Iter 7200, train entropy gap 0.7919 bits (loss 20.173, data 19.381) 
epoch 16 train loss 13.9668 nats / 20.1498 bits
time since start: 3142.7 secs
Epoch 17 Iter 0, train entropy gap 0.7944 bits (loss 20.175, data 19.381) 
Epoch 17 Iter 200, train entropy gap 0.6864 bits (loss 20.067, data 19.381) 
Epoch 17 Iter 400, train entropy gap 0.8891 bits (loss 20.270, data 19.381) 
Epoch 17 Iter 600, train entropy gap 0.9828 bits (loss 20.364, data 19.381) 
Epoch 17 Iter 800, train entropy gap 0.8980 bits (loss 20.279, data 19.381) 
Epoch 17 Iter 1000, train entropy gap 0.6007 bits (loss 19.982, data 19.381) 
Epoch 17 Iter 1200, train entropy gap 0.5462 bits (loss 19.927, data 19.381) 
Epoch 17 Iter 1400, train entropy gap 0.7489 bits (loss 20.130, data 19.381) 
Epoch 17 Iter 1600, train entropy gap 0.7185 bits (loss 20.099, data 19.381) 
Epoch 17 Iter 1800, train entropy gap 0.7920 bits (loss 20.173, data 19.381) 
Epoch 17 Iter 2000, train entropy gap 0.6773 bits (loss 20.058, data 19.381) 
Epoch 17 Iter 2200, train entropy gap 0.7955 bits (loss 20.176, data 19.381) 
Epoch 17 Iter 2400, train entropy gap 0.8383 bits (loss 20.219, data 19.381) 
Epoch 17 Iter 2600, train entropy gap 0.8206 bits (loss 20.201, data 19.381) 
Epoch 17 Iter 2800, train entropy gap 0.7355 bits (loss 20.116, data 19.381) 
Epoch 17 Iter 3000, train entropy gap 0.8686 bits (loss 20.249, data 19.381) 
Epoch 17 Iter 3200, train entropy gap 0.7229 bits (loss 20.104, data 19.381) 
Epoch 17 Iter 3400, train entropy gap 0.8895 bits (loss 20.270, data 19.381) 
Epoch 17 Iter 3600, train entropy gap 0.8537 bits (loss 20.235, data 19.381) 
Epoch 17 Iter 3800, train entropy gap 1.0282 bits (loss 20.409, data 19.381) 
Epoch 17 Iter 4000, train entropy gap 0.7450 bits (loss 20.126, data 19.381) 
Epoch 17 Iter 4200, train entropy gap 0.9595 bits (loss 20.340, data 19.381) 
Epoch 17 Iter 4400, train entropy gap 0.7699 bits (loss 20.151, data 19.381) 
Epoch 17 Iter 4600, train entropy gap 0.7277 bits (loss 20.108, data 19.381) 
Epoch 17 Iter 4800, train entropy gap 0.8520 bits (loss 20.233, data 19.381) 
Epoch 17 Iter 5000, train entropy gap 0.8448 bits (loss 20.226, data 19.381) 
Epoch 17 Iter 5200, train entropy gap 0.9892 bits (loss 20.370, data 19.381) 
Epoch 17 Iter 5400, train entropy gap 0.5130 bits (loss 19.894, data 19.381) 
Epoch 17 Iter 5600, train entropy gap 0.6734 bits (loss 20.054, data 19.381) 
Epoch 17 Iter 5800, train entropy gap 0.8705 bits (loss 20.251, data 19.381) 
Epoch 17 Iter 6000, train entropy gap 0.8785 bits (loss 20.259, data 19.381) 
Epoch 17 Iter 6200, train entropy gap 0.6918 bits (loss 20.073, data 19.381) 
Epoch 17 Iter 6400, train entropy gap 0.8951 bits (loss 20.276, data 19.381) 
Epoch 17 Iter 6600, train entropy gap 0.6286 bits (loss 20.009, data 19.381) 
Epoch 17 Iter 6800, train entropy gap 0.6601 bits (loss 20.041, data 19.381) 
Epoch 17 Iter 7000, train entropy gap 0.7858 bits (loss 20.167, data 19.381) 
Epoch 17 Iter 7200, train entropy gap 0.7089 bits (loss 20.090, data 19.381) 
epoch 17 train loss 13.9646 nats / 20.1467 bits
time since start: 3266.9 secs
Epoch 18 Iter 0, train entropy gap 0.9119 bits (loss 20.293, data 19.381) 
Epoch 18 Iter 200, train entropy gap 0.6638 bits (loss 20.045, data 19.381) 
Epoch 18 Iter 400, train entropy gap 0.5972 bits (loss 19.978, data 19.381) 
Epoch 18 Iter 600, train entropy gap 0.6569 bits (loss 20.038, data 19.381) 
Epoch 18 Iter 800, train entropy gap 0.6715 bits (loss 20.052, data 19.381) 
Epoch 18 Iter 1000, train entropy gap 0.6124 bits (loss 19.993, data 19.381) 
Epoch 18 Iter 1200, train entropy gap 0.8766 bits (loss 20.257, data 19.381) 
Epoch 18 Iter 1400, train entropy gap 0.6995 bits (loss 20.080, data 19.381) 
Epoch 18 Iter 1600, train entropy gap 0.7656 bits (loss 20.146, data 19.381) 
Epoch 18 Iter 1800, train entropy gap 0.8795 bits (loss 20.260, data 19.381) 
Epoch 18 Iter 2000, train entropy gap 0.7394 bits (loss 20.120, data 19.381) 
Epoch 18 Iter 2200, train entropy gap 0.7326 bits (loss 20.113, data 19.381) 
Epoch 18 Iter 2400, train entropy gap 0.8306 bits (loss 20.211, data 19.381) 
Epoch 18 Iter 2600, train entropy gap 0.7301 bits (loss 20.111, data 19.381) 
Epoch 18 Iter 2800, train entropy gap 0.5858 bits (loss 19.967, data 19.381) 
Epoch 18 Iter 3000, train entropy gap 0.6341 bits (loss 20.015, data 19.381) 
Epoch 18 Iter 3200, train entropy gap 0.8675 bits (loss 20.248, data 19.381) 
Epoch 18 Iter 3400, train entropy gap 0.7987 bits (loss 20.180, data 19.381) 
Epoch 18 Iter 3600, train entropy gap 0.8421 bits (loss 20.223, data 19.381) 
Epoch 18 Iter 3800, train entropy gap 0.6889 bits (loss 20.070, data 19.381) 
Epoch 18 Iter 4000, train entropy gap 0.6879 bits (loss 20.069, data 19.381) 
Epoch 18 Iter 4200, train entropy gap 0.6133 bits (loss 19.994, data 19.381) 
Epoch 18 Iter 4400, train entropy gap 0.7929 bits (loss 20.174, data 19.381) 
Epoch 18 Iter 4600, train entropy gap 0.8002 bits (loss 20.181, data 19.381) 
Epoch 18 Iter 4800, train entropy gap 0.9125 bits (loss 20.293, data 19.381) 
Epoch 18 Iter 5000, train entropy gap 0.8707 bits (loss 20.252, data 19.381) 
Epoch 18 Iter 5200, train entropy gap 0.6488 bits (loss 20.030, data 19.381) 
Epoch 18 Iter 5400, train entropy gap 0.9185 bits (loss 20.299, data 19.381) 
Epoch 18 Iter 5600, train entropy gap 0.8501 bits (loss 20.231, data 19.381) 
Epoch 18 Iter 5800, train entropy gap 0.8106 bits (loss 20.191, data 19.381) 
Epoch 18 Iter 6000, train entropy gap 0.5651 bits (loss 19.946, data 19.381) 
Epoch 18 Iter 6200, train entropy gap 0.5722 bits (loss 19.953, data 19.381) 
Epoch 18 Iter 6400, train entropy gap 0.9148 bits (loss 20.296, data 19.381) 
Epoch 18 Iter 6600, train entropy gap 0.8920 bits (loss 20.273, data 19.381) 
Epoch 18 Iter 6800, train entropy gap 0.8040 bits (loss 20.185, data 19.381) 
Epoch 18 Iter 7000, train entropy gap 0.8011 bits (loss 20.182, data 19.381) 
Epoch 18 Iter 7200, train entropy gap 0.6440 bits (loss 20.025, data 19.381) 
epoch 18 train loss 13.9627 nats / 20.1440 bits
time since start: 3391.1 secs
Epoch 19 Iter 0, train entropy gap 0.8180 bits (loss 20.199, data 19.381) 
Epoch 19 Iter 200, train entropy gap 0.6409 bits (loss 20.022, data 19.381) 
Epoch 19 Iter 400, train entropy gap 0.6438 bits (loss 20.025, data 19.381) 
Epoch 19 Iter 600, train entropy gap 0.7912 bits (loss 20.172, data 19.381) 
Epoch 19 Iter 800, train entropy gap 0.7270 bits (loss 20.108, data 19.381) 
Epoch 19 Iter 1000, train entropy gap 0.8950 bits (loss 20.276, data 19.381) 
Epoch 19 Iter 1200, train entropy gap 0.7360 bits (loss 20.117, data 19.381) 
Epoch 19 Iter 1400, train entropy gap 0.6498 bits (loss 20.031, data 19.381) 
Epoch 19 Iter 1600, train entropy gap 0.7170 bits (loss 20.098, data 19.381) 
Epoch 19 Iter 1800, train entropy gap 0.8021 bits (loss 20.183, data 19.381) 
Epoch 19 Iter 2000, train entropy gap 0.6649 bits (loss 20.046, data 19.381) 
Epoch 19 Iter 2200, train entropy gap 0.9085 bits (loss 20.289, data 19.381) 
Epoch 19 Iter 2400, train entropy gap 0.8121 bits (loss 20.193, data 19.381) 
Epoch 19 Iter 2600, train entropy gap 0.7612 bits (loss 20.142, data 19.381) 
Epoch 19 Iter 2800, train entropy gap 0.7960 bits (loss 20.177, data 19.381) 
Epoch 19 Iter 3000, train entropy gap 0.6881 bits (loss 20.069, data 19.381) 
Epoch 19 Iter 3200, train entropy gap 0.7512 bits (loss 20.132, data 19.381) 
Epoch 19 Iter 3400, train entropy gap 0.9449 bits (loss 20.326, data 19.381) 
Epoch 19 Iter 3600, train entropy gap 0.6614 bits (loss 20.042, data 19.381) 
Epoch 19 Iter 3800, train entropy gap 0.7247 bits (loss 20.106, data 19.381) 
Epoch 19 Iter 4000, train entropy gap 0.6120 bits (loss 19.993, data 19.381) 
Epoch 19 Iter 4200, train entropy gap 0.7128 bits (loss 20.094, data 19.381) 
Epoch 19 Iter 4400, train entropy gap 0.7586 bits (loss 20.139, data 19.381) 
Epoch 19 Iter 4600, train entropy gap 0.6305 bits (loss 20.011, data 19.381) 
Epoch 19 Iter 4800, train entropy gap 0.7085 bits (loss 20.089, data 19.381) 
Epoch 19 Iter 5000, train entropy gap 0.7973 bits (loss 20.178, data 19.381) 
Epoch 19 Iter 5200, train entropy gap 0.7720 bits (loss 20.153, data 19.381) 
Epoch 19 Iter 5400, train entropy gap 0.7084 bits (loss 20.089, data 19.381) 
Epoch 19 Iter 5600, train entropy gap 0.7870 bits (loss 20.168, data 19.381) 
Epoch 19 Iter 5800, train entropy gap 0.9616 bits (loss 20.342, data 19.381) 
Epoch 19 Iter 6000, train entropy gap 0.8112 bits (loss 20.192, data 19.381) 
Epoch 19 Iter 6200, train entropy gap 0.6370 bits (loss 20.018, data 19.381) 
Epoch 19 Iter 6400, train entropy gap 0.7552 bits (loss 20.136, data 19.381) 
Epoch 19 Iter 6600, train entropy gap 0.9295 bits (loss 20.310, data 19.381) 
Epoch 19 Iter 6800, train entropy gap 0.8535 bits (loss 20.234, data 19.381) 
Epoch 19 Iter 7000, train entropy gap 0.7218 bits (loss 20.103, data 19.381) 
Epoch 19 Iter 7200, train entropy gap 0.9379 bits (loss 20.319, data 19.381) 
epoch 19 train loss 13.9605 nats / 20.1407 bits
time since start: 3515.4 secs
Training done; evaluating likelihood on full data:
Epoch None Iter 0, test loss 16.3952 nats / 23.6533 bits
Epoch None Iter 500, test loss 15.3936 nats / 22.2083 bits
Epoch None Iter 1000, test loss 13.1271 nats / 18.9384 bits
Epoch None Iter 1500, test loss 12.6463 nats / 18.2447 bits
Epoch None Iter 2000, test loss 13.2151 nats / 19.0654 bits
Epoch None Iter 2500, test loss 12.2977 nats / 17.7418 bits
Epoch None Iter 3000, test loss 13.5824 nats / 19.5953 bits
Epoch None Iter 3500, test loss 15.7017 nats / 22.6528 bits
Epoch None Iter 4000, test loss 12.7630 nats / 18.4130 bits
Epoch None Iter 4500, test loss 16.8748 nats / 24.3451 bits
Epoch None Iter 5000, test loss 17.2103 nats / 24.8292 bits
Epoch None Iter 5500, test loss 13.7094 nats / 19.7784 bits
Epoch None Iter 6000, test loss 13.7541 nats / 19.8430 bits
Epoch None Iter 6500, test loss 12.6441 nats / 18.2416 bits
Epoch None Iter 7000, test loss 15.3199 nats / 22.1019 bits
Saved to:
models/dmv-11.4MB-model20.123-data19.381-transformer-blocks4-model256-ff512-heads32-use_flash_attnTrue-posEmb-gelu-20epochs-seed0.pt
