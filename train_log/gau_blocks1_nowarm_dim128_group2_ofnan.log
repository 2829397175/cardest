Device cuda
Device cuda
Loading csv... done, took 6.1s
Parsing... done, took 5.0s
Entropy of DMV_ofnan([Column(Record Type, distribution_size=2), Column(Registration Class, distribution_size=69), Column(State, distribution_size=77), Column(County, distribution_size=63), Column(Body Type, distribution_size=57), Column(Fuel Type, distribution_size=8), Column(Reg Valid Date, distribution_size=2828), Column(Color, distribution_size=218), Column(Scofflaw Indicator, distribution_size=2), Column(Suspension Indicator, distribution_size=2), Column(Revocation Indicator, distribution_size=2)]): 19.3435 bits
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7315785 entries, 0 to 7315784
Data columns (total 11 columns):
 #   Column                Dtype         
---  ------                -----         
 0   Record Type           object        
 1   Registration Class    object        
 2   State                 object        
 3   County                object        
 4   Body Type             object        
 5   Fuel Type             object        
 6   Reg Valid Date        datetime64[ns]
 7   Color                 object        
 8   Scofflaw Indicator    object        
 9   Suspension Indicator  object        
 10  Revocation Indicator  object        
dtypes: datetime64[ns](1), object(10)
memory usage: 614.0+ MB
None
ordering [ 0  1  2  3  4  5  6  7  8  9 10]
Number of model parameters: 544177 (~= 2.1MB)
FLASHTransformer(
  (layers): Sequential(
    (0): FLASH(
      (attn_fn): ReLUSquared()
      (rotary_pos_emb): RotaryEmbedding()
      (rel_pos_bias): T5RelativePositionBias(
        (relative_attention_bias): Embedding(32, 1)
      )
      (norm): ScaleNorm()
      (dropout): Dropout(p=0.0, inplace=False)
      (to_hidden): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
      )
      (to_qk): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): SiLU()
      )
      (qk_offset_scale): OffsetScale()
      (to_out): Linear(in_features=256, out_features=128, bias=True)
    )
  )
  (to_logits): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (embeddings): ModuleList(
    (0): Embedding(2, 128)
    (1): Embedding(69, 128)
    (2): Embedding(77, 128)
    (3): Embedding(63, 128)
    (4): Embedding(57, 128)
    (5): Embedding(8, 128)
    (6): Embedding(2828, 128)
    (7): Embedding(218, 128)
    (8): Embedding(2, 128)
    (9): Embedding(2, 128)
    (10): Embedding(2, 128)
  )
  (pos_embeddings): Embedding(11, 128)
)
Discretizing table... done, took 3.6s
Epoch 0 Iter 0, train entropy gap 31.7515 bits (loss 51.095, data 19.343) 
Epoch 0 Iter 200, train entropy gap 2.5150 bits (loss 21.858, data 19.343) 
Epoch 0 Iter 400, train entropy gap 1.3419 bits (loss 20.685, data 19.343) 
Epoch 0 Iter 600, train entropy gap 1.2673 bits (loss 20.611, data 19.343) 
Epoch 0 Iter 800, train entropy gap 1.4263 bits (loss 20.770, data 19.343) 
Epoch 0 Iter 1000, train entropy gap 1.2363 bits (loss 20.580, data 19.343) 
Epoch 0 Iter 1200, train entropy gap 1.1309 bits (loss 20.474, data 19.343) 
Epoch 0 Iter 1400, train entropy gap 1.1383 bits (loss 20.482, data 19.343) 
Epoch 0 Iter 1600, train entropy gap 0.9391 bits (loss 20.283, data 19.343) 
Epoch 0 Iter 1800, train entropy gap 0.7800 bits (loss 20.123, data 19.343) 
Epoch 0 Iter 2000, train entropy gap 0.9667 bits (loss 20.310, data 19.343) 
Epoch 0 Iter 2200, train entropy gap 1.0640 bits (loss 20.407, data 19.343) 
Epoch 0 Iter 2400, train entropy gap 0.7216 bits (loss 20.065, data 19.343) 
Epoch 0 Iter 2600, train entropy gap 0.8815 bits (loss 20.225, data 19.343) 
Epoch 0 Iter 2800, train entropy gap 0.8788 bits (loss 20.222, data 19.343) 
Epoch 0 Iter 3000, train entropy gap 0.8673 bits (loss 20.211, data 19.343) 
Epoch 0 Iter 3200, train entropy gap 0.9147 bits (loss 20.258, data 19.343) 
Epoch 0 Iter 3400, train entropy gap 1.1424 bits (loss 20.486, data 19.343) 
Epoch 0 Iter 3600, train entropy gap 0.8559 bits (loss 20.199, data 19.343) 
Epoch 0 Iter 3800, train entropy gap 0.9926 bits (loss 20.336, data 19.343) 
Epoch 0 Iter 4000, train entropy gap 1.0850 bits (loss 20.428, data 19.343) 
Epoch 0 Iter 4200, train entropy gap 1.0654 bits (loss 20.409, data 19.343) 
Epoch 0 Iter 4400, train entropy gap 0.9387 bits (loss 20.282, data 19.343) 
Epoch 0 Iter 4600, train entropy gap 1.0970 bits (loss 20.440, data 19.343) 
Epoch 0 Iter 4800, train entropy gap 0.9523 bits (loss 20.296, data 19.343) 
Epoch 0 Iter 5000, train entropy gap 1.0368 bits (loss 20.380, data 19.343) 
Epoch 0 Iter 5200, train entropy gap 1.0255 bits (loss 20.369, data 19.343) 
Epoch 0 Iter 5400, train entropy gap 0.8588 bits (loss 20.202, data 19.343) 
Epoch 0 Iter 5600, train entropy gap 0.9589 bits (loss 20.302, data 19.343) 
Epoch 0 Iter 5800, train entropy gap 0.8865 bits (loss 20.230, data 19.343) 
Epoch 0 Iter 6000, train entropy gap 0.9237 bits (loss 20.267, data 19.343) 
Epoch 0 Iter 6200, train entropy gap 1.0508 bits (loss 20.394, data 19.343) 
Epoch 0 Iter 6400, train entropy gap 0.8501 bits (loss 20.194, data 19.343) 
Epoch 0 Iter 6600, train entropy gap 0.9487 bits (loss 20.292, data 19.343) 
Epoch 0 Iter 6800, train entropy gap 0.8520 bits (loss 20.195, data 19.343) 
Epoch 0 Iter 7000, train entropy gap 0.7794 bits (loss 20.123, data 19.343) 
epoch 0 train loss 14.2214 nats / 20.5172 bits
time since start: 164.6 secs
Epoch 1 Iter 0, train entropy gap 0.7232 bits (loss 20.067, data 19.343) 
Epoch 1 Iter 200, train entropy gap 1.1064 bits (loss 20.450, data 19.343) 
Epoch 1 Iter 400, train entropy gap 1.0184 bits (loss 20.362, data 19.343) 
Epoch 1 Iter 600, train entropy gap 1.0543 bits (loss 20.398, data 19.343) 
Epoch 1 Iter 800, train entropy gap 0.7510 bits (loss 20.095, data 19.343) 
Epoch 1 Iter 1000, train entropy gap 0.7516 bits (loss 20.095, data 19.343) 
Epoch 1 Iter 1200, train entropy gap 0.8265 bits (loss 20.170, data 19.343) 
Epoch 1 Iter 1400, train entropy gap 0.9112 bits (loss 20.255, data 19.343) 
Epoch 1 Iter 1600, train entropy gap 0.7705 bits (loss 20.114, data 19.343) 
Epoch 1 Iter 1800, train entropy gap 0.9384 bits (loss 20.282, data 19.343) 
Epoch 1 Iter 2000, train entropy gap 0.9174 bits (loss 20.261, data 19.343) 
Epoch 1 Iter 2200, train entropy gap 0.9622 bits (loss 20.306, data 19.343) 
Epoch 1 Iter 2400, train entropy gap 0.8072 bits (loss 20.151, data 19.343) 
Epoch 1 Iter 2600, train entropy gap 0.9074 bits (loss 20.251, data 19.343) 
Epoch 1 Iter 2800, train entropy gap 0.9084 bits (loss 20.252, data 19.343) 
Epoch 1 Iter 3000, train entropy gap 0.7910 bits (loss 20.134, data 19.343) 
Epoch 1 Iter 3200, train entropy gap 0.8377 bits (loss 20.181, data 19.343) 
Epoch 1 Iter 3400, train entropy gap 0.9476 bits (loss 20.291, data 19.343) 
Epoch 1 Iter 3600, train entropy gap 0.7604 bits (loss 20.104, data 19.343) 
Epoch 1 Iter 3800, train entropy gap 0.9766 bits (loss 20.320, data 19.343) 
Epoch 1 Iter 4000, train entropy gap 0.7649 bits (loss 20.108, data 19.343) 
Epoch 1 Iter 4200, train entropy gap 0.9178 bits (loss 20.261, data 19.343) 
Epoch 1 Iter 4400, train entropy gap 0.8191 bits (loss 20.163, data 19.343) 
Epoch 1 Iter 4600, train entropy gap 0.9129 bits (loss 20.256, data 19.343) 
Epoch 1 Iter 4800, train entropy gap 0.8277 bits (loss 20.171, data 19.343) 
Epoch 1 Iter 5000, train entropy gap 0.8242 bits (loss 20.168, data 19.343) 
Epoch 1 Iter 5200, train entropy gap 0.5946 bits (loss 19.938, data 19.343) 
Epoch 1 Iter 5400, train entropy gap 0.7678 bits (loss 20.111, data 19.343) 
Epoch 1 Iter 5600, train entropy gap 0.8755 bits (loss 20.219, data 19.343) 
Epoch 1 Iter 5800, train entropy gap 0.8840 bits (loss 20.227, data 19.343) 
Epoch 1 Iter 6000, train entropy gap 0.9588 bits (loss 20.302, data 19.343) 
Epoch 1 Iter 6200, train entropy gap 0.9622 bits (loss 20.306, data 19.343) 
Epoch 1 Iter 6400, train entropy gap 0.9097 bits (loss 20.253, data 19.343) 
Epoch 1 Iter 6600, train entropy gap 0.7911 bits (loss 20.135, data 19.343) 
Epoch 1 Iter 6800, train entropy gap 0.8553 bits (loss 20.199, data 19.343) 
Epoch 1 Iter 7000, train entropy gap 0.8562 bits (loss 20.200, data 19.343) 
epoch 1 train loss 14.0203 nats / 20.2271 bits
time since start: 328.6 secs
Epoch 2 Iter 0, train entropy gap 0.8107 bits (loss 20.154, data 19.343) 
Epoch 2 Iter 200, train entropy gap 0.8358 bits (loss 20.179, data 19.343) 
Epoch 2 Iter 400, train entropy gap 0.7898 bits (loss 20.133, data 19.343) 
Epoch 2 Iter 600, train entropy gap 0.9172 bits (loss 20.261, data 19.343) 
Epoch 2 Iter 800, train entropy gap 0.8187 bits (loss 20.162, data 19.343) 
Epoch 2 Iter 1000, train entropy gap 0.6206 bits (loss 19.964, data 19.343) 
Epoch 2 Iter 1200, train entropy gap 0.7899 bits (loss 20.133, data 19.343) 
Epoch 2 Iter 1400, train entropy gap 0.7991 bits (loss 20.143, data 19.343) 
Epoch 2 Iter 1600, train entropy gap 0.8086 bits (loss 20.152, data 19.343) 
Epoch 2 Iter 1800, train entropy gap 0.9238 bits (loss 20.267, data 19.343) 
Epoch 2 Iter 2000, train entropy gap 0.7203 bits (loss 20.064, data 19.343) 
Epoch 2 Iter 2200, train entropy gap 0.6872 bits (loss 20.031, data 19.343) 
Epoch 2 Iter 2400, train entropy gap 0.9802 bits (loss 20.324, data 19.343) 
Epoch 2 Iter 2600, train entropy gap 0.7388 bits (loss 20.082, data 19.343) 
Epoch 2 Iter 2800, train entropy gap 0.6618 bits (loss 20.005, data 19.343) 
Epoch 2 Iter 3000, train entropy gap 0.8872 bits (loss 20.231, data 19.343) 
Epoch 2 Iter 3200, train entropy gap 0.8026 bits (loss 20.146, data 19.343) 
Epoch 2 Iter 3400, train entropy gap 0.9717 bits (loss 20.315, data 19.343) 
Epoch 2 Iter 3600, train entropy gap 0.8263 bits (loss 20.170, data 19.343) 
Epoch 2 Iter 3800, train entropy gap 0.9398 bits (loss 20.283, data 19.343) 
Epoch 2 Iter 4000, train entropy gap 0.8863 bits (loss 20.230, data 19.343) 
Epoch 2 Iter 4200, train entropy gap 0.7617 bits (loss 20.105, data 19.343) 
Epoch 2 Iter 4400, train entropy gap 0.7374 bits (loss 20.081, data 19.343) 
Epoch 2 Iter 4600, train entropy gap 0.8444 bits (loss 20.188, data 19.343) 
Epoch 2 Iter 4800, train entropy gap 1.1545 bits (loss 20.498, data 19.343) 
Epoch 2 Iter 5000, train entropy gap 0.9761 bits (loss 20.320, data 19.343) 
Epoch 2 Iter 5200, train entropy gap 0.7762 bits (loss 20.120, data 19.343) 
Epoch 2 Iter 5400, train entropy gap 0.8605 bits (loss 20.204, data 19.343) 
Epoch 2 Iter 5600, train entropy gap 0.9662 bits (loss 20.310, data 19.343) 
Epoch 2 Iter 5800, train entropy gap 0.6759 bits (loss 20.019, data 19.343) 
Epoch 2 Iter 6000, train entropy gap 0.7302 bits (loss 20.074, data 19.343) 
Epoch 2 Iter 6200, train entropy gap 0.8487 bits (loss 20.192, data 19.343) 
Epoch 2 Iter 6400, train entropy gap 1.0466 bits (loss 20.390, data 19.343) 
Epoch 2 Iter 6600, train entropy gap 0.7993 bits (loss 20.143, data 19.343) 
Epoch 2 Iter 6800, train entropy gap 0.9043 bits (loss 20.248, data 19.343) 
Epoch 2 Iter 7000, train entropy gap 1.0018 bits (loss 20.345, data 19.343) 
epoch 2 train loss 14.0073 nats / 20.2082 bits
time since start: 492.7 secs
Epoch 3 Iter 0, train entropy gap 0.8571 bits (loss 20.201, data 19.343) 
Epoch 3 Iter 200, train entropy gap 0.8546 bits (loss 20.198, data 19.343) 
Epoch 3 Iter 400, train entropy gap 0.7334 bits (loss 20.077, data 19.343) 
Epoch 3 Iter 600, train entropy gap 0.9585 bits (loss 20.302, data 19.343) 
Epoch 3 Iter 800, train entropy gap 1.0021 bits (loss 20.346, data 19.343) 
Epoch 3 Iter 1000, train entropy gap 0.8006 bits (loss 20.144, data 19.343) 
Epoch 3 Iter 1200, train entropy gap 0.7960 bits (loss 20.140, data 19.343) 
Epoch 3 Iter 1400, train entropy gap 0.9067 bits (loss 20.250, data 19.343) 
Epoch 3 Iter 1600, train entropy gap 0.8369 bits (loss 20.180, data 19.343) 
Epoch 3 Iter 1800, train entropy gap 0.8986 bits (loss 20.242, data 19.343) 
Epoch 3 Iter 2000, train entropy gap 0.7530 bits (loss 20.096, data 19.343) 
Epoch 3 Iter 2200, train entropy gap 0.7061 bits (loss 20.050, data 19.343) 
Epoch 3 Iter 2400, train entropy gap 0.7956 bits (loss 20.139, data 19.343) 
Epoch 3 Iter 2600, train entropy gap 0.9137 bits (loss 20.257, data 19.343) 
Epoch 3 Iter 2800, train entropy gap 0.8753 bits (loss 20.219, data 19.343) 
Epoch 3 Iter 3000, train entropy gap 1.0030 bits (loss 20.346, data 19.343) 
Epoch 3 Iter 3200, train entropy gap 0.9017 bits (loss 20.245, data 19.343) 
Epoch 3 Iter 3400, train entropy gap 0.9426 bits (loss 20.286, data 19.343) 
Epoch 3 Iter 3600, train entropy gap 0.9008 bits (loss 20.244, data 19.343) 
Epoch 3 Iter 3800, train entropy gap 0.7908 bits (loss 20.134, data 19.343) 
Epoch 3 Iter 4000, train entropy gap 0.7591 bits (loss 20.103, data 19.343) 
Epoch 3 Iter 4200, train entropy gap 0.7556 bits (loss 20.099, data 19.343) 
Epoch 3 Iter 4400, train entropy gap 0.9311 bits (loss 20.275, data 19.343) 
Epoch 3 Iter 4600, train entropy gap 0.9072 bits (loss 20.251, data 19.343) 
Epoch 3 Iter 4800, train entropy gap 0.8893 bits (loss 20.233, data 19.343) 
Epoch 3 Iter 5000, train entropy gap 0.8455 bits (loss 20.189, data 19.343) 
Epoch 3 Iter 5200, train entropy gap 0.7432 bits (loss 20.087, data 19.343) 
Epoch 3 Iter 5400, train entropy gap 0.7771 bits (loss 20.121, data 19.343) 
Epoch 3 Iter 5600, train entropy gap 0.8127 bits (loss 20.156, data 19.343) 
Epoch 3 Iter 5800, train entropy gap 0.8480 bits (loss 20.191, data 19.343) 
Epoch 3 Iter 6000, train entropy gap 0.8013 bits (loss 20.145, data 19.343) 
Epoch 3 Iter 6200, train entropy gap 1.1563 bits (loss 20.500, data 19.343) 
Epoch 3 Iter 6400, train entropy gap 0.7949 bits (loss 20.138, data 19.343) 
Epoch 3 Iter 6600, train entropy gap 0.6180 bits (loss 19.962, data 19.343) 
Epoch 3 Iter 6800, train entropy gap 0.9059 bits (loss 20.249, data 19.343) 
Epoch 3 Iter 7000, train entropy gap 0.9270 bits (loss 20.270, data 19.343) 
epoch 3 train loss 13.9996 nats / 20.1972 bits
time since start: 656.7 secs
Epoch 4 Iter 0, train entropy gap 0.9055 bits (loss 20.249, data 19.343) 
Epoch 4 Iter 200, train entropy gap 0.8165 bits (loss 20.160, data 19.343) 
Epoch 4 Iter 400, train entropy gap 0.7152 bits (loss 20.059, data 19.343) 
Epoch 4 Iter 600, train entropy gap 0.7171 bits (loss 20.061, data 19.343) 
Epoch 4 Iter 800, train entropy gap 0.8436 bits (loss 20.187, data 19.343) 
Epoch 4 Iter 1000, train entropy gap 0.8140 bits (loss 20.157, data 19.343) 
Epoch 4 Iter 1200, train entropy gap 0.8470 bits (loss 20.190, data 19.343) 
Epoch 4 Iter 1400, train entropy gap 0.6292 bits (loss 19.973, data 19.343) 
Epoch 4 Iter 1600, train entropy gap 0.9831 bits (loss 20.327, data 19.343) 
Epoch 4 Iter 1800, train entropy gap 0.9813 bits (loss 20.325, data 19.343) 
Epoch 4 Iter 2000, train entropy gap 0.7955 bits (loss 20.139, data 19.343) 
Epoch 4 Iter 2200, train entropy gap 0.7464 bits (loss 20.090, data 19.343) 
Epoch 4 Iter 2400, train entropy gap 0.9613 bits (loss 20.305, data 19.343) 
Epoch 4 Iter 2600, train entropy gap 0.7254 bits (loss 20.069, data 19.343) 
Epoch 4 Iter 2800, train entropy gap 0.8970 bits (loss 20.240, data 19.343) 
Epoch 4 Iter 3000, train entropy gap 0.8306 bits (loss 20.174, data 19.343) 
Epoch 4 Iter 3200, train entropy gap 0.8768 bits (loss 20.220, data 19.343) 
Epoch 4 Iter 3400, train entropy gap 0.8991 bits (loss 20.243, data 19.343) 
Epoch 4 Iter 3600, train entropy gap 1.2221 bits (loss 20.566, data 19.343) 
Epoch 4 Iter 3800, train entropy gap 0.8140 bits (loss 20.157, data 19.343) 
Epoch 4 Iter 4000, train entropy gap 0.8540 bits (loss 20.197, data 19.343) 
Epoch 4 Iter 4200, train entropy gap 0.9025 bits (loss 20.246, data 19.343) 
Epoch 4 Iter 4400, train entropy gap 1.0247 bits (loss 20.368, data 19.343) 
Epoch 4 Iter 4600, train entropy gap 0.8140 bits (loss 20.157, data 19.343) 
Epoch 4 Iter 4800, train entropy gap 0.9445 bits (loss 20.288, data 19.343) 
Epoch 4 Iter 5000, train entropy gap 0.7978 bits (loss 20.141, data 19.343) 
Epoch 4 Iter 5200, train entropy gap 0.9317 bits (loss 20.275, data 19.343) 
Epoch 4 Iter 5400, train entropy gap 0.7514 bits (loss 20.095, data 19.343) 
Epoch 4 Iter 5600, train entropy gap 0.7372 bits (loss 20.081, data 19.343) 
Epoch 4 Iter 5800, train entropy gap 0.7074 bits (loss 20.051, data 19.343) 
Epoch 4 Iter 6000, train entropy gap 0.8170 bits (loss 20.161, data 19.343) 
Epoch 4 Iter 6200, train entropy gap 1.0241 bits (loss 20.368, data 19.343) 
Epoch 4 Iter 6400, train entropy gap 0.7369 bits (loss 20.080, data 19.343) 
Epoch 4 Iter 6600, train entropy gap 0.8829 bits (loss 20.226, data 19.343) 
Epoch 4 Iter 6800, train entropy gap 0.9878 bits (loss 20.331, data 19.343) 
Epoch 4 Iter 7000, train entropy gap 0.7945 bits (loss 20.138, data 19.343) 
epoch 4 train loss 13.9942 nats / 20.1894 bits
time since start: 820.9 secs
Epoch 5 Iter 0, train entropy gap 0.8488 bits (loss 20.192, data 19.343) 
Epoch 5 Iter 200, train entropy gap 1.1590 bits (loss 20.502, data 19.343) 
Epoch 5 Iter 400, train entropy gap 0.6607 bits (loss 20.004, data 19.343) 
Epoch 5 Iter 600, train entropy gap 0.8834 bits (loss 20.227, data 19.343) 
Epoch 5 Iter 800, train entropy gap 0.7905 bits (loss 20.134, data 19.343) 
Epoch 5 Iter 1000, train entropy gap 1.1040 bits (loss 20.447, data 19.343) 
Epoch 5 Iter 1200, train entropy gap 0.8098 bits (loss 20.153, data 19.343) 
Epoch 5 Iter 1400, train entropy gap 0.6966 bits (loss 20.040, data 19.343) 
Epoch 5 Iter 1600, train entropy gap 0.9145 bits (loss 20.258, data 19.343) 
Epoch 5 Iter 1800, train entropy gap 0.7126 bits (loss 20.056, data 19.343) 
Epoch 5 Iter 2000, train entropy gap 0.8493 bits (loss 20.193, data 19.343) 
Epoch 5 Iter 2200, train entropy gap 0.9163 bits (loss 20.260, data 19.343) 
Epoch 5 Iter 2400, train entropy gap 0.8712 bits (loss 20.215, data 19.343) 
Epoch 5 Iter 2600, train entropy gap 0.9580 bits (loss 20.301, data 19.343) 
Epoch 5 Iter 2800, train entropy gap 0.7331 bits (loss 20.077, data 19.343) 
Epoch 5 Iter 3000, train entropy gap 0.7237 bits (loss 20.067, data 19.343) 
Epoch 5 Iter 3200, train entropy gap 0.8963 bits (loss 20.240, data 19.343) 
Epoch 5 Iter 3400, train entropy gap 0.9931 bits (loss 20.337, data 19.343) 
Epoch 5 Iter 3600, train entropy gap 0.9629 bits (loss 20.306, data 19.343) 
Epoch 5 Iter 3800, train entropy gap 0.7303 bits (loss 20.074, data 19.343) 
Epoch 5 Iter 4000, train entropy gap 0.8533 bits (loss 20.197, data 19.343) 
Epoch 5 Iter 4200, train entropy gap 0.7279 bits (loss 20.071, data 19.343) 
Epoch 5 Iter 4400, train entropy gap 0.6350 bits (loss 19.978, data 19.343) 
Epoch 5 Iter 4600, train entropy gap 0.7569 bits (loss 20.100, data 19.343) 
Epoch 5 Iter 4800, train entropy gap 0.6863 bits (loss 20.030, data 19.343) 
Epoch 5 Iter 5000, train entropy gap 0.9806 bits (loss 20.324, data 19.343) 
Epoch 5 Iter 5200, train entropy gap 0.8032 bits (loss 20.147, data 19.343) 
Epoch 5 Iter 5400, train entropy gap 0.9048 bits (loss 20.248, data 19.343) 
Epoch 5 Iter 5600, train entropy gap 0.8303 bits (loss 20.174, data 19.343) 
Epoch 5 Iter 5800, train entropy gap 0.9289 bits (loss 20.272, data 19.343) 
Epoch 5 Iter 6000, train entropy gap 0.5875 bits (loss 19.931, data 19.343) 
Epoch 5 Iter 6200, train entropy gap 0.8681 bits (loss 20.212, data 19.343) 
Epoch 5 Iter 6400, train entropy gap 0.9923 bits (loss 20.336, data 19.343) 
Epoch 5 Iter 6600, train entropy gap 0.7764 bits (loss 20.120, data 19.343) 
Epoch 5 Iter 6800, train entropy gap 0.8847 bits (loss 20.228, data 19.343) 
Epoch 5 Iter 7000, train entropy gap 0.7916 bits (loss 20.135, data 19.343) 
epoch 5 train loss 13.9902 nats / 20.1836 bits
time since start: 984.8 secs
Epoch 6 Iter 0, train entropy gap 0.7547 bits (loss 20.098, data 19.343) 
Epoch 6 Iter 200, train entropy gap 0.8860 bits (loss 20.230, data 19.343) 
Epoch 6 Iter 400, train entropy gap 0.8316 bits (loss 20.175, data 19.343) 
Epoch 6 Iter 600, train entropy gap 0.8826 bits (loss 20.226, data 19.343) 
Epoch 6 Iter 800, train entropy gap 0.8934 bits (loss 20.237, data 19.343) 
Epoch 6 Iter 1000, train entropy gap 0.8541 bits (loss 20.198, data 19.343) 
Epoch 6 Iter 1200, train entropy gap 0.9442 bits (loss 20.288, data 19.343) 
Epoch 6 Iter 1400, train entropy gap 0.8734 bits (loss 20.217, data 19.343) 
Epoch 6 Iter 1600, train entropy gap 0.6144 bits (loss 19.958, data 19.343) 
Epoch 6 Iter 1800, train entropy gap 0.9148 bits (loss 20.258, data 19.343) 
Epoch 6 Iter 2000, train entropy gap 0.8380 bits (loss 20.181, data 19.343) 
Epoch 6 Iter 2200, train entropy gap 0.9439 bits (loss 20.287, data 19.343) 
Epoch 6 Iter 2400, train entropy gap 0.8504 bits (loss 20.194, data 19.343) 
Epoch 6 Iter 2600, train entropy gap 0.8421 bits (loss 20.186, data 19.343) 
Epoch 6 Iter 2800, train entropy gap 0.9132 bits (loss 20.257, data 19.343) 
Epoch 6 Iter 3000, train entropy gap 0.9178 bits (loss 20.261, data 19.343) 
Epoch 6 Iter 3200, train entropy gap 0.9082 bits (loss 20.252, data 19.343) 
Epoch 6 Iter 3400, train entropy gap 0.9896 bits (loss 20.333, data 19.343) 
Epoch 6 Iter 3600, train entropy gap 0.8684 bits (loss 20.212, data 19.343) 
Epoch 6 Iter 3800, train entropy gap 0.8682 bits (loss 20.212, data 19.343) 
Epoch 6 Iter 4000, train entropy gap 0.5830 bits (loss 19.926, data 19.343) 
Epoch 6 Iter 4200, train entropy gap 0.6711 bits (loss 20.015, data 19.343) 
Epoch 6 Iter 4400, train entropy gap 0.8552 bits (loss 20.199, data 19.343) 
Epoch 6 Iter 4600, train entropy gap 0.7832 bits (loss 20.127, data 19.343) 
Epoch 6 Iter 4800, train entropy gap 0.8735 bits (loss 20.217, data 19.343) 
Epoch 6 Iter 5000, train entropy gap 0.8579 bits (loss 20.201, data 19.343) 
Epoch 6 Iter 5200, train entropy gap 0.5770 bits (loss 19.920, data 19.343) 
Epoch 6 Iter 5400, train entropy gap 0.6586 bits (loss 20.002, data 19.343) 
Epoch 6 Iter 5600, train entropy gap 1.0316 bits (loss 20.375, data 19.343) 
Epoch 6 Iter 5800, train entropy gap 0.6558 bits (loss 19.999, data 19.343) 
Epoch 6 Iter 6000, train entropy gap 0.7692 bits (loss 20.113, data 19.343) 
Epoch 6 Iter 6200, train entropy gap 0.6814 bits (loss 20.025, data 19.343) 
Epoch 6 Iter 6400, train entropy gap 0.8749 bits (loss 20.218, data 19.343) 
Epoch 6 Iter 6600, train entropy gap 0.7086 bits (loss 20.052, data 19.343) 
Epoch 6 Iter 6800, train entropy gap 0.7712 bits (loss 20.115, data 19.343) 
Epoch 6 Iter 7000, train entropy gap 0.9097 bits (loss 20.253, data 19.343) 
epoch 6 train loss 13.9869 nats / 20.1788 bits
time since start: 1149.0 secs
Epoch 7 Iter 0, train entropy gap 0.8900 bits (loss 20.233, data 19.343) 
Epoch 7 Iter 200, train entropy gap 0.5287 bits (loss 19.872, data 19.343) 
Epoch 7 Iter 400, train entropy gap 0.8760 bits (loss 20.219, data 19.343) 
Epoch 7 Iter 600, train entropy gap 0.7075 bits (loss 20.051, data 19.343) 
Epoch 7 Iter 800, train entropy gap 0.6500 bits (loss 19.993, data 19.343) 
Epoch 7 Iter 1000, train entropy gap 0.7362 bits (loss 20.080, data 19.343) 
Epoch 7 Iter 1200, train entropy gap 0.8203 bits (loss 20.164, data 19.343) 
Epoch 7 Iter 1400, train entropy gap 0.6202 bits (loss 19.964, data 19.343) 
Epoch 7 Iter 1600, train entropy gap 0.8488 bits (loss 20.192, data 19.343) 
Epoch 7 Iter 1800, train entropy gap 0.7899 bits (loss 20.133, data 19.343) 
Epoch 7 Iter 2000, train entropy gap 0.8456 bits (loss 20.189, data 19.343) 
Epoch 7 Iter 2200, train entropy gap 0.8328 bits (loss 20.176, data 19.343) 
Epoch 7 Iter 2400, train entropy gap 0.9131 bits (loss 20.257, data 19.343) 
Epoch 7 Iter 2600, train entropy gap 0.9013 bits (loss 20.245, data 19.343) 
Epoch 7 Iter 2800, train entropy gap 1.0115 bits (loss 20.355, data 19.343) 
Epoch 7 Iter 3000, train entropy gap 0.9116 bits (loss 20.255, data 19.343) 
Epoch 7 Iter 3200, train entropy gap 0.8495 bits (loss 20.193, data 19.343) 
Epoch 7 Iter 3400, train entropy gap 0.7006 bits (loss 20.044, data 19.343) 
Epoch 7 Iter 3600, train entropy gap 0.8569 bits (loss 20.200, data 19.343) 
Epoch 7 Iter 3800, train entropy gap 1.0487 bits (loss 20.392, data 19.343) 
Epoch 7 Iter 4000, train entropy gap 0.7593 bits (loss 20.103, data 19.343) 
Epoch 7 Iter 4200, train entropy gap 0.8386 bits (loss 20.182, data 19.343) 
Epoch 7 Iter 4400, train entropy gap 0.8038 bits (loss 20.147, data 19.343) 
Epoch 7 Iter 4600, train entropy gap 0.7917 bits (loss 20.135, data 19.343) 
Epoch 7 Iter 4800, train entropy gap 0.8635 bits (loss 20.207, data 19.343) 
Epoch 7 Iter 5000, train entropy gap 0.8802 bits (loss 20.224, data 19.343) 
Epoch 7 Iter 5200, train entropy gap 1.0215 bits (loss 20.365, data 19.343) 
Epoch 7 Iter 5400, train entropy gap 0.7513 bits (loss 20.095, data 19.343) 
Epoch 7 Iter 5600, train entropy gap 0.8357 bits (loss 20.179, data 19.343) 
Epoch 7 Iter 5800, train entropy gap 0.8869 bits (loss 20.230, data 19.343) 
Epoch 7 Iter 6000, train entropy gap 0.6959 bits (loss 20.039, data 19.343) 
Epoch 7 Iter 6200, train entropy gap 1.0509 bits (loss 20.394, data 19.343) 
Epoch 7 Iter 6400, train entropy gap 0.9777 bits (loss 20.321, data 19.343) 
Epoch 7 Iter 6600, train entropy gap 0.8269 bits (loss 20.170, data 19.343) 
Epoch 7 Iter 6800, train entropy gap 0.8598 bits (loss 20.203, data 19.343) 
Epoch 7 Iter 7000, train entropy gap 0.5323 bits (loss 19.876, data 19.343) 
epoch 7 train loss 13.9840 nats / 20.1747 bits
time since start: 1313.0 secs
Epoch 8 Iter 0, train entropy gap 0.8454 bits (loss 20.189, data 19.343) 
Epoch 8 Iter 200, train entropy gap 0.9401 bits (loss 20.284, data 19.343) 
Epoch 8 Iter 400, train entropy gap 0.6791 bits (loss 20.023, data 19.343) 
Epoch 8 Iter 600, train entropy gap 0.8747 bits (loss 20.218, data 19.343) 
Epoch 8 Iter 800, train entropy gap 0.9655 bits (loss 20.309, data 19.343) 
Epoch 8 Iter 1000, train entropy gap 0.5898 bits (loss 19.933, data 19.343) 
Epoch 8 Iter 1200, train entropy gap 0.8475 bits (loss 20.191, data 19.343) 
Epoch 8 Iter 1400, train entropy gap 0.8487 bits (loss 20.192, data 19.343) 
Epoch 8 Iter 1600, train entropy gap 0.6443 bits (loss 19.988, data 19.343) 
Epoch 8 Iter 1800, train entropy gap 0.9509 bits (loss 20.294, data 19.343) 
Epoch 8 Iter 2000, train entropy gap 1.0093 bits (loss 20.353, data 19.343) 
Epoch 8 Iter 2200, train entropy gap 0.5618 bits (loss 19.905, data 19.343) 
Epoch 8 Iter 2400, train entropy gap 0.8442 bits (loss 20.188, data 19.343) 
Epoch 8 Iter 2600, train entropy gap 0.7285 bits (loss 20.072, data 19.343) 
Epoch 8 Iter 2800, train entropy gap 0.7619 bits (loss 20.105, data 19.343) 
Epoch 8 Iter 3000, train entropy gap 0.8214 bits (loss 20.165, data 19.343) 
Epoch 8 Iter 3200, train entropy gap 0.8628 bits (loss 20.206, data 19.343) 
Epoch 8 Iter 3400, train entropy gap 1.0372 bits (loss 20.381, data 19.343) 
Epoch 8 Iter 3600, train entropy gap 0.8126 bits (loss 20.156, data 19.343) 
Epoch 8 Iter 3800, train entropy gap 0.6579 bits (loss 20.001, data 19.343) 
Epoch 8 Iter 4000, train entropy gap 0.8579 bits (loss 20.201, data 19.343) 
Epoch 8 Iter 4200, train entropy gap 0.7857 bits (loss 20.129, data 19.343) 
Epoch 8 Iter 4400, train entropy gap 0.8919 bits (loss 20.235, data 19.343) 
Epoch 8 Iter 4600, train entropy gap 0.7707 bits (loss 20.114, data 19.343) 
Epoch 8 Iter 4800, train entropy gap 0.7355 bits (loss 20.079, data 19.343) 
Epoch 8 Iter 5000, train entropy gap 0.9194 bits (loss 20.263, data 19.343) 
Epoch 8 Iter 5200, train entropy gap 0.9670 bits (loss 20.310, data 19.343) 
Epoch 8 Iter 5400, train entropy gap 0.5256 bits (loss 19.869, data 19.343) 
Epoch 8 Iter 5600, train entropy gap 0.8096 bits (loss 20.153, data 19.343) 
Epoch 8 Iter 5800, train entropy gap 0.7491 bits (loss 20.093, data 19.343) 
Epoch 8 Iter 6000, train entropy gap 0.8926 bits (loss 20.236, data 19.343) 
Epoch 8 Iter 6200, train entropy gap 0.6260 bits (loss 19.969, data 19.343) 
Epoch 8 Iter 6400, train entropy gap 0.8864 bits (loss 20.230, data 19.343) 
Epoch 8 Iter 6600, train entropy gap 1.0548 bits (loss 20.398, data 19.343) 
Epoch 8 Iter 6800, train entropy gap 0.9112 bits (loss 20.255, data 19.343) 
Epoch 8 Iter 7000, train entropy gap 0.7203 bits (loss 20.064, data 19.343) 
epoch 8 train loss 13.9821 nats / 20.1719 bits
time since start: 1476.8 secs
Epoch 9 Iter 0, train entropy gap 0.6568 bits (loss 20.000, data 19.343) 
Epoch 9 Iter 200, train entropy gap 0.9483 bits (loss 20.292, data 19.343) 
Epoch 9 Iter 400, train entropy gap 0.8601 bits (loss 20.204, data 19.343) 
Epoch 9 Iter 600, train entropy gap 0.9089 bits (loss 20.252, data 19.343) 
Epoch 9 Iter 800, train entropy gap 0.8544 bits (loss 20.198, data 19.343) 
Epoch 9 Iter 1000, train entropy gap 0.9273 bits (loss 20.271, data 19.343) 
Epoch 9 Iter 1200, train entropy gap 0.6190 bits (loss 19.962, data 19.343) 
Epoch 9 Iter 1400, train entropy gap 0.6718 bits (loss 20.015, data 19.343) 
Epoch 9 Iter 1600, train entropy gap 0.9179 bits (loss 20.261, data 19.343) 
Epoch 9 Iter 1800, train entropy gap 0.8270 bits (loss 20.170, data 19.343) 
Epoch 9 Iter 2000, train entropy gap 0.6935 bits (loss 20.037, data 19.343) 
Epoch 9 Iter 2200, train entropy gap 0.7280 bits (loss 20.071, data 19.343) 
Epoch 9 Iter 2400, train entropy gap 0.7439 bits (loss 20.087, data 19.343) 
Epoch 9 Iter 2600, train entropy gap 0.9250 bits (loss 20.268, data 19.343) 
Epoch 9 Iter 2800, train entropy gap 0.8463 bits (loss 20.190, data 19.343) 
Epoch 9 Iter 3000, train entropy gap 0.6867 bits (loss 20.030, data 19.343) 
Epoch 9 Iter 3200, train entropy gap 0.8741 bits (loss 20.218, data 19.343) 
Epoch 9 Iter 3400, train entropy gap 0.6009 bits (loss 19.944, data 19.343) 
Epoch 9 Iter 3600, train entropy gap 0.7108 bits (loss 20.054, data 19.343) 
Epoch 9 Iter 3800, train entropy gap 0.8110 bits (loss 20.154, data 19.343) 
Epoch 9 Iter 4000, train entropy gap 0.7795 bits (loss 20.123, data 19.343) 
Epoch 9 Iter 4200, train entropy gap 0.7683 bits (loss 20.112, data 19.343) 
Epoch 9 Iter 4400, train entropy gap 0.8485 bits (loss 20.192, data 19.343) 
Epoch 9 Iter 4600, train entropy gap 0.7063 bits (loss 20.050, data 19.343) 
Epoch 9 Iter 4800, train entropy gap 0.8352 bits (loss 20.179, data 19.343) 
Epoch 9 Iter 5000, train entropy gap 0.8314 bits (loss 20.175, data 19.343) 
Epoch 9 Iter 5200, train entropy gap 0.6560 bits (loss 19.999, data 19.343) 
Epoch 9 Iter 5400, train entropy gap 1.0378 bits (loss 20.381, data 19.343) 
Epoch 9 Iter 5600, train entropy gap 0.7454 bits (loss 20.089, data 19.343) 
Epoch 9 Iter 5800, train entropy gap 0.9708 bits (loss 20.314, data 19.343) 
Epoch 9 Iter 6000, train entropy gap 0.9228 bits (loss 20.266, data 19.343) 
Epoch 9 Iter 6200, train entropy gap 1.0383 bits (loss 20.382, data 19.343) 
Epoch 9 Iter 6400, train entropy gap 0.7020 bits (loss 20.045, data 19.343) 
Epoch 9 Iter 6600, train entropy gap 0.5518 bits (loss 19.895, data 19.343) 
Epoch 9 Iter 6800, train entropy gap 0.6109 bits (loss 19.954, data 19.343) 
Epoch 9 Iter 7000, train entropy gap 0.5638 bits (loss 19.907, data 19.343) 
epoch 9 train loss 13.9807 nats / 20.1699 bits
time since start: 1640.9 secs
Epoch 10 Iter 0, train entropy gap 0.7380 bits (loss 20.081, data 19.343) 
Epoch 10 Iter 200, train entropy gap 0.7014 bits (loss 20.045, data 19.343) 
Epoch 10 Iter 400, train entropy gap 0.9765 bits (loss 20.320, data 19.343) 
Epoch 10 Iter 600, train entropy gap 0.7525 bits (loss 20.096, data 19.343) 
Epoch 10 Iter 800, train entropy gap 0.6801 bits (loss 20.024, data 19.343) 
Epoch 10 Iter 1000, train entropy gap 0.6351 bits (loss 19.979, data 19.343) 
Epoch 10 Iter 1200, train entropy gap 0.7043 bits (loss 20.048, data 19.343) 
Epoch 10 Iter 1400, train entropy gap 0.9468 bits (loss 20.290, data 19.343) 
Epoch 10 Iter 1600, train entropy gap 0.6848 bits (loss 20.028, data 19.343) 
Epoch 10 Iter 1800, train entropy gap 0.7396 bits (loss 20.083, data 19.343) 
Epoch 10 Iter 2000, train entropy gap 1.0448 bits (loss 20.388, data 19.343) 
Epoch 10 Iter 2200, train entropy gap 1.0099 bits (loss 20.353, data 19.343) 
Epoch 10 Iter 2400, train entropy gap 0.7504 bits (loss 20.094, data 19.343) 
Epoch 10 Iter 2600, train entropy gap 0.9259 bits (loss 20.269, data 19.343) 
Epoch 10 Iter 2800, train entropy gap 0.6497 bits (loss 19.993, data 19.343) 
Epoch 10 Iter 3000, train entropy gap 0.8212 bits (loss 20.165, data 19.343) 
Epoch 10 Iter 3200, train entropy gap 0.8167 bits (loss 20.160, data 19.343) 
Epoch 10 Iter 3400, train entropy gap 0.6550 bits (loss 19.999, data 19.343) 
Epoch 10 Iter 3600, train entropy gap 0.9840 bits (loss 20.327, data 19.343) 
Epoch 10 Iter 3800, train entropy gap 0.6460 bits (loss 19.989, data 19.343) 
Epoch 10 Iter 4000, train entropy gap 0.8079 bits (loss 20.151, data 19.343) 
Epoch 10 Iter 4200, train entropy gap 1.0115 bits (loss 20.355, data 19.343) 
Epoch 10 Iter 4400, train entropy gap 0.7932 bits (loss 20.137, data 19.343) 
Epoch 10 Iter 4600, train entropy gap 0.7883 bits (loss 20.132, data 19.343) 
Epoch 10 Iter 4800, train entropy gap 0.6301 bits (loss 19.974, data 19.343) 
Epoch 10 Iter 5000, train entropy gap 0.8779 bits (loss 20.221, data 19.343) 
Epoch 10 Iter 5200, train entropy gap 0.9628 bits (loss 20.306, data 19.343) 
Epoch 10 Iter 5400, train entropy gap 0.8264 bits (loss 20.170, data 19.343) 
Epoch 10 Iter 5600, train entropy gap 0.7254 bits (loss 20.069, data 19.343) 
Epoch 10 Iter 5800, train entropy gap 0.8049 bits (loss 20.148, data 19.343) 
Epoch 10 Iter 6000, train entropy gap 0.6387 bits (loss 19.982, data 19.343) 
Epoch 10 Iter 6200, train entropy gap 1.1088 bits (loss 20.452, data 19.343) 
Epoch 10 Iter 6400, train entropy gap 0.9215 bits (loss 20.265, data 19.343) 
Epoch 10 Iter 6600, train entropy gap 0.6936 bits (loss 20.037, data 19.343) 
Epoch 10 Iter 6800, train entropy gap 0.7349 bits (loss 20.078, data 19.343) 
Epoch 10 Iter 7000, train entropy gap 0.8482 bits (loss 20.192, data 19.343) 
epoch 10 train loss 13.9794 nats / 20.1681 bits
time since start: 1804.8 secs
Epoch 11 Iter 0, train entropy gap 0.7596 bits (loss 20.103, data 19.343) 
Epoch 11 Iter 200, train entropy gap 0.7941 bits (loss 20.138, data 19.343) 
Epoch 11 Iter 400, train entropy gap 0.7928 bits (loss 20.136, data 19.343) 
Epoch 11 Iter 600, train entropy gap 0.8483 bits (loss 20.192, data 19.343) 
Epoch 11 Iter 800, train entropy gap 0.7345 bits (loss 20.078, data 19.343) 
Epoch 11 Iter 1000, train entropy gap 0.6225 bits (loss 19.966, data 19.343) 
Epoch 11 Iter 1200, train entropy gap 0.7788 bits (loss 20.122, data 19.343) 
Epoch 11 Iter 1400, train entropy gap 0.7063 bits (loss 20.050, data 19.343) 
Epoch 11 Iter 1600, train entropy gap 0.9492 bits (loss 20.293, data 19.343) 
Epoch 11 Iter 1800, train entropy gap 0.8563 bits (loss 20.200, data 19.343) 
Epoch 11 Iter 2000, train entropy gap 1.0962 bits (loss 20.440, data 19.343) 
Epoch 11 Iter 2200, train entropy gap 0.6893 bits (loss 20.033, data 19.343) 
Epoch 11 Iter 2400, train entropy gap 0.8422 bits (loss 20.186, data 19.343) 
Epoch 11 Iter 2600, train entropy gap 0.8193 bits (loss 20.163, data 19.343) 
Epoch 11 Iter 2800, train entropy gap 0.8107 bits (loss 20.154, data 19.343) 
Epoch 11 Iter 3000, train entropy gap 0.6715 bits (loss 20.015, data 19.343) 
Epoch 11 Iter 3200, train entropy gap 0.6393 bits (loss 19.983, data 19.343) 
Epoch 11 Iter 3400, train entropy gap 0.9394 bits (loss 20.283, data 19.343) 
Epoch 11 Iter 3600, train entropy gap 0.8169 bits (loss 20.160, data 19.343) 
Epoch 11 Iter 3800, train entropy gap 0.6432 bits (loss 19.987, data 19.343) 
Epoch 11 Iter 4000, train entropy gap 0.9510 bits (loss 20.294, data 19.343) 
Epoch 11 Iter 4200, train entropy gap 0.7364 bits (loss 20.080, data 19.343) 
Epoch 11 Iter 4400, train entropy gap 0.8960 bits (loss 20.239, data 19.343) 
Epoch 11 Iter 4600, train entropy gap 0.8985 bits (loss 20.242, data 19.343) 
Epoch 11 Iter 4800, train entropy gap 0.9643 bits (loss 20.308, data 19.343) 
Epoch 11 Iter 5000, train entropy gap 0.9190 bits (loss 20.263, data 19.343) 
Epoch 11 Iter 5200, train entropy gap 0.9993 bits (loss 20.343, data 19.343) 
Epoch 11 Iter 5400, train entropy gap 0.9189 bits (loss 20.262, data 19.343) 
Epoch 11 Iter 5600, train entropy gap 0.7610 bits (loss 20.105, data 19.343) 
Epoch 11 Iter 5800, train entropy gap 0.9015 bits (loss 20.245, data 19.343) 
Epoch 11 Iter 6000, train entropy gap 0.9077 bits (loss 20.251, data 19.343) 
Epoch 11 Iter 6200, train entropy gap 0.9699 bits (loss 20.313, data 19.343) 
Epoch 11 Iter 6400, train entropy gap 0.9135 bits (loss 20.257, data 19.343) 
Epoch 11 Iter 6600, train entropy gap 0.9558 bits (loss 20.299, data 19.343) 
Epoch 11 Iter 6800, train entropy gap 0.8923 bits (loss 20.236, data 19.343) 
Epoch 11 Iter 7000, train entropy gap 0.8781 bits (loss 20.222, data 19.343) 
epoch 11 train loss 13.9782 nats / 20.1663 bits
time since start: 1968.9 secs
Epoch 12 Iter 0, train entropy gap 0.7213 bits (loss 20.065, data 19.343) 
Epoch 12 Iter 200, train entropy gap 0.8492 bits (loss 20.193, data 19.343) 
Epoch 12 Iter 400, train entropy gap 0.7620 bits (loss 20.106, data 19.343) 
Epoch 12 Iter 600, train entropy gap 0.6150 bits (loss 19.958, data 19.343) 
Epoch 12 Iter 800, train entropy gap 0.9844 bits (loss 20.328, data 19.343) 
Epoch 12 Iter 1000, train entropy gap 0.8258 bits (loss 20.169, data 19.343) 
Epoch 12 Iter 1200, train entropy gap 0.8682 bits (loss 20.212, data 19.343) 
Epoch 12 Iter 1400, train entropy gap 0.7286 bits (loss 20.072, data 19.343) 
Epoch 12 Iter 1600, train entropy gap 0.8352 bits (loss 20.179, data 19.343) 
Epoch 12 Iter 1800, train entropy gap 0.9268 bits (loss 20.270, data 19.343) 
Epoch 12 Iter 2000, train entropy gap 0.8179 bits (loss 20.161, data 19.343) 
Epoch 12 Iter 2200, train entropy gap 0.9503 bits (loss 20.294, data 19.343) 
Epoch 12 Iter 2400, train entropy gap 0.7987 bits (loss 20.142, data 19.343) 
Epoch 12 Iter 2600, train entropy gap 0.8923 bits (loss 20.236, data 19.343) 
Epoch 12 Iter 2800, train entropy gap 0.8559 bits (loss 20.199, data 19.343) 
Epoch 12 Iter 3000, train entropy gap 0.7406 bits (loss 20.084, data 19.343) 
Epoch 12 Iter 3200, train entropy gap 0.7247 bits (loss 20.068, data 19.343) 
Epoch 12 Iter 3400, train entropy gap 0.6816 bits (loss 20.025, data 19.343) 
Epoch 12 Iter 3600, train entropy gap 0.8432 bits (loss 20.187, data 19.343) 
Epoch 12 Iter 3800, train entropy gap 0.8381 bits (loss 20.182, data 19.343) 
Epoch 12 Iter 4000, train entropy gap 0.8913 bits (loss 20.235, data 19.343) 
Epoch 12 Iter 4200, train entropy gap 0.7682 bits (loss 20.112, data 19.343) 
Epoch 12 Iter 4400, train entropy gap 0.7939 bits (loss 20.137, data 19.343) 
Epoch 12 Iter 4600, train entropy gap 0.7267 bits (loss 20.070, data 19.343) 
Epoch 12 Iter 4800, train entropy gap 0.7673 bits (loss 20.111, data 19.343) 
Epoch 12 Iter 5000, train entropy gap 0.8360 bits (loss 20.179, data 19.343) 
Epoch 12 Iter 5200, train entropy gap 0.7326 bits (loss 20.076, data 19.343) 
Epoch 12 Iter 5400, train entropy gap 0.9669 bits (loss 20.310, data 19.343) 
Epoch 12 Iter 5600, train entropy gap 0.8415 bits (loss 20.185, data 19.343) 
Epoch 12 Iter 5800, train entropy gap 0.6389 bits (loss 19.982, data 19.343) 
Epoch 12 Iter 6000, train entropy gap 0.9103 bits (loss 20.254, data 19.343) 
Epoch 12 Iter 6200, train entropy gap 0.8691 bits (loss 20.213, data 19.343) 
Epoch 12 Iter 6400, train entropy gap 0.6771 bits (loss 20.021, data 19.343) 
Epoch 12 Iter 6600, train entropy gap 0.8271 bits (loss 20.171, data 19.343) 
Epoch 12 Iter 6800, train entropy gap 0.9346 bits (loss 20.278, data 19.343) 
Epoch 12 Iter 7000, train entropy gap 0.9075 bits (loss 20.251, data 19.343) 
epoch 12 train loss 13.9772 nats / 20.1648 bits
time since start: 2133.4 secs
Epoch 13 Iter 0, train entropy gap 0.8046 bits (loss 20.148, data 19.343) 
Epoch 13 Iter 200, train entropy gap 0.7992 bits (loss 20.143, data 19.343) 
Epoch 13 Iter 400, train entropy gap 1.0167 bits (loss 20.360, data 19.343) 
Epoch 13 Iter 600, train entropy gap 0.7445 bits (loss 20.088, data 19.343) 
Epoch 13 Iter 800, train entropy gap 0.7308 bits (loss 20.074, data 19.343) 
Epoch 13 Iter 1000, train entropy gap 0.8341 bits (loss 20.178, data 19.343) 
Epoch 13 Iter 1200, train entropy gap 0.6590 bits (loss 20.002, data 19.343) 
Epoch 13 Iter 1400, train entropy gap 0.9749 bits (loss 20.318, data 19.343) 
Epoch 13 Iter 1600, train entropy gap 0.8257 bits (loss 20.169, data 19.343) 
Epoch 13 Iter 1800, train entropy gap 0.7028 bits (loss 20.046, data 19.343) 
Epoch 13 Iter 2000, train entropy gap 0.8907 bits (loss 20.234, data 19.343) 
Epoch 13 Iter 2200, train entropy gap 0.8748 bits (loss 20.218, data 19.343) 
Epoch 13 Iter 2400, train entropy gap 0.6369 bits (loss 19.980, data 19.343) 
Epoch 13 Iter 2600, train entropy gap 0.8279 bits (loss 20.171, data 19.343) 
Epoch 13 Iter 2800, train entropy gap 0.6758 bits (loss 20.019, data 19.343) 
Epoch 13 Iter 3000, train entropy gap 0.8027 bits (loss 20.146, data 19.343) 
Epoch 13 Iter 3200, train entropy gap 1.0800 bits (loss 20.423, data 19.343) 
Epoch 13 Iter 3400, train entropy gap 0.7997 bits (loss 20.143, data 19.343) 
Epoch 13 Iter 3600, train entropy gap 0.8416 bits (loss 20.185, data 19.343) 
Epoch 13 Iter 3800, train entropy gap 0.8163 bits (loss 20.160, data 19.343) 
Epoch 13 Iter 4000, train entropy gap 0.8179 bits (loss 20.161, data 19.343) 
Epoch 13 Iter 4200, train entropy gap 0.8044 bits (loss 20.148, data 19.343) 
Epoch 13 Iter 4400, train entropy gap 0.8629 bits (loss 20.206, data 19.343) 
Epoch 13 Iter 4600, train entropy gap 0.6891 bits (loss 20.033, data 19.343) 
Epoch 13 Iter 4800, train entropy gap 0.7909 bits (loss 20.134, data 19.343) 
Epoch 13 Iter 5000, train entropy gap 0.8221 bits (loss 20.166, data 19.343) 
Epoch 13 Iter 5200, train entropy gap 0.8041 bits (loss 20.148, data 19.343) 
Epoch 13 Iter 5400, train entropy gap 0.9337 bits (loss 20.277, data 19.343) 
Epoch 13 Iter 5600, train entropy gap 0.8003 bits (loss 20.144, data 19.343) 
Epoch 13 Iter 5800, train entropy gap 0.6735 bits (loss 20.017, data 19.343) 
Epoch 13 Iter 6000, train entropy gap 0.9629 bits (loss 20.306, data 19.343) 
Epoch 13 Iter 6200, train entropy gap 0.7715 bits (loss 20.115, data 19.343) 
Epoch 13 Iter 6400, train entropy gap 0.7922 bits (loss 20.136, data 19.343) 
Epoch 13 Iter 6600, train entropy gap 0.8543 bits (loss 20.198, data 19.343) 
Epoch 13 Iter 6800, train entropy gap 0.7199 bits (loss 20.063, data 19.343) 
Epoch 13 Iter 7000, train entropy gap 0.8924 bits (loss 20.236, data 19.343) 
epoch 13 train loss 13.9762 nats / 20.1634 bits
time since start: 2297.7 secs
Epoch 14 Iter 0, train entropy gap 0.9694 bits (loss 20.313, data 19.343) 
Epoch 14 Iter 200, train entropy gap 0.8142 bits (loss 20.158, data 19.343) 
Epoch 14 Iter 400, train entropy gap 0.7110 bits (loss 20.054, data 19.343) 
Epoch 14 Iter 600, train entropy gap 0.7231 bits (loss 20.067, data 19.343) 
Epoch 14 Iter 800, train entropy gap 0.8495 bits (loss 20.193, data 19.343) 
Epoch 14 Iter 1000, train entropy gap 0.8335 bits (loss 20.177, data 19.343) 
Epoch 14 Iter 1200, train entropy gap 0.8917 bits (loss 20.235, data 19.343) 
Epoch 14 Iter 1400, train entropy gap 0.6758 bits (loss 20.019, data 19.343) 
Epoch 14 Iter 1600, train entropy gap 0.9563 bits (loss 20.300, data 19.343) 
Epoch 14 Iter 1800, train entropy gap 0.8289 bits (loss 20.172, data 19.343) 
Epoch 14 Iter 2000, train entropy gap 0.8831 bits (loss 20.227, data 19.343) 
Epoch 14 Iter 2200, train entropy gap 1.1197 bits (loss 20.463, data 19.343) 
Epoch 14 Iter 2400, train entropy gap 0.7055 bits (loss 20.049, data 19.343) 
Epoch 14 Iter 2600, train entropy gap 0.7783 bits (loss 20.122, data 19.343) 
Epoch 14 Iter 2800, train entropy gap 0.8114 bits (loss 20.155, data 19.343) 
Epoch 14 Iter 3000, train entropy gap 0.7504 bits (loss 20.094, data 19.343) 
Epoch 14 Iter 3200, train entropy gap 0.7797 bits (loss 20.123, data 19.343) 
Epoch 14 Iter 3400, train entropy gap 0.6912 bits (loss 20.035, data 19.343) 
Epoch 14 Iter 3600, train entropy gap 0.7300 bits (loss 20.073, data 19.343) 
Epoch 14 Iter 3800, train entropy gap 0.9261 bits (loss 20.270, data 19.343) 
Epoch 14 Iter 4000, train entropy gap 0.6058 bits (loss 19.949, data 19.343) 
Epoch 14 Iter 4200, train entropy gap 0.9081 bits (loss 20.252, data 19.343) 
Epoch 14 Iter 4400, train entropy gap 0.8725 bits (loss 20.216, data 19.343) 
Epoch 14 Iter 4600, train entropy gap 0.9424 bits (loss 20.286, data 19.343) 
Epoch 14 Iter 4800, train entropy gap 0.9632 bits (loss 20.307, data 19.343) 
Epoch 14 Iter 5000, train entropy gap 0.8757 bits (loss 20.219, data 19.343) 
Epoch 14 Iter 5200, train entropy gap 0.7661 bits (loss 20.110, data 19.343) 
Epoch 14 Iter 5400, train entropy gap 0.9324 bits (loss 20.276, data 19.343) 
Epoch 14 Iter 5600, train entropy gap 1.0179 bits (loss 20.361, data 19.343) 
Epoch 14 Iter 5800, train entropy gap 0.8716 bits (loss 20.215, data 19.343) 
Epoch 14 Iter 6000, train entropy gap 0.6388 bits (loss 19.982, data 19.343) 
Epoch 14 Iter 6200, train entropy gap 0.7799 bits (loss 20.123, data 19.343) 
Epoch 14 Iter 6400, train entropy gap 0.8090 bits (loss 20.152, data 19.343) 
Epoch 14 Iter 6600, train entropy gap 0.5429 bits (loss 19.886, data 19.343) 
Epoch 14 Iter 6800, train entropy gap 0.7167 bits (loss 20.060, data 19.343) 
Epoch 14 Iter 7000, train entropy gap 0.9215 bits (loss 20.265, data 19.343) 
epoch 14 train loss 13.9739 nats / 20.1601 bits
time since start: 2461.7 secs
Epoch 15 Iter 0, train entropy gap 0.5900 bits (loss 19.933, data 19.343) 
Epoch 15 Iter 200, train entropy gap 0.8050 bits (loss 20.148, data 19.343) 
Epoch 15 Iter 400, train entropy gap 0.7768 bits (loss 20.120, data 19.343) 
Epoch 15 Iter 600, train entropy gap 0.7330 bits (loss 20.077, data 19.343) 
Epoch 15 Iter 800, train entropy gap 0.8792 bits (loss 20.223, data 19.343) 
Epoch 15 Iter 1000, train entropy gap 0.7574 bits (loss 20.101, data 19.343) 
Epoch 15 Iter 1200, train entropy gap 0.6324 bits (loss 19.976, data 19.343) 
Epoch 15 Iter 1400, train entropy gap 0.7567 bits (loss 20.100, data 19.343) 
Epoch 15 Iter 1600, train entropy gap 0.9173 bits (loss 20.261, data 19.343) 
Epoch 15 Iter 1800, train entropy gap 0.6372 bits (loss 19.981, data 19.343) 
Epoch 15 Iter 2000, train entropy gap 0.7525 bits (loss 20.096, data 19.343) 
Epoch 15 Iter 2200, train entropy gap 0.7562 bits (loss 20.100, data 19.343) 
Epoch 15 Iter 2400, train entropy gap 0.7527 bits (loss 20.096, data 19.343) 
Epoch 15 Iter 2600, train entropy gap 0.7316 bits (loss 20.075, data 19.343) 
Epoch 15 Iter 2800, train entropy gap 0.8319 bits (loss 20.175, data 19.343) 
Epoch 15 Iter 3000, train entropy gap 0.9497 bits (loss 20.293, data 19.343) 
Epoch 15 Iter 3200, train entropy gap 0.7316 bits (loss 20.075, data 19.343) 
Epoch 15 Iter 3400, train entropy gap 0.7024 bits (loss 20.046, data 19.343) 
Epoch 15 Iter 3600, train entropy gap 0.8163 bits (loss 20.160, data 19.343) 
Epoch 15 Iter 3800, train entropy gap 0.8838 bits (loss 20.227, data 19.343) 
Epoch 15 Iter 4000, train entropy gap 0.7565 bits (loss 20.100, data 19.343) 
Epoch 15 Iter 4200, train entropy gap 0.7671 bits (loss 20.111, data 19.343) 
Epoch 15 Iter 4400, train entropy gap 0.9389 bits (loss 20.282, data 19.343) 
Epoch 15 Iter 4600, train entropy gap 0.9455 bits (loss 20.289, data 19.343) 
Epoch 15 Iter 4800, train entropy gap 0.6476 bits (loss 19.991, data 19.343) 
Epoch 15 Iter 5000, train entropy gap 0.7777 bits (loss 20.121, data 19.343) 
Epoch 15 Iter 5200, train entropy gap 0.9824 bits (loss 20.326, data 19.343) 
Epoch 15 Iter 5400, train entropy gap 0.7011 bits (loss 20.045, data 19.343) 
Epoch 15 Iter 5600, train entropy gap 0.8230 bits (loss 20.166, data 19.343) 
Epoch 15 Iter 5800, train entropy gap 0.7552 bits (loss 20.099, data 19.343) 
Epoch 15 Iter 6000, train entropy gap 0.7377 bits (loss 20.081, data 19.343) 
Epoch 15 Iter 6200, train entropy gap 0.9464 bits (loss 20.290, data 19.343) 
Epoch 15 Iter 6400, train entropy gap 0.8499 bits (loss 20.193, data 19.343) 
Epoch 15 Iter 6600, train entropy gap 0.7174 bits (loss 20.061, data 19.343) 
Epoch 15 Iter 6800, train entropy gap 0.8751 bits (loss 20.219, data 19.343) 
Epoch 15 Iter 7000, train entropy gap 0.8949 bits (loss 20.238, data 19.343) 
epoch 15 train loss 13.9727 nats / 20.1583 bits
time since start: 2625.7 secs
Epoch 16 Iter 0, train entropy gap 1.2205 bits (loss 20.564, data 19.343) 
Epoch 16 Iter 200, train entropy gap 0.7038 bits (loss 20.047, data 19.343) 
Epoch 16 Iter 400, train entropy gap 0.8356 bits (loss 20.179, data 19.343) 
Epoch 16 Iter 600, train entropy gap 0.8686 bits (loss 20.212, data 19.343) 
Epoch 16 Iter 800, train entropy gap 0.9078 bits (loss 20.251, data 19.343) 
Epoch 16 Iter 1000, train entropy gap 0.6923 bits (loss 20.036, data 19.343) 
Epoch 16 Iter 1200, train entropy gap 0.9291 bits (loss 20.273, data 19.343) 
Epoch 16 Iter 1400, train entropy gap 0.7648 bits (loss 20.108, data 19.343) 
Epoch 16 Iter 1600, train entropy gap 0.9257 bits (loss 20.269, data 19.343) 
Epoch 16 Iter 1800, train entropy gap 0.9240 bits (loss 20.268, data 19.343) 
Epoch 16 Iter 2000, train entropy gap 0.7059 bits (loss 20.049, data 19.343) 
Epoch 16 Iter 2200, train entropy gap 0.7793 bits (loss 20.123, data 19.343) 
Epoch 16 Iter 2400, train entropy gap 0.9206 bits (loss 20.264, data 19.343) 
Epoch 16 Iter 2600, train entropy gap 0.8161 bits (loss 20.160, data 19.343) 
Epoch 16 Iter 2800, train entropy gap 0.7605 bits (loss 20.104, data 19.343) 
Epoch 16 Iter 3000, train entropy gap 0.7682 bits (loss 20.112, data 19.343) 
Epoch 16 Iter 3200, train entropy gap 0.8191 bits (loss 20.163, data 19.343) 
Epoch 16 Iter 3400, train entropy gap 0.8434 bits (loss 20.187, data 19.343) 
Epoch 16 Iter 3600, train entropy gap 0.8197 bits (loss 20.163, data 19.343) 
Epoch 16 Iter 3800, train entropy gap 0.8464 bits (loss 20.190, data 19.343) 
Epoch 16 Iter 4000, train entropy gap 0.7228 bits (loss 20.066, data 19.343) 
Epoch 16 Iter 4200, train entropy gap 0.5921 bits (loss 19.936, data 19.343) 
Epoch 16 Iter 4400, train entropy gap 0.7971 bits (loss 20.141, data 19.343) 
Epoch 16 Iter 4600, train entropy gap 0.6684 bits (loss 20.012, data 19.343) 
Epoch 16 Iter 4800, train entropy gap 0.7424 bits (loss 20.086, data 19.343) 
Epoch 16 Iter 5000, train entropy gap 0.8757 bits (loss 20.219, data 19.343) 
Epoch 16 Iter 5200, train entropy gap 0.9027 bits (loss 20.246, data 19.343) 
Epoch 16 Iter 5400, train entropy gap 0.8724 bits (loss 20.216, data 19.343) 
Epoch 16 Iter 5600, train entropy gap 0.7204 bits (loss 20.064, data 19.343) 
Epoch 16 Iter 5800, train entropy gap 0.8080 bits (loss 20.151, data 19.343) 
Epoch 16 Iter 6000, train entropy gap 0.7537 bits (loss 20.097, data 19.343) 
Epoch 16 Iter 6200, train entropy gap 0.5138 bits (loss 19.857, data 19.343) 
Epoch 16 Iter 6400, train entropy gap 0.8239 bits (loss 20.167, data 19.343) 
Epoch 16 Iter 6600, train entropy gap 0.8367 bits (loss 20.180, data 19.343) 
Epoch 16 Iter 6800, train entropy gap 0.9796 bits (loss 20.323, data 19.343) 
Epoch 16 Iter 7000, train entropy gap 1.0623 bits (loss 20.406, data 19.343) 
epoch 16 train loss 13.9717 nats / 20.1569 bits
time since start: 2789.9 secs
Epoch 17 Iter 0, train entropy gap 0.7540 bits (loss 20.098, data 19.343) 
Epoch 17 Iter 200, train entropy gap 0.8590 bits (loss 20.202, data 19.343) 
Epoch 17 Iter 400, train entropy gap 0.6650 bits (loss 20.008, data 19.343) 
Epoch 17 Iter 600, train entropy gap 0.7816 bits (loss 20.125, data 19.343) 
Epoch 17 Iter 800, train entropy gap 0.8409 bits (loss 20.184, data 19.343) 
Epoch 17 Iter 1000, train entropy gap 0.8760 bits (loss 20.219, data 19.343) 
Epoch 17 Iter 1200, train entropy gap 0.7186 bits (loss 20.062, data 19.343) 
Epoch 17 Iter 1400, train entropy gap 1.1468 bits (loss 20.490, data 19.343) 
Epoch 17 Iter 1600, train entropy gap 0.7395 bits (loss 20.083, data 19.343) 
Epoch 17 Iter 1800, train entropy gap 0.7508 bits (loss 20.094, data 19.343) 
Epoch 17 Iter 2000, train entropy gap 0.9435 bits (loss 20.287, data 19.343) 
Epoch 17 Iter 2200, train entropy gap 0.9305 bits (loss 20.274, data 19.343) 
Epoch 17 Iter 2400, train entropy gap 0.6903 bits (loss 20.034, data 19.343) 
Epoch 17 Iter 2600, train entropy gap 0.8249 bits (loss 20.168, data 19.343) 
Epoch 17 Iter 2800, train entropy gap 0.7352 bits (loss 20.079, data 19.343) 
Epoch 17 Iter 3000, train entropy gap 0.9325 bits (loss 20.276, data 19.343) 
Epoch 17 Iter 3200, train entropy gap 0.8545 bits (loss 20.198, data 19.343) 
Epoch 17 Iter 3400, train entropy gap 0.9605 bits (loss 20.304, data 19.343) 
Epoch 17 Iter 3600, train entropy gap 0.9201 bits (loss 20.264, data 19.343) 
Epoch 17 Iter 3800, train entropy gap 0.7680 bits (loss 20.111, data 19.343) 
Epoch 17 Iter 4000, train entropy gap 0.9433 bits (loss 20.287, data 19.343) 
Epoch 17 Iter 4200, train entropy gap 0.8106 bits (loss 20.154, data 19.343) 
Epoch 17 Iter 4400, train entropy gap 0.8347 bits (loss 20.178, data 19.343) 
Epoch 17 Iter 4600, train entropy gap 1.0010 bits (loss 20.344, data 19.343) 
Epoch 17 Iter 4800, train entropy gap 0.6587 bits (loss 20.002, data 19.343) 
Epoch 17 Iter 5000, train entropy gap 0.8602 bits (loss 20.204, data 19.343) 
Epoch 17 Iter 5200, train entropy gap 0.8858 bits (loss 20.229, data 19.343) 
Epoch 17 Iter 5400, train entropy gap 0.9358 bits (loss 20.279, data 19.343) 
Epoch 17 Iter 5600, train entropy gap 0.7442 bits (loss 20.088, data 19.343) 
Epoch 17 Iter 5800, train entropy gap 0.9637 bits (loss 20.307, data 19.343) 
Epoch 17 Iter 6000, train entropy gap 0.5907 bits (loss 19.934, data 19.343) 
Epoch 17 Iter 6200, train entropy gap 0.6798 bits (loss 20.023, data 19.343) 
Epoch 17 Iter 6400, train entropy gap 0.7750 bits (loss 20.118, data 19.343) 
Epoch 17 Iter 6600, train entropy gap 0.7697 bits (loss 20.113, data 19.343) 
Epoch 17 Iter 6800, train entropy gap 0.8576 bits (loss 20.201, data 19.343) 
Epoch 17 Iter 7000, train entropy gap 0.7159 bits (loss 20.059, data 19.343) 
epoch 17 train loss 13.9706 nats / 20.1554 bits
time since start: 2954.1 secs
Epoch 18 Iter 0, train entropy gap 0.9709 bits (loss 20.314, data 19.343) 
Epoch 18 Iter 200, train entropy gap 0.9105 bits (loss 20.254, data 19.343) 
Epoch 18 Iter 400, train entropy gap 0.8811 bits (loss 20.225, data 19.343) 
Epoch 18 Iter 600, train entropy gap 0.8306 bits (loss 20.174, data 19.343) 
Epoch 18 Iter 800, train entropy gap 0.6313 bits (loss 19.975, data 19.343) 
Epoch 18 Iter 1000, train entropy gap 0.6510 bits (loss 19.994, data 19.343) 
Epoch 18 Iter 1200, train entropy gap 0.9444 bits (loss 20.288, data 19.343) 
Epoch 18 Iter 1400, train entropy gap 0.9010 bits (loss 20.244, data 19.343) 
Epoch 18 Iter 1600, train entropy gap 0.8919 bits (loss 20.235, data 19.343) 
Epoch 18 Iter 1800, train entropy gap 0.8569 bits (loss 20.200, data 19.343) 
Epoch 18 Iter 2000, train entropy gap 0.7951 bits (loss 20.139, data 19.343) 
Epoch 18 Iter 2200, train entropy gap 0.8312 bits (loss 20.175, data 19.343) 
Epoch 18 Iter 2400, train entropy gap 0.9420 bits (loss 20.285, data 19.343) 
Epoch 18 Iter 2600, train entropy gap 0.8395 bits (loss 20.183, data 19.343) 
Epoch 18 Iter 2800, train entropy gap 1.0352 bits (loss 20.379, data 19.343) 
Epoch 18 Iter 3000, train entropy gap 0.8902 bits (loss 20.234, data 19.343) 
Epoch 18 Iter 3200, train entropy gap 0.8231 bits (loss 20.167, data 19.343) 
Epoch 18 Iter 3400, train entropy gap 0.4566 bits (loss 19.800, data 19.343) 
Epoch 18 Iter 3600, train entropy gap 0.9000 bits (loss 20.243, data 19.343) 
Epoch 18 Iter 3800, train entropy gap 0.7814 bits (loss 20.125, data 19.343) 
Epoch 18 Iter 4000, train entropy gap 1.0093 bits (loss 20.353, data 19.343) 
Epoch 18 Iter 4200, train entropy gap 0.8400 bits (loss 20.184, data 19.343) 
Epoch 18 Iter 4400, train entropy gap 0.7219 bits (loss 20.065, data 19.343) 
Epoch 18 Iter 4600, train entropy gap 0.7660 bits (loss 20.109, data 19.343) 
Epoch 18 Iter 4800, train entropy gap 0.7655 bits (loss 20.109, data 19.343) 
Epoch 18 Iter 5000, train entropy gap 0.6766 bits (loss 20.020, data 19.343) 
Epoch 18 Iter 5200, train entropy gap 0.6739 bits (loss 20.017, data 19.343) 
Epoch 18 Iter 5400, train entropy gap 0.7451 bits (loss 20.089, data 19.343) 
Epoch 18 Iter 5600, train entropy gap 0.7324 bits (loss 20.076, data 19.343) 
Epoch 18 Iter 5800, train entropy gap 0.7723 bits (loss 20.116, data 19.343) 
Epoch 18 Iter 6000, train entropy gap 0.7539 bits (loss 20.097, data 19.343) 
Epoch 18 Iter 6200, train entropy gap 0.6872 bits (loss 20.031, data 19.343) 
Epoch 18 Iter 6400, train entropy gap 0.9408 bits (loss 20.284, data 19.343) 
Epoch 18 Iter 6600, train entropy gap 0.8277 bits (loss 20.171, data 19.343) 
Epoch 18 Iter 6800, train entropy gap 0.7281 bits (loss 20.072, data 19.343) 
Epoch 18 Iter 7000, train entropy gap 0.7117 bits (loss 20.055, data 19.343) 
epoch 18 train loss 13.9698 nats / 20.1542 bits
time since start: 3118.2 secs
Epoch 19 Iter 0, train entropy gap 0.6808 bits (loss 20.024, data 19.343) 
Epoch 19 Iter 200, train entropy gap 0.7997 bits (loss 20.143, data 19.343) 
Epoch 19 Iter 400, train entropy gap 0.9115 bits (loss 20.255, data 19.343) 
Epoch 19 Iter 600, train entropy gap 0.8668 bits (loss 20.210, data 19.343) 
Epoch 19 Iter 800, train entropy gap 0.8038 bits (loss 20.147, data 19.343) 
Epoch 19 Iter 1000, train entropy gap 0.8415 bits (loss 20.185, data 19.343) 
Epoch 19 Iter 1200, train entropy gap 0.8765 bits (loss 20.220, data 19.343) 
Epoch 19 Iter 1400, train entropy gap 0.8124 bits (loss 20.156, data 19.343) 
Epoch 19 Iter 1600, train entropy gap 0.7922 bits (loss 20.136, data 19.343) 
Epoch 19 Iter 1800, train entropy gap 0.8940 bits (loss 20.237, data 19.343) 
Epoch 19 Iter 2000, train entropy gap 0.9428 bits (loss 20.286, data 19.343) 
Epoch 19 Iter 2200, train entropy gap 0.8607 bits (loss 20.204, data 19.343) 
Epoch 19 Iter 2400, train entropy gap 0.8329 bits (loss 20.176, data 19.343) 
Epoch 19 Iter 2600, train entropy gap 0.7707 bits (loss 20.114, data 19.343) 
Epoch 19 Iter 2800, train entropy gap 0.9711 bits (loss 20.315, data 19.343) 
Epoch 19 Iter 3000, train entropy gap 1.1022 bits (loss 20.446, data 19.343) 
Epoch 19 Iter 3200, train entropy gap 0.7463 bits (loss 20.090, data 19.343) 
Epoch 19 Iter 3400, train entropy gap 0.9407 bits (loss 20.284, data 19.343) 
Epoch 19 Iter 3600, train entropy gap 0.7860 bits (loss 20.130, data 19.343) 
Epoch 19 Iter 3800, train entropy gap 0.6887 bits (loss 20.032, data 19.343) 
Epoch 19 Iter 4000, train entropy gap 0.6970 bits (loss 20.040, data 19.343) 
Epoch 19 Iter 4200, train entropy gap 1.0173 bits (loss 20.361, data 19.343) 
Epoch 19 Iter 4400, train entropy gap 0.8948 bits (loss 20.238, data 19.343) 
Epoch 19 Iter 4600, train entropy gap 0.7865 bits (loss 20.130, data 19.343) 
Epoch 19 Iter 4800, train entropy gap 0.7640 bits (loss 20.107, data 19.343) 
Epoch 19 Iter 5000, train entropy gap 0.7165 bits (loss 20.060, data 19.343) 
Epoch 19 Iter 5200, train entropy gap 0.7466 bits (loss 20.090, data 19.343) 
Epoch 19 Iter 5400, train entropy gap 0.7923 bits (loss 20.136, data 19.343) 
Epoch 19 Iter 5600, train entropy gap 0.6663 bits (loss 20.010, data 19.343) 
Epoch 19 Iter 5800, train entropy gap 0.6893 bits (loss 20.033, data 19.343) 
Epoch 19 Iter 6000, train entropy gap 0.8061 bits (loss 20.150, data 19.343) 
Epoch 19 Iter 6200, train entropy gap 0.6415 bits (loss 19.985, data 19.343) 
Epoch 19 Iter 6400, train entropy gap 0.7788 bits (loss 20.122, data 19.343) 
Epoch 19 Iter 6600, train entropy gap 0.8446 bits (loss 20.188, data 19.343) 
Epoch 19 Iter 6800, train entropy gap 0.7299 bits (loss 20.073, data 19.343) 
Epoch 19 Iter 7000, train entropy gap 0.8637 bits (loss 20.207, data 19.343) 
epoch 19 train loss 13.9692 nats / 20.1533 bits
time since start: 3282.0 secs
Training done; evaluating likelihood on full data:
Epoch None Iter 0, test loss 17.4761 nats / 25.2126 bits
Epoch None Iter 500, test loss 15.0370 nats / 21.6938 bits
Epoch None Iter 1000, test loss 13.1793 nats / 19.0137 bits
Epoch None Iter 1500, test loss 12.5721 nats / 18.1377 bits
Epoch None Iter 2000, test loss 13.3967 nats / 19.3274 bits
Epoch None Iter 2500, test loss 12.4024 nats / 17.8928 bits
Epoch None Iter 3000, test loss 15.4522 nats / 22.2928 bits
Epoch None Iter 3500, test loss 12.9540 nats / 18.6887 bits
Epoch None Iter 4000, test loss 12.5913 nats / 18.1654 bits
Epoch None Iter 4500, test loss 13.6606 nats / 19.7081 bits
Epoch None Iter 5000, test loss 12.7111 nats / 18.3383 bits
Epoch None Iter 5500, test loss 15.5243 nats / 22.3969 bits
Epoch None Iter 6000, test loss 14.0280 nats / 20.2382 bits
Epoch None Iter 6500, test loss 13.0280 nats / 18.7955 bits
Epoch None Iter 7000, test loss 16.8024 nats / 24.2408 bits
Saved to:
/home/jixy/naru/models/pretrained/DMV/DMV_ofnan_p100/dmv-ofnan-2.1MB-model20.145-data19.343-flash-blocks1-embed_dim128-expansion_factor2.0-group_size2-posEmb-20epochs-seed0.pt
