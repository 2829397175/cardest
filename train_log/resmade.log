Device cuda
Loading csv... done, took 6.3s
Parsing... done, took 5.1s
Entropy of DMV([Column(Record Type, distribution_size=8), Column(Registration Class, distribution_size=72), Column(State, distribution_size=79), Column(County, distribution_size=64), Column(Body Type, distribution_size=59), Column(Fuel Type, distribution_size=10), Column(Reg Valid Date, distribution_size=2884), Column(Color, distribution_size=222), Column(Scofflaw Indicator, distribution_size=3), Column(Suspension Indicator, distribution_size=3), Column(Revocation Indicator, distribution_size=3)]): 19.3808 bits
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7389597 entries, 0 to 7389596
Data columns (total 11 columns):
 #   Column                Dtype         
---  ------                -----         
 0   Record Type           object        
 1   Registration Class    object        
 2   State                 object        
 3   County                object        
 4   Body Type             object        
 5   Fuel Type             object        
 6   Reg Valid Date        datetime64[ns]
 7   Color                 object        
 8   Scofflaw Indicator    object        
 9   Suspension Indicator  object        
 10  Revocation Indicator  object        
dtypes: datetime64[ns](1), object(10)
memory usage: 620.2+ MB
None
fixed_ordering None seed 0 natural_ordering True
encoded_bins (output) [8, 72, 79, 64, 59, 10, 2884, 222, 3, 3, 3]
encoded_bins (input) [3, 7, 7, 6, 6, 4, 12, 8, 2, 2, 2]
Number of model parameters: 1621715 (~= 6.2MB)
MADE(
  (net): Sequential(
    (0): MaskedLinear(in_features=59, out_features=256, bias=True)
    (1): MaskedResidualBlock(
      (layers): ModuleList(
        (0): MaskedLinear(in_features=256, out_features=256, bias=True)
        (1): MaskedLinear(in_features=256, out_features=256, bias=True)
      )
      (activation): ReLU()
    )
    (2): MaskedResidualBlock(
      (layers): ModuleList(
        (0): MaskedLinear(in_features=256, out_features=256, bias=True)
        (1): MaskedLinear(in_features=256, out_features=256, bias=True)
      )
      (activation): ReLU()
    )
    (3): MaskedResidualBlock(
      (layers): ModuleList(
        (0): MaskedLinear(in_features=256, out_features=256, bias=True)
        (1): MaskedLinear(in_features=256, out_features=256, bias=True)
      )
      (activation): ReLU()
    )
    (4): MaskedResidualBlock(
      (layers): ModuleList(
        (0): MaskedLinear(in_features=256, out_features=256, bias=True)
        (1): MaskedLinear(in_features=256, out_features=256, bias=True)
      )
      (activation): ReLU()
    )
    (5): MaskedLinear(in_features=256, out_features=3407, bias=True)
  )
  (direct_io_layer): MaskedLinear(in_features=59, out_features=3407, bias=True)
)
Applying InitWeight()
Discretizing table... done, took 4.8s
Epoch 0 Iter 0, train entropy gap 35.4815 bits (loss 54.862, data 19.381) 
Epoch 0 Iter 200, train entropy gap 34.7411 bits (loss 54.122, data 19.381) 
Epoch 0 Iter 400, train entropy gap 32.5204 bits (loss 51.901, data 19.381) 
Epoch 0 Iter 600, train entropy gap 27.7858 bits (loss 47.167, data 19.381) 
Epoch 0 Iter 800, train entropy gap 19.2450 bits (loss 38.626, data 19.381) 
Epoch 0 Iter 1000, train entropy gap 14.8927 bits (loss 34.273, data 19.381) 
Epoch 0 Iter 1200, train entropy gap 10.5685 bits (loss 29.949, data 19.381) 
Epoch 0 Iter 1400, train entropy gap 7.7782 bits (loss 27.159, data 19.381) 
Epoch 0 Iter 1600, train entropy gap 6.0376 bits (loss 25.418, data 19.381) 
Epoch 0 Iter 1800, train entropy gap 5.5468 bits (loss 24.928, data 19.381) 
Epoch 0 Iter 2000, train entropy gap 5.1322 bits (loss 24.513, data 19.381) 
Epoch 0 Iter 2200, train entropy gap 4.9339 bits (loss 24.315, data 19.381) 
Epoch 0 Iter 2400, train entropy gap 4.4593 bits (loss 23.840, data 19.381) 
Epoch 0 Iter 2600, train entropy gap 4.6025 bits (loss 23.983, data 19.381) 
Epoch 0 Iter 2800, train entropy gap 4.4315 bits (loss 23.812, data 19.381) 
Epoch 0 Iter 3000, train entropy gap 4.0886 bits (loss 23.469, data 19.381) 
Epoch 0 Iter 3200, train entropy gap 3.8853 bits (loss 23.266, data 19.381) 
Epoch 0 Iter 3400, train entropy gap 3.6076 bits (loss 22.988, data 19.381) 
Epoch 0 Iter 3600, train entropy gap 3.5851 bits (loss 22.966, data 19.381) 
epoch 0 train loss 21.6510 nats / 31.2358 bits
time since start: 38.9 secs
Epoch 1 Iter 0, train entropy gap 3.5865 bits (loss 22.967, data 19.381) 
Epoch 1 Iter 200, train entropy gap 3.4647 bits (loss 22.846, data 19.381) 
Epoch 1 Iter 400, train entropy gap 3.7058 bits (loss 23.087, data 19.381) 
Epoch 1 Iter 600, train entropy gap 3.4822 bits (loss 22.863, data 19.381) 
Epoch 1 Iter 800, train entropy gap 3.4599 bits (loss 22.841, data 19.381) 
Epoch 1 Iter 1000, train entropy gap 3.4048 bits (loss 22.786, data 19.381) 
Epoch 1 Iter 1200, train entropy gap 3.1729 bits (loss 22.554, data 19.381) 
Epoch 1 Iter 1400, train entropy gap 3.2896 bits (loss 22.670, data 19.381) 
Epoch 1 Iter 1600, train entropy gap 3.1121 bits (loss 22.493, data 19.381) 
Epoch 1 Iter 1800, train entropy gap 3.2050 bits (loss 22.586, data 19.381) 
Epoch 1 Iter 2000, train entropy gap 3.3063 bits (loss 22.687, data 19.381) 
Epoch 1 Iter 2200, train entropy gap 3.1215 bits (loss 22.502, data 19.381) 
Epoch 1 Iter 2400, train entropy gap 2.9901 bits (loss 22.371, data 19.381) 
Epoch 1 Iter 2600, train entropy gap 3.0461 bits (loss 22.427, data 19.381) 
Epoch 1 Iter 2800, train entropy gap 2.8233 bits (loss 22.204, data 19.381) 
Epoch 1 Iter 3000, train entropy gap 2.6692 bits (loss 22.050, data 19.381) 
Epoch 1 Iter 3200, train entropy gap 2.5973 bits (loss 21.978, data 19.381) 
Epoch 1 Iter 3400, train entropy gap 2.6700 bits (loss 22.051, data 19.381) 
Epoch 1 Iter 3600, train entropy gap 2.5261 bits (loss 21.907, data 19.381) 
epoch 1 train loss 15.5995 nats / 22.5053 bits
time since start: 76.3 secs
Epoch 2 Iter 0, train entropy gap 2.5603 bits (loss 21.941, data 19.381) 
Epoch 2 Iter 200, train entropy gap 2.5754 bits (loss 21.956, data 19.381) 
Epoch 2 Iter 400, train entropy gap 2.6008 bits (loss 21.982, data 19.381) 
Epoch 2 Iter 600, train entropy gap 2.3474 bits (loss 21.728, data 19.381) 
Epoch 2 Iter 800, train entropy gap 2.7142 bits (loss 22.095, data 19.381) 
Epoch 2 Iter 1000, train entropy gap 2.6146 bits (loss 21.995, data 19.381) 
Epoch 2 Iter 1200, train entropy gap 2.3921 bits (loss 21.773, data 19.381) 
Epoch 2 Iter 1400, train entropy gap 2.4937 bits (loss 21.874, data 19.381) 
Epoch 2 Iter 1600, train entropy gap 2.4748 bits (loss 21.856, data 19.381) 
Epoch 2 Iter 1800, train entropy gap 2.5541 bits (loss 21.935, data 19.381) 
Epoch 2 Iter 2000, train entropy gap 2.4636 bits (loss 21.844, data 19.381) 
Epoch 2 Iter 2200, train entropy gap 2.4324 bits (loss 21.813, data 19.381) 
Epoch 2 Iter 2400, train entropy gap 2.2218 bits (loss 21.603, data 19.381) 
Epoch 2 Iter 2600, train entropy gap 2.1479 bits (loss 21.529, data 19.381) 
Epoch 2 Iter 2800, train entropy gap 2.2054 bits (loss 21.586, data 19.381) 
Epoch 2 Iter 3000, train entropy gap 2.1181 bits (loss 21.499, data 19.381) 
Epoch 2 Iter 3200, train entropy gap 2.2047 bits (loss 21.585, data 19.381) 
Epoch 2 Iter 3400, train entropy gap 2.1465 bits (loss 21.527, data 19.381) 
Epoch 2 Iter 3600, train entropy gap 1.9310 bits (loss 21.312, data 19.381) 
epoch 2 train loss 15.0716 nats / 21.7438 bits
time since start: 113.7 secs
Epoch 3 Iter 0, train entropy gap 2.0119 bits (loss 21.393, data 19.381) 
Epoch 3 Iter 200, train entropy gap 1.9892 bits (loss 21.370, data 19.381) 
Epoch 3 Iter 400, train entropy gap 2.1084 bits (loss 21.489, data 19.381) 
Epoch 3 Iter 600, train entropy gap 1.8942 bits (loss 21.275, data 19.381) 
Epoch 3 Iter 800, train entropy gap 1.9150 bits (loss 21.296, data 19.381) 
Epoch 3 Iter 1000, train entropy gap 1.8562 bits (loss 21.237, data 19.381) 
Epoch 3 Iter 1200, train entropy gap 1.7437 bits (loss 21.125, data 19.381) 
Epoch 3 Iter 1400, train entropy gap 1.8783 bits (loss 21.259, data 19.381) 
Epoch 3 Iter 1600, train entropy gap 1.7992 bits (loss 21.180, data 19.381) 
Epoch 3 Iter 1800, train entropy gap 1.9363 bits (loss 21.317, data 19.381) 
Epoch 3 Iter 2000, train entropy gap 1.9035 bits (loss 21.284, data 19.381) 
Epoch 3 Iter 2200, train entropy gap 1.8344 bits (loss 21.215, data 19.381) 
Epoch 3 Iter 2400, train entropy gap 1.7205 bits (loss 21.101, data 19.381) 
Epoch 3 Iter 2600, train entropy gap 1.7551 bits (loss 21.136, data 19.381) 
Epoch 3 Iter 2800, train entropy gap 1.7322 bits (loss 21.113, data 19.381) 
Epoch 3 Iter 3000, train entropy gap 1.7311 bits (loss 21.112, data 19.381) 
Epoch 3 Iter 3200, train entropy gap 1.8770 bits (loss 21.258, data 19.381) 
Epoch 3 Iter 3400, train entropy gap 1.5313 bits (loss 20.912, data 19.381) 
Epoch 3 Iter 3600, train entropy gap 1.7350 bits (loss 21.116, data 19.381) 
epoch 3 train loss 14.7231 nats / 21.2409 bits
time since start: 151.1 secs
Epoch 4 Iter 0, train entropy gap 1.6959 bits (loss 21.077, data 19.381) 
Epoch 4 Iter 200, train entropy gap 1.5261 bits (loss 20.907, data 19.381) 
Epoch 4 Iter 400, train entropy gap 1.5451 bits (loss 20.926, data 19.381) 
Epoch 4 Iter 600, train entropy gap 1.5841 bits (loss 20.965, data 19.381) 
Epoch 4 Iter 800, train entropy gap 1.5391 bits (loss 20.920, data 19.381) 
Epoch 4 Iter 1000, train entropy gap 1.5460 bits (loss 20.927, data 19.381) 
Epoch 4 Iter 1200, train entropy gap 1.7871 bits (loss 21.168, data 19.381) 
Epoch 4 Iter 1400, train entropy gap 1.5908 bits (loss 20.972, data 19.381) 
Epoch 4 Iter 1600, train entropy gap 1.5831 bits (loss 20.964, data 19.381) 
Epoch 4 Iter 1800, train entropy gap 1.4178 bits (loss 20.799, data 19.381) 
Epoch 4 Iter 2000, train entropy gap 1.5157 bits (loss 20.896, data 19.381) 
Epoch 4 Iter 2200, train entropy gap 1.4935 bits (loss 20.874, data 19.381) 
Epoch 4 Iter 2400, train entropy gap 1.6714 bits (loss 21.052, data 19.381) 
Epoch 4 Iter 2600, train entropy gap 1.4326 bits (loss 20.813, data 19.381) 
Epoch 4 Iter 2800, train entropy gap 1.5682 bits (loss 20.949, data 19.381) 
Epoch 4 Iter 3000, train entropy gap 1.4027 bits (loss 20.784, data 19.381) 
Epoch 4 Iter 3200, train entropy gap 1.2072 bits (loss 20.588, data 19.381) 
Epoch 4 Iter 3400, train entropy gap 1.3981 bits (loss 20.779, data 19.381) 
Epoch 4 Iter 3600, train entropy gap 1.6032 bits (loss 20.984, data 19.381) 
epoch 4 train loss 14.4904 nats / 20.9052 bits
time since start: 188.2 secs
Epoch 5 Iter 0, train entropy gap 1.4387 bits (loss 20.820, data 19.381) 
Epoch 5 Iter 200, train entropy gap 1.4168 bits (loss 20.798, data 19.381) 
Epoch 5 Iter 400, train entropy gap 1.3309 bits (loss 20.712, data 19.381) 
Epoch 5 Iter 600, train entropy gap 1.2719 bits (loss 20.653, data 19.381) 
Epoch 5 Iter 800, train entropy gap 1.4409 bits (loss 20.822, data 19.381) 
Epoch 5 Iter 1000, train entropy gap 1.3723 bits (loss 20.753, data 19.381) 
Epoch 5 Iter 1200, train entropy gap 1.3499 bits (loss 20.731, data 19.381) 
Epoch 5 Iter 1400, train entropy gap 1.1939 bits (loss 20.575, data 19.381) 
Epoch 5 Iter 1600, train entropy gap 1.3284 bits (loss 20.709, data 19.381) 
Epoch 5 Iter 1800, train entropy gap 1.5631 bits (loss 20.944, data 19.381) 
Epoch 5 Iter 2000, train entropy gap 1.3601 bits (loss 20.741, data 19.381) 
Epoch 5 Iter 2200, train entropy gap 1.2193 bits (loss 20.600, data 19.381) 
Epoch 5 Iter 2400, train entropy gap 1.2694 bits (loss 20.650, data 19.381) 
Epoch 5 Iter 2600, train entropy gap 1.4729 bits (loss 20.854, data 19.381) 
Epoch 5 Iter 2800, train entropy gap 1.4171 bits (loss 20.798, data 19.381) 
Epoch 5 Iter 3000, train entropy gap 1.1750 bits (loss 20.556, data 19.381) 
Epoch 5 Iter 3200, train entropy gap 1.1163 bits (loss 20.497, data 19.381) 
Epoch 5 Iter 3400, train entropy gap 1.3477 bits (loss 20.728, data 19.381) 
Epoch 5 Iter 3600, train entropy gap 1.1317 bits (loss 20.512, data 19.381) 
epoch 5 train loss 14.3420 nats / 20.6911 bits
time since start: 225.2 secs
Epoch 6 Iter 0, train entropy gap 1.0741 bits (loss 20.455, data 19.381) 
Epoch 6 Iter 200, train entropy gap 1.0118 bits (loss 20.393, data 19.381) 
Epoch 6 Iter 400, train entropy gap 1.2299 bits (loss 20.611, data 19.381) 
Epoch 6 Iter 600, train entropy gap 1.1938 bits (loss 20.575, data 19.381) 
Epoch 6 Iter 800, train entropy gap 1.1708 bits (loss 20.552, data 19.381) 
Epoch 6 Iter 1000, train entropy gap 1.1589 bits (loss 20.540, data 19.381) 
Epoch 6 Iter 1200, train entropy gap 1.2717 bits (loss 20.653, data 19.381) 
Epoch 6 Iter 1400, train entropy gap 1.2487 bits (loss 20.629, data 19.381) 
Epoch 6 Iter 1600, train entropy gap 1.1065 bits (loss 20.487, data 19.381) 
Epoch 6 Iter 1800, train entropy gap 1.2339 bits (loss 20.615, data 19.381) 
Epoch 6 Iter 2000, train entropy gap 1.2189 bits (loss 20.600, data 19.381) 
Epoch 6 Iter 2200, train entropy gap 1.2543 bits (loss 20.635, data 19.381) 
Epoch 6 Iter 2400, train entropy gap 1.1336 bits (loss 20.514, data 19.381) 
Epoch 6 Iter 2600, train entropy gap 1.1026 bits (loss 20.483, data 19.381) 
Epoch 6 Iter 2800, train entropy gap 1.1493 bits (loss 20.530, data 19.381) 
Epoch 6 Iter 3000, train entropy gap 1.1289 bits (loss 20.510, data 19.381) 
Epoch 6 Iter 3200, train entropy gap 1.4276 bits (loss 20.808, data 19.381) 
Epoch 6 Iter 3400, train entropy gap 1.0188 bits (loss 20.400, data 19.381) 
Epoch 6 Iter 3600, train entropy gap 1.1142 bits (loss 20.495, data 19.381) 
epoch 6 train loss 14.2490 nats / 20.5569 bits
time since start: 262.6 secs
Epoch 7 Iter 0, train entropy gap 1.1604 bits (loss 20.541, data 19.381) 
Epoch 7 Iter 200, train entropy gap 1.1279 bits (loss 20.509, data 19.381) 
Epoch 7 Iter 400, train entropy gap 1.1416 bits (loss 20.522, data 19.381) 
Epoch 7 Iter 600, train entropy gap 1.0320 bits (loss 20.413, data 19.381) 
Epoch 7 Iter 800, train entropy gap 1.1737 bits (loss 20.555, data 19.381) 
Epoch 7 Iter 1000, train entropy gap 0.9935 bits (loss 20.374, data 19.381) 
Epoch 7 Iter 1200, train entropy gap 1.1333 bits (loss 20.514, data 19.381) 
Epoch 7 Iter 1400, train entropy gap 1.2363 bits (loss 20.617, data 19.381) 
Epoch 7 Iter 1600, train entropy gap 1.0722 bits (loss 20.453, data 19.381) 
Epoch 7 Iter 1800, train entropy gap 1.0223 bits (loss 20.403, data 19.381) 
Epoch 7 Iter 2000, train entropy gap 1.1908 bits (loss 20.572, data 19.381) 
Epoch 7 Iter 2200, train entropy gap 0.9856 bits (loss 20.366, data 19.381) 
Epoch 7 Iter 2400, train entropy gap 0.8639 bits (loss 20.245, data 19.381) 
Epoch 7 Iter 2600, train entropy gap 1.0436 bits (loss 20.424, data 19.381) 
Epoch 7 Iter 2800, train entropy gap 1.1264 bits (loss 20.507, data 19.381) 
Epoch 7 Iter 3000, train entropy gap 1.1443 bits (loss 20.525, data 19.381) 
Epoch 7 Iter 3200, train entropy gap 1.0560 bits (loss 20.437, data 19.381) 
Epoch 7 Iter 3400, train entropy gap 1.0127 bits (loss 20.394, data 19.381) 
Epoch 7 Iter 3600, train entropy gap 1.1076 bits (loss 20.488, data 19.381) 
epoch 7 train loss 14.1922 nats / 20.4750 bits
time since start: 299.6 secs
Epoch 8 Iter 0, train entropy gap 1.1013 bits (loss 20.482, data 19.381) 
Epoch 8 Iter 200, train entropy gap 0.9086 bits (loss 20.289, data 19.381) 
Epoch 8 Iter 400, train entropy gap 0.9988 bits (loss 20.380, data 19.381) 
Epoch 8 Iter 600, train entropy gap 1.1273 bits (loss 20.508, data 19.381) 
Epoch 8 Iter 800, train entropy gap 1.0292 bits (loss 20.410, data 19.381) 
Epoch 8 Iter 1000, train entropy gap 0.8854 bits (loss 20.266, data 19.381) 
Epoch 8 Iter 1200, train entropy gap 1.0685 bits (loss 20.449, data 19.381) 
Epoch 8 Iter 1400, train entropy gap 0.9803 bits (loss 20.361, data 19.381) 
Epoch 8 Iter 1600, train entropy gap 1.2780 bits (loss 20.659, data 19.381) 
Epoch 8 Iter 1800, train entropy gap 0.9271 bits (loss 20.308, data 19.381) 
Epoch 8 Iter 2000, train entropy gap 0.9826 bits (loss 20.363, data 19.381) 
Epoch 8 Iter 2200, train entropy gap 1.1287 bits (loss 20.509, data 19.381) 
Epoch 8 Iter 2400, train entropy gap 1.1986 bits (loss 20.579, data 19.381) 
Epoch 8 Iter 2600, train entropy gap 1.0862 bits (loss 20.467, data 19.381) 
Epoch 8 Iter 2800, train entropy gap 1.1409 bits (loss 20.522, data 19.381) 
Epoch 8 Iter 3000, train entropy gap 1.2391 bits (loss 20.620, data 19.381) 
Epoch 8 Iter 3200, train entropy gap 1.1123 bits (loss 20.493, data 19.381) 
Epoch 8 Iter 3400, train entropy gap 1.0961 bits (loss 20.477, data 19.381) 
Epoch 8 Iter 3600, train entropy gap 1.0191 bits (loss 20.400, data 19.381) 
epoch 8 train loss 14.1581 nats / 20.4258 bits
time since start: 336.7 secs
Epoch 9 Iter 0, train entropy gap 1.1520 bits (loss 20.533, data 19.381) 
Epoch 9 Iter 200, train entropy gap 0.9919 bits (loss 20.373, data 19.381) 
Epoch 9 Iter 400, train entropy gap 1.0396 bits (loss 20.420, data 19.381) 
Epoch 9 Iter 600, train entropy gap 0.9664 bits (loss 20.347, data 19.381) 
Epoch 9 Iter 800, train entropy gap 1.0701 bits (loss 20.451, data 19.381) 
Epoch 9 Iter 1000, train entropy gap 0.8900 bits (loss 20.271, data 19.381) 
Epoch 9 Iter 1200, train entropy gap 0.9544 bits (loss 20.335, data 19.381) 
Epoch 9 Iter 1400, train entropy gap 1.1546 bits (loss 20.535, data 19.381) 
Epoch 9 Iter 1600, train entropy gap 1.1502 bits (loss 20.531, data 19.381) 
Epoch 9 Iter 1800, train entropy gap 1.0611 bits (loss 20.442, data 19.381) 
Epoch 9 Iter 2000, train entropy gap 0.8974 bits (loss 20.278, data 19.381) 
Epoch 9 Iter 2200, train entropy gap 0.9146 bits (loss 20.295, data 19.381) 
Epoch 9 Iter 2400, train entropy gap 0.8701 bits (loss 20.251, data 19.381) 
Epoch 9 Iter 2600, train entropy gap 0.9322 bits (loss 20.313, data 19.381) 
Epoch 9 Iter 2800, train entropy gap 1.0374 bits (loss 20.418, data 19.381) 
Epoch 9 Iter 3000, train entropy gap 0.9772 bits (loss 20.358, data 19.381) 
Epoch 9 Iter 3200, train entropy gap 1.0010 bits (loss 20.382, data 19.381) 
Epoch 9 Iter 3400, train entropy gap 1.1329 bits (loss 20.514, data 19.381) 
Epoch 9 Iter 3600, train entropy gap 1.1334 bits (loss 20.514, data 19.381) 
epoch 9 train loss 14.1368 nats / 20.3950 bits
time since start: 373.9 secs
Epoch 10 Iter 0, train entropy gap 0.9578 bits (loss 20.339, data 19.381) 
Epoch 10 Iter 200, train entropy gap 0.8717 bits (loss 20.253, data 19.381) 
Epoch 10 Iter 400, train entropy gap 0.9436 bits (loss 20.324, data 19.381) 
Epoch 10 Iter 600, train entropy gap 0.9119 bits (loss 20.293, data 19.381) 
Epoch 10 Iter 800, train entropy gap 1.0386 bits (loss 20.419, data 19.381) 
Epoch 10 Iter 1000, train entropy gap 1.0261 bits (loss 20.407, data 19.381) 
Epoch 10 Iter 1200, train entropy gap 1.0133 bits (loss 20.394, data 19.381) 
Epoch 10 Iter 1400, train entropy gap 0.8293 bits (loss 20.210, data 19.381) 
Epoch 10 Iter 1600, train entropy gap 0.9128 bits (loss 20.294, data 19.381) 
Epoch 10 Iter 1800, train entropy gap 1.1044 bits (loss 20.485, data 19.381) 
Epoch 10 Iter 2000, train entropy gap 1.0102 bits (loss 20.391, data 19.381) 
Epoch 10 Iter 2200, train entropy gap 0.9768 bits (loss 20.358, data 19.381) 
Epoch 10 Iter 2400, train entropy gap 0.8585 bits (loss 20.239, data 19.381) 
Epoch 10 Iter 2600, train entropy gap 0.8594 bits (loss 20.240, data 19.381) 
Epoch 10 Iter 2800, train entropy gap 0.9839 bits (loss 20.365, data 19.381) 
Epoch 10 Iter 3000, train entropy gap 0.9732 bits (loss 20.354, data 19.381) 
Epoch 10 Iter 3200, train entropy gap 1.0470 bits (loss 20.428, data 19.381) 
Epoch 10 Iter 3400, train entropy gap 0.7945 bits (loss 20.175, data 19.381) 
Epoch 10 Iter 3600, train entropy gap 1.0645 bits (loss 20.445, data 19.381) 
epoch 10 train loss 14.1227 nats / 20.3747 bits
time since start: 411.4 secs
Epoch 11 Iter 0, train entropy gap 1.0730 bits (loss 20.454, data 19.381) 
Epoch 11 Iter 200, train entropy gap 0.9087 bits (loss 20.289, data 19.381) 
Epoch 11 Iter 400, train entropy gap 1.1580 bits (loss 20.539, data 19.381) 
Epoch 11 Iter 600, train entropy gap 1.1231 bits (loss 20.504, data 19.381) 
Epoch 11 Iter 800, train entropy gap 0.9143 bits (loss 20.295, data 19.381) 
Epoch 11 Iter 1000, train entropy gap 1.0716 bits (loss 20.452, data 19.381) 
Epoch 11 Iter 1200, train entropy gap 0.9406 bits (loss 20.321, data 19.381) 
Epoch 11 Iter 1400, train entropy gap 0.9352 bits (loss 20.316, data 19.381) 
Epoch 11 Iter 1600, train entropy gap 1.0051 bits (loss 20.386, data 19.381) 
Epoch 11 Iter 1800, train entropy gap 0.9385 bits (loss 20.319, data 19.381) 
Epoch 11 Iter 2000, train entropy gap 0.9854 bits (loss 20.366, data 19.381) 
Epoch 11 Iter 2200, train entropy gap 0.9374 bits (loss 20.318, data 19.381) 
Epoch 11 Iter 2400, train entropy gap 1.0505 bits (loss 20.431, data 19.381) 
Epoch 11 Iter 2600, train entropy gap 0.8314 bits (loss 20.212, data 19.381) 
Epoch 11 Iter 2800, train entropy gap 1.0773 bits (loss 20.458, data 19.381) 
Epoch 11 Iter 3000, train entropy gap 0.9383 bits (loss 20.319, data 19.381) 
Epoch 11 Iter 3200, train entropy gap 0.9618 bits (loss 20.343, data 19.381) 
Epoch 11 Iter 3400, train entropy gap 1.0533 bits (loss 20.434, data 19.381) 
Epoch 11 Iter 3600, train entropy gap 1.1207 bits (loss 20.502, data 19.381) 
epoch 11 train loss 14.1130 nats / 20.3608 bits
time since start: 448.6 secs
Epoch 12 Iter 0, train entropy gap 1.0143 bits (loss 20.395, data 19.381) 
Epoch 12 Iter 200, train entropy gap 1.1385 bits (loss 20.519, data 19.381) 
Epoch 12 Iter 400, train entropy gap 0.9128 bits (loss 20.294, data 19.381) 
Epoch 12 Iter 600, train entropy gap 0.9906 bits (loss 20.371, data 19.381) 
Epoch 12 Iter 800, train entropy gap 0.9932 bits (loss 20.374, data 19.381) 
Epoch 12 Iter 1000, train entropy gap 0.9007 bits (loss 20.281, data 19.381) 
Epoch 12 Iter 1200, train entropy gap 1.1141 bits (loss 20.495, data 19.381) 
Epoch 12 Iter 1400, train entropy gap 0.9290 bits (loss 20.310, data 19.381) 
Epoch 12 Iter 1600, train entropy gap 0.8208 bits (loss 20.202, data 19.381) 
Epoch 12 Iter 1800, train entropy gap 1.0161 bits (loss 20.397, data 19.381) 
Epoch 12 Iter 2000, train entropy gap 0.9941 bits (loss 20.375, data 19.381) 
Epoch 12 Iter 2200, train entropy gap 1.0315 bits (loss 20.412, data 19.381) 
Epoch 12 Iter 2400, train entropy gap 1.0286 bits (loss 20.409, data 19.381) 
Epoch 12 Iter 2600, train entropy gap 1.0470 bits (loss 20.428, data 19.381) 
Epoch 12 Iter 2800, train entropy gap 1.0005 bits (loss 20.381, data 19.381) 
Epoch 12 Iter 3000, train entropy gap 0.9808 bits (loss 20.362, data 19.381) 
Epoch 12 Iter 3200, train entropy gap 0.9658 bits (loss 20.347, data 19.381) 
Epoch 12 Iter 3400, train entropy gap 1.0490 bits (loss 20.430, data 19.381) 
Epoch 12 Iter 3600, train entropy gap 0.8529 bits (loss 20.234, data 19.381) 
epoch 12 train loss 14.1058 nats / 20.3504 bits
time since start: 485.9 secs
Epoch 13 Iter 0, train entropy gap 0.8971 bits (loss 20.278, data 19.381) 
Epoch 13 Iter 200, train entropy gap 1.0899 bits (loss 20.471, data 19.381) 
Epoch 13 Iter 400, train entropy gap 0.8430 bits (loss 20.224, data 19.381) 
Epoch 13 Iter 600, train entropy gap 0.9539 bits (loss 20.335, data 19.381) 
Epoch 13 Iter 800, train entropy gap 1.0063 bits (loss 20.387, data 19.381) 
Epoch 13 Iter 1000, train entropy gap 0.8704 bits (loss 20.251, data 19.381) 
Epoch 13 Iter 1200, train entropy gap 0.9207 bits (loss 20.301, data 19.381) 
Epoch 13 Iter 1400, train entropy gap 0.9957 bits (loss 20.376, data 19.381) 
Epoch 13 Iter 1600, train entropy gap 0.9014 bits (loss 20.282, data 19.381) 
Epoch 13 Iter 1800, train entropy gap 0.9872 bits (loss 20.368, data 19.381) 
Epoch 13 Iter 2000, train entropy gap 0.8802 bits (loss 20.261, data 19.381) 
Epoch 13 Iter 2200, train entropy gap 0.9372 bits (loss 20.318, data 19.381) 
Epoch 13 Iter 2400, train entropy gap 1.0724 bits (loss 20.453, data 19.381) 
Epoch 13 Iter 2600, train entropy gap 0.8426 bits (loss 20.223, data 19.381) 
Epoch 13 Iter 2800, train entropy gap 0.9258 bits (loss 20.307, data 19.381) 
Epoch 13 Iter 3000, train entropy gap 0.9195 bits (loss 20.300, data 19.381) 
Epoch 13 Iter 3200, train entropy gap 1.0984 bits (loss 20.479, data 19.381) 
Epoch 13 Iter 3400, train entropy gap 1.0404 bits (loss 20.421, data 19.381) 
Epoch 13 Iter 3600, train entropy gap 1.0877 bits (loss 20.469, data 19.381) 
epoch 13 train loss 14.1000 nats / 20.3419 bits
time since start: 523.7 secs
Epoch 14 Iter 0, train entropy gap 0.8940 bits (loss 20.275, data 19.381) 
Epoch 14 Iter 200, train entropy gap 0.9718 bits (loss 20.353, data 19.381) 
Epoch 14 Iter 400, train entropy gap 1.0472 bits (loss 20.428, data 19.381) 
Epoch 14 Iter 600, train entropy gap 0.9537 bits (loss 20.334, data 19.381) 
Epoch 14 Iter 800, train entropy gap 1.1339 bits (loss 20.515, data 19.381) 
Epoch 14 Iter 1000, train entropy gap 1.0237 bits (loss 20.405, data 19.381) 
Epoch 14 Iter 1200, train entropy gap 0.7542 bits (loss 20.135, data 19.381) 
Epoch 14 Iter 1400, train entropy gap 0.8991 bits (loss 20.280, data 19.381) 
Epoch 14 Iter 1600, train entropy gap 0.9559 bits (loss 20.337, data 19.381) 
Epoch 14 Iter 1800, train entropy gap 1.0250 bits (loss 20.406, data 19.381) 
Epoch 14 Iter 2000, train entropy gap 0.9643 bits (loss 20.345, data 19.381) 
Epoch 14 Iter 2200, train entropy gap 1.0686 bits (loss 20.449, data 19.381) 
Epoch 14 Iter 2400, train entropy gap 0.7856 bits (loss 20.166, data 19.381) 
Epoch 14 Iter 2600, train entropy gap 0.9799 bits (loss 20.361, data 19.381) 
Epoch 14 Iter 2800, train entropy gap 0.9650 bits (loss 20.346, data 19.381) 
Epoch 14 Iter 3000, train entropy gap 0.9967 bits (loss 20.378, data 19.381) 
Epoch 14 Iter 3200, train entropy gap 1.1439 bits (loss 20.525, data 19.381) 
Epoch 14 Iter 3400, train entropy gap 0.9275 bits (loss 20.308, data 19.381) 
Epoch 14 Iter 3600, train entropy gap 0.9280 bits (loss 20.309, data 19.381) 
epoch 14 train loss 14.0950 nats / 20.3348 bits
time since start: 560.7 secs
Epoch 15 Iter 0, train entropy gap 0.7819 bits (loss 20.163, data 19.381) 
Epoch 15 Iter 200, train entropy gap 1.0433 bits (loss 20.424, data 19.381) 
Epoch 15 Iter 400, train entropy gap 0.9779 bits (loss 20.359, data 19.381) 
Epoch 15 Iter 600, train entropy gap 0.8286 bits (loss 20.209, data 19.381) 
Epoch 15 Iter 800, train entropy gap 0.9495 bits (loss 20.330, data 19.381) 
Epoch 15 Iter 1000, train entropy gap 1.1189 bits (loss 20.500, data 19.381) 
Epoch 15 Iter 1200, train entropy gap 1.0296 bits (loss 20.410, data 19.381) 
Epoch 15 Iter 1400, train entropy gap 0.9996 bits (loss 20.380, data 19.381) 
Epoch 15 Iter 1600, train entropy gap 1.0022 bits (loss 20.383, data 19.381) 
Epoch 15 Iter 1800, train entropy gap 0.8005 bits (loss 20.181, data 19.381) 
Epoch 15 Iter 2000, train entropy gap 1.0706 bits (loss 20.451, data 19.381) 
Epoch 15 Iter 2200, train entropy gap 0.8546 bits (loss 20.235, data 19.381) 
Epoch 15 Iter 2400, train entropy gap 0.8602 bits (loss 20.241, data 19.381) 
Epoch 15 Iter 2600, train entropy gap 1.0143 bits (loss 20.395, data 19.381) 
Epoch 15 Iter 2800, train entropy gap 1.0505 bits (loss 20.431, data 19.381) 
Epoch 15 Iter 3000, train entropy gap 1.0063 bits (loss 20.387, data 19.381) 
Epoch 15 Iter 3200, train entropy gap 1.0346 bits (loss 20.415, data 19.381) 
Epoch 15 Iter 3400, train entropy gap 0.9709 bits (loss 20.352, data 19.381) 
Epoch 15 Iter 3600, train entropy gap 0.8743 bits (loss 20.255, data 19.381) 
epoch 15 train loss 14.0908 nats / 20.3288 bits
time since start: 597.4 secs
Epoch 16 Iter 0, train entropy gap 0.9267 bits (loss 20.307, data 19.381) 
Epoch 16 Iter 200, train entropy gap 0.9714 bits (loss 20.352, data 19.381) 
Epoch 16 Iter 400, train entropy gap 0.9473 bits (loss 20.328, data 19.381) 
Epoch 16 Iter 600, train entropy gap 0.9964 bits (loss 20.377, data 19.381) 
Epoch 16 Iter 800, train entropy gap 1.0241 bits (loss 20.405, data 19.381) 
Epoch 16 Iter 1000, train entropy gap 1.0037 bits (loss 20.385, data 19.381) 
Epoch 16 Iter 1200, train entropy gap 0.9626 bits (loss 20.343, data 19.381) 
Epoch 16 Iter 1400, train entropy gap 0.9132 bits (loss 20.294, data 19.381) 
Epoch 16 Iter 1600, train entropy gap 0.9956 bits (loss 20.376, data 19.381) 
Epoch 16 Iter 1800, train entropy gap 1.0798 bits (loss 20.461, data 19.381) 
Epoch 16 Iter 2000, train entropy gap 1.1137 bits (loss 20.495, data 19.381) 
Epoch 16 Iter 2200, train entropy gap 1.0551 bits (loss 20.436, data 19.381) 
Epoch 16 Iter 2400, train entropy gap 0.9476 bits (loss 20.328, data 19.381) 
Epoch 16 Iter 2600, train entropy gap 1.0275 bits (loss 20.408, data 19.381) 
Epoch 16 Iter 2800, train entropy gap 1.0089 bits (loss 20.390, data 19.381) 
Epoch 16 Iter 3000, train entropy gap 0.9595 bits (loss 20.340, data 19.381) 
Epoch 16 Iter 3200, train entropy gap 1.0430 bits (loss 20.424, data 19.381) 
Epoch 16 Iter 3400, train entropy gap 0.9528 bits (loss 20.334, data 19.381) 
Epoch 16 Iter 3600, train entropy gap 0.9645 bits (loss 20.345, data 19.381) 
epoch 16 train loss 14.0871 nats / 20.3234 bits
time since start: 634.3 secs
Epoch 17 Iter 0, train entropy gap 0.9192 bits (loss 20.300, data 19.381) 
Epoch 17 Iter 200, train entropy gap 0.9630 bits (loss 20.344, data 19.381) 
Epoch 17 Iter 400, train entropy gap 0.8476 bits (loss 20.228, data 19.381) 
Epoch 17 Iter 600, train entropy gap 0.9794 bits (loss 20.360, data 19.381) 
Epoch 17 Iter 800, train entropy gap 0.8537 bits (loss 20.234, data 19.381) 
Epoch 17 Iter 1000, train entropy gap 1.0131 bits (loss 20.394, data 19.381) 
Epoch 17 Iter 1200, train entropy gap 0.8790 bits (loss 20.260, data 19.381) 
Epoch 17 Iter 1400, train entropy gap 0.9038 bits (loss 20.285, data 19.381) 
Epoch 17 Iter 1600, train entropy gap 1.2092 bits (loss 20.590, data 19.381) 
Epoch 17 Iter 1800, train entropy gap 1.0504 bits (loss 20.431, data 19.381) 
Epoch 17 Iter 2000, train entropy gap 0.9509 bits (loss 20.332, data 19.381) 
Epoch 17 Iter 2200, train entropy gap 1.0219 bits (loss 20.403, data 19.381) 
Epoch 17 Iter 2400, train entropy gap 0.8484 bits (loss 20.229, data 19.381) 
Epoch 17 Iter 2600, train entropy gap 0.9630 bits (loss 20.344, data 19.381) 
Epoch 17 Iter 2800, train entropy gap 0.9588 bits (loss 20.340, data 19.381) 
Epoch 17 Iter 3000, train entropy gap 1.1233 bits (loss 20.504, data 19.381) 
Epoch 17 Iter 3200, train entropy gap 0.9615 bits (loss 20.342, data 19.381) 
Epoch 17 Iter 3400, train entropy gap 0.8842 bits (loss 20.265, data 19.381) 
Epoch 17 Iter 3600, train entropy gap 1.0298 bits (loss 20.411, data 19.381) 
epoch 17 train loss 14.0841 nats / 20.3190 bits
time since start: 671.3 secs
Epoch 18 Iter 0, train entropy gap 0.9108 bits (loss 20.292, data 19.381) 
Epoch 18 Iter 200, train entropy gap 0.8179 bits (loss 20.199, data 19.381) 
Epoch 18 Iter 400, train entropy gap 0.9915 bits (loss 20.372, data 19.381) 
Epoch 18 Iter 600, train entropy gap 1.1008 bits (loss 20.482, data 19.381) 
Epoch 18 Iter 800, train entropy gap 0.8160 bits (loss 20.197, data 19.381) 
Epoch 18 Iter 1000, train entropy gap 0.9452 bits (loss 20.326, data 19.381) 
Epoch 18 Iter 1200, train entropy gap 0.8921 bits (loss 20.273, data 19.381) 
Epoch 18 Iter 1400, train entropy gap 1.0478 bits (loss 20.429, data 19.381) 
Epoch 18 Iter 1600, train entropy gap 0.8516 bits (loss 20.232, data 19.381) 
Epoch 18 Iter 1800, train entropy gap 0.9250 bits (loss 20.306, data 19.381) 
Epoch 18 Iter 2000, train entropy gap 0.9743 bits (loss 20.355, data 19.381) 
Epoch 18 Iter 2200, train entropy gap 0.8867 bits (loss 20.267, data 19.381) 
Epoch 18 Iter 2400, train entropy gap 0.9188 bits (loss 20.300, data 19.381) 
Epoch 18 Iter 2600, train entropy gap 0.8211 bits (loss 20.202, data 19.381) 
Epoch 18 Iter 2800, train entropy gap 1.0334 bits (loss 20.414, data 19.381) 
Epoch 18 Iter 3000, train entropy gap 0.9692 bits (loss 20.350, data 19.381) 
Epoch 18 Iter 3200, train entropy gap 0.8908 bits (loss 20.272, data 19.381) 
Epoch 18 Iter 3400, train entropy gap 1.0542 bits (loss 20.435, data 19.381) 
Epoch 18 Iter 3600, train entropy gap 0.9223 bits (loss 20.303, data 19.381) 
epoch 18 train loss 14.0812 nats / 20.3148 bits
time since start: 706.8 secs
Epoch 19 Iter 0, train entropy gap 0.9341 bits (loss 20.315, data 19.381) 
Epoch 19 Iter 200, train entropy gap 0.9221 bits (loss 20.303, data 19.381) 
Epoch 19 Iter 400, train entropy gap 0.9391 bits (loss 20.320, data 19.381) 
Epoch 19 Iter 600, train entropy gap 0.9579 bits (loss 20.339, data 19.381) 
Epoch 19 Iter 800, train entropy gap 0.8874 bits (loss 20.268, data 19.381) 
Epoch 19 Iter 1000, train entropy gap 1.1144 bits (loss 20.495, data 19.381) 
Epoch 19 Iter 1200, train entropy gap 0.9396 bits (loss 20.320, data 19.381) 
Epoch 19 Iter 1400, train entropy gap 1.0751 bits (loss 20.456, data 19.381) 
Epoch 19 Iter 1600, train entropy gap 0.9907 bits (loss 20.371, data 19.381) 
Epoch 19 Iter 1800, train entropy gap 0.9507 bits (loss 20.332, data 19.381) 
Epoch 19 Iter 2000, train entropy gap 0.9435 bits (loss 20.324, data 19.381) 
Epoch 19 Iter 2200, train entropy gap 0.9094 bits (loss 20.290, data 19.381) 
Epoch 19 Iter 2400, train entropy gap 0.8077 bits (loss 20.189, data 19.381) 
Epoch 19 Iter 2600, train entropy gap 0.8512 bits (loss 20.232, data 19.381) 
Epoch 19 Iter 2800, train entropy gap 0.9354 bits (loss 20.316, data 19.381) 
Epoch 19 Iter 3000, train entropy gap 1.0566 bits (loss 20.437, data 19.381) 
Epoch 19 Iter 3200, train entropy gap 0.8852 bits (loss 20.266, data 19.381) 
Epoch 19 Iter 3400, train entropy gap 1.0174 bits (loss 20.398, data 19.381) 
Epoch 19 Iter 3600, train entropy gap 1.0524 bits (loss 20.433, data 19.381) 
epoch 19 train loss 14.0786 nats / 20.3112 bits
time since start: 736.5 secs
Training done; evaluating likelihood on full data:
Epoch None Iter 0, test loss 16.7695 nats / 24.1932 bits
Epoch None Iter 500, test loss 15.5199 nats / 22.3905 bits
Epoch None Iter 1000, test loss 13.1103 nats / 18.9141 bits
Epoch None Iter 1500, test loss 12.6692 nats / 18.2777 bits
Epoch None Iter 2000, test loss 13.4337 nats / 19.3807 bits
Epoch None Iter 2500, test loss 12.3556 nats / 17.8254 bits
Epoch None Iter 3000, test loss 13.5658 nats / 19.5714 bits
Epoch None Iter 3500, test loss 15.7920 nats / 22.7831 bits
Epoch None Iter 4000, test loss 12.7894 nats / 18.4512 bits
Epoch None Iter 4500, test loss 17.9122 nats / 25.8418 bits
Epoch None Iter 5000, test loss 17.3816 nats / 25.0763 bits
Epoch None Iter 5500, test loss 13.8058 nats / 19.9175 bits
Epoch None Iter 6000, test loss 13.7255 nats / 19.8018 bits
Epoch None Iter 6500, test loss 12.6748 nats / 18.2859 bits
Epoch None Iter 7000, test loss 15.4977 nats / 22.3585 bits
Saved to:
models/dmv-6.2MB-model20.311-data19.381-made-resmade-hidden256_256_256_256_256-emb32-directIo-binaryInone_hotOut-inputNoEmbIfLeq-20epochs-seed0.pt
